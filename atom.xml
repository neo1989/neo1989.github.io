<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>愚苏记</title>
  
  <subtitle>To no avail but try.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://neo1989.net/"/>
  <updated>2024-02-29T14:24:15.116Z</updated>
  <id>https://neo1989.net/</id>
  
  <author>
    <name>Neo</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>必读论文 · Seven Failure Points When Engineering a RAG System (2024)</title>
    <link href="https://neo1989.net/Theses/THESIS-Seven-Failure-Points-When-Engineering-a-RAG-System/"/>
    <id>https://neo1989.net/Theses/THESIS-Seven-Failure-Points-When-Engineering-a-RAG-System/</id>
    <published>2024-02-29T05:56:11.000Z</published>
    <updated>2024-02-29T14:24:15.116Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract">Abstract</h2><p>随着软件工程师在应用程序中不断引入一种名为检索增强生成（Retrieval Augmented Generation, RAG）的策略，以实现语义搜索功能，RAG 系统的应用也日趋广泛。RAG 系统的核心在于寻找与搜索问题在语义上相匹配的文档，并将这些文档交给大语言模型（LLM），如 ChatGPT，依靠 LLM 来抽取准确的答案。RAG 系统旨在：a) 减少大语言模型产生错误回应的风险，b) 为生成的回答关联上来源和参考文献，以及 c) 避免对文档进行元数据标注的必要。但是，RAG 系统也存在局限性，这些局限性源于信息检索系统本身的缺陷以及对大语言模型的依赖性。在本文中，我们通过三个不同领域：研究、教育和生物医学的案例研究，分析了 RAG 系统的失败经验。我们总结了这些案例中的教训，并提出了设计 RAG 系统时应考虑的七个潜在失败点。从我们的工作中得出两个主要的结论是：1) RAG 系统的验证只能在实际运行中才能进行，以及 2) RAG 系统的稳健性是通过不断的迭代优化而形成的，而非在最初设计时就能完全预设的。</p><h2 id="Introduction">Introduction</h2><p>大语言模型（LLMs）的最新进展，包括 ChatGPT，为软件工程师提供了构建新型人机交互（HCI）解决方案的新工具，能够帮助他们完成复杂的任务，概括文档，解答特定文件中的问题，以及创造新的内容。不过，LLMs 在处理最新知识或企业数据库中的特定领域知识方面还存在不足。目前有两种解决策略：a) 对 LLMs 进行微调（继续用特定领域的资料训练 LLM），这需要管理或提供一个经过微调的 LLM；或 b) 使用基于检索的增强生成（RAG）系统，这种系统依赖 LLMs 利用现有的（可扩展的）知识资料来生成答案。这两种方法在数据隐私与安全、可扩展性、成本、所需技能等方面各有利弊。本文将重点讨论 RAG 系统。</p><p>检索增强生成（RAG）系统提出了一个具有吸引力的解决方案来应对这一挑战。它将检索机制与大语言模型（LLMs）的生成功能相结合，能够生成与上下文相关、准确且最新的信息。RAG 系统融合了信息检索和大语言模型的生成才能。其检索部分致力于从数据仓库中寻找与用户问题相关的信息，而生成部分则利用这些检索到的信息作为背景，以产生针对用户问题的答案。RAG 系统的一个重要应用是，它使得所有非结构化的信息都能被索引和查询，这大大缩短了开发周期，无需构建知识图谱，同时也减少了数据整理和清洗的工作量。</p><p>软件工程师在构建 RAG 系统时，首先需要对获取的不同格式的领域知识进行预处理，并将其作为工件存放。接着，他们要将这些经过处理的信息储存在适当的数据仓库（例如向量数据库）中，选择或者整合一种合适的查询与工件匹配策略，对找到的工件进行排序，并通过调用大语言模型（LLMs）的 API，结合用户的查询和相关的上下文文档。目前，关于构建 RAG 系统的新技术不断涌现，但要了解这些技术如何适用于特定的应用场景以及它们的实际效果如何，还需要进一步的探索。</p><p>在本研究中，我们通过三个案例研究分享了所学到的经验和七个导致失败的关键因素。本文旨在为实践者提供参考，并为 RAG 系统的研究发展指明方向。据我们所知，这是首次就构建鲁棒 RAG 系统面临的挑战提供实证分析。随着大语言模型（LLMs）技术的不断进步，软件工程领域的专家们需要负起责任，分享如何构建基于 LLMs 的鲁棒系统的知识。这项工作对于提升 RAG 系统的鲁棒性来说，是一个重要的进展。</p><p>本项研究的主要问题包括：</p><ul><li><p>在构建 RAG 系统时，我们会遇到哪些失败的环节？(第5节) 为了探究这些潜在的失败环节，我们以 BioASQ 数据集为基础开展了一项实证研究。该实验包含了15,000篇文档和1,000组问题与答案。我们首先对所有文档建立索引，随后利用 GPT-4 运行查询并记录生成的答案。接下来，我们用 OpenAI 的评估工具对所有问题与答案进行了验证。我们对所有出现差异的案例、被标记为错误的案例以及随机选取的标记为正确的案例进行了手动审查，以此来分析并识别出现问题的模式。</p></li><li><p>当我们要构建一个 RAG 系统时，有哪些关键因素需要我们仔细考虑呢？在这里，我们将分享从三个 RAG 系统实施案例中吸取的宝贵经验。这些案例不仅展示了我们在实施过程中遇到的挑战，也揭示了我们从中获取的深刻洞察。</p></li></ul><p>这项研究带来的主要贡献包括：</p><ul><li>我们罗列了 RAG 系统中可能出现的各种失败点 (FP)。</li><li>我们分享了三个 RAG 系统实施案例的实践经验，其中两个案例的系统现正于 Deakin 大学运行。</li><li>我们根据从三个案例研究中吸取的经验，为 RAG 系统的研究指明了一条新的道路。</li></ul><h2 id="Related-Work">Related Work</h2><p>RAG是指在预训练和推理阶段，利用文档来提升大语言模型的性能。但是，要知道，训练这样的模型需要大量的计算资源、数据准备时间，因此，如果能直接使用未经训练或微调的 RAG，无疑是一种极具吸引力的方案。然而，当我们试图使用大语言模型来提取信息时，便会遭遇一些挑战，比如处理长篇文本的性能问题。</p><p>最近的一项调查显示，大语言模型在 RAG 流程中被广泛应用，包括检索器、数据生成、重写器和阅读器。我们的研究从软件工程的角度出发，旨在深入探讨工程师在实践中可能遇到的问题，以及为了实现当前最先进的 RAG 系统，需要进行哪些软件工程的研究。</p><p>近期有研究对 RAG 系统进行了基准测试，但并未关注在实施过程中可能出现的问题。软件工程研究已经探讨了 RAG 系统在代码相关任务中的应用。然而，RAG 系统的应用范围远超软件工程任务。本文从实践者的角度出发，补充了现有的研究，揭示了在实施 RAG 系统过程中可能遇到的挑战。</p><p>RAG 系统中产生的错误和失败与其他信息检索系统有许多相同之处，如 1) 缺乏查询重写的评价标准，2) 文档的重新排名，以及 3) 高效的内容概括。这些问题，我们的研究结果已经证实。而与大语言模型的语义和生成特性相关的部分，如评估事实准确性，便是 RAG 系统所独有的挑战。</p><h2 id="Retrieval-Augmented-Generation">Retrieval Augmented Generation</h2><p>随着 ChatGPT、Claude 和 Bard 等大语言模型服务的广泛应用，人们开始探索将它们作为问答系统的可能性。虽然这些系统的表现令人瞩目，但也存在两个根本性的问题：1) &quot;幻觉&quot;问题 —— 即大语言模型生成的答案看似正确，实则错误；2) &quot;无法控制&quot;问题 —— 除了通过精心设计的提示，我们无法直接指导或修改模型的输出内容。为了解决这些问题，人们设计了 RAG 系统，这是一种信息检索方法，旨在克服直接使用大语言模型所带来的限制。</p><p>RAG 的工作方式是，首先将用自然语言表达的查询问题转化为嵌入，以在大量文档中进行语义搜索。在找到相关的文档后，这些文档会被送到一个大语言模型中，由模型生成答案。如 图1 所示，RAG 系统主要包含两个步骤：一是建立索引，二是进行查询。更多的细节可以参考相关的研究调查报告。</p><p><img src="//s3.mindex.xyz/blog/Theses/7822f2a103869fb54aa6f83968687c27.png" alt="图1：创建一个检索增强生成（RAG）系统，需要进行索引和查询两个步骤。通常情况下，索引步骤在系统开发阶段完成，而查询步骤则在系统实际运行时进行。在我们的研究中，我们找到的可能导致系统失败的环节，都在图表中用红色框进行了标注。同时，所有必须完成的步骤，也都在图表中用下划线进行了标识。"></p><h3 id="Index-Process">Index Process</h3><p>在 RAG 系统中，我们采用一种称为 “嵌入” 的技术来帮助检索系统工作。“嵌入” 是一种压缩了的文档语义表示方式，可以想象成是一个由数字组成的向量。在建立索引的过程中，我们会把每个文档切分成更小的片段，然后用一个特殊的模型将这些片段转化成 “嵌入”。这些原始的片段和它们对应的 “嵌入” 会被一起存储在数据库中。在这个过程中，软件工程师需要做出一些设计决策，比如如何合理地切分文档，以及每个片段应该有多大。如果切分的片段太小，某些问题可能就无法得到完整的答案；而如果片段太大，那么生成的答案可能会包含一些无关的信息。</p><p>不同类型的文档在处理和分块策略上有不同的需求。例如，对于视频内容，我们需要一个转录系统来提取音频并在编码前将其转换为文本（详见 <a href="#Cognitive-Reviewer">Cognitive Reviewer</a> ）。此外，选择何种嵌入方式也至关重要，因为更改嵌入策略需要重新对所有分块进行索引。在选择嵌入方式时，我们应根据其在语义上检索正确答案的能力来决定。这个过程会受到分块大小、预期的问题类型、内容的结构以及应用领域的影响。</p><h3 id="Query-Process">Query Process</h3><p>查询过程是在实时运行中进行的。首先，我们将自然语言形式的问题转化为一般性的查询。为了让这个查询更具普遍性，我们使用了大语言模型，这使得我们可以在新的查询中加入更多的上下文信息，比如之前的聊天历史。然后，我们根据新的查询计算出一个嵌入，用于在数据库中寻找相关的文档。我们会使用如余弦相似度这样的相似性方法来检索最相似的 top k 个文档（向量数据库有一些技术，如倒排索引，可以加速检索过程）。直观来说，与查询在语义上更接近的块更有可能包含我们需要的答案。</p><p>检索到的文档将被重新排序，以便让含有答案的文档块尽可能地排在前面。接下来的阶段是“整合器”（Consolidator），它负责处理这些文档块。这个步骤的存在是为了解决大语言模型面临的两个主要限制：1）Token 的数量限制；2）处理速度的限制。像 OpenAI 这样的服务会对输入的文本量设定一个上限。这就限制了我们可以用于提取答案的文档块的数量，因此我们需要一个策略来精简并链接这些文档块，以便从中获取答案。这些在线服务还会限制在一定时间内可以使用的 Token 数量，这就限制了系统的响应速度。因此，软件工程师在设计 RAG 系统时需要考虑这些权衡。</p><p>在 RAG 流程的最后阶段，答案会从生成的文本中被提取出来。在这个阶段，我们需要从输入的问题中筛选出有用的信息，同时遵循一些特定的格式要求，比如把答案列成一个选项列表，然后生成最后的输出结果。要实现 RAG 系统，我们需要设计多种不同的问题和答案处理方式。这样做可以确保我们能得到和特定领域相关的问题。通过使用 LLM 从文本中实时提取答案，我们可以开发出一些新的应用领域，比如实时的问题回答系统。不过，RAG 系统的测试是非常困难的，因为我们没有现成的数据可以用来测试。我们只能通过生成一些模拟的数据，或者先行试运行系统来进行实验性的测试。</p><h2 id="Case-Studies">Case Studies</h2><p>本研究通过三个案例研究，探讨了在 RAG 系统的实施过程中可能遇到的挑战。表 1 展示了每个案例研究的概述。BioASQ 案例研究的所有脚本、数据，以及每个失败环节的示例，都已在网上公开。由于涉及到保密问题，另外两个案例研究并未包含在内。</p><p><img src="//s3.mindex.xyz/blog/Theses/920285f4374640c3cea4bf404a8cdf66.png" alt="表1：这是本文所提到的 RAG 案例研究的概要。"></p><h3 id="Cognitive-Reviewer">Cognitive Reviewer</h3><p>Cognitive Reviewer 是一款 RAG 系统，旨在帮助研究人员分析科学文档。研究人员可以设定研究问题或目标，并上传一系列相关的研究论文。接着，系统会根据设定的目标对所有文档进行排序，供研究人员进行人工审阅。此外，研究人员还可以直接向系统提出关于所有文档的问题。目前，Deakin University 的博士生们正在使用 Cognitive Reviewer 来支持他们的文献综述工作。Cognitive Reviewer 在运行时进行索引处理，并依赖于一个强大的数据处理流程来处理上传的文档，也就是说，在开发阶段无法进行质量控制。此系统还采用了一种排名算法来对上传的文档进行排序。</p><h3 id="AI-Tutor">AI Tutor</h3><p>AI 导师是一个 RAG 系统，学生可以向系统提出关于课程的问题，答案则基于学习资料。学生可以通过查看答案来源的列表来核实答案。AI 导师通过整合到 Deakin 大学的学习管理系统，对包括 PDF 文档、视频和文本文件在内的所有内容进行编码和索引。在这个编码和索引的过程中，我们使用深度学习模型 Whisper 对视频进行转录，然后将其分解成可管理的部分。AI 导师是在 2023 年 8 月到 11 月期间开发的，用于一个在 2023 年 10 月 30 日开始的拥有 200 名学生的课程试点项目。我们的目标是分享实施过程中的经验教训，并在试点项目结束时分享后续的发现。这个 RAG 流程包括一种可以简化用户查询的重写功能。我们设计了一个聊天界面，其中用户和 AI 导师之间之前的对话被用作每个问题的上下文。重写功能会考虑这种上下文，重新构造用户的查询，以解决像 “请进一步解释这个概念” 这样的模糊请求。</p><h3 id="Biomedical-Question-and-Answer">Biomedical Question and Answer</h3><p>在之前的案例中，我们主要研究的是内容规模较小的文件。为了进一步探索大规模数据的问题，我们使用了 BioASQ 数据集，构建了一个 RAG 系统。BioASQ 数据集由生物医学专家编制，包含了问题、相关文档链接和答案，答案的形式可能是yes/no、文本摘要、事实或者列表。我们从这个数据集中下载了 4017 篇开放获取的文档，并提出了 1000 个问题。所有的文档都经过了索引处理，并在 RAG 系统中进行了问题提问。接着，我们运用 OpenAI 实现的 OpenEvals 技术对生成的问题进行了评估。在所有生成的问题中，我们手动审查了 40 个问题，以及所有被 OpenEvals 标记为不准确的问题。我们发现，在这个领域，自动评估的结果通常比人类评估者更为保守。但是，需要注意的是，BioASQ 是一个特定领域的数据集，而进行评审的并非专家。也就是说，大语言模型可能在某些方面比非专家更有见解。</p><h2 id="Failure-Points-of-RAG-Systems">Failure Points of RAG Systems</h2><p>通过我们的案例研究，我们发现了一系列即将在下文中详述的问题。接下来的部分，我们将探讨这样一个研究问题：在构建 RAG 系统过程中，都有哪些可能导致失败的环节？</p><ul><li><p><strong>Missing Content</strong> 首个问题出现在，当我们提出一个无法从现有文档中找到答案的问题时。在最好的情况下，RAG 系统会回应：“对不起，我无法回答这个问题。”然而，对于那些与内容相关，但是并没有明确答案的问题，系统可能会被误导，产生错误的回答。</p></li><li><p><strong>Missed the Top Ranked Documents</strong>  问题的答案其实在文档中，但由于排名不够高，没有被返回给用户。理论上，系统会对所有文档进行排名，然后在后续步骤中使用。但实际上，系统只会返回排名 top k 的文档，其中 k 是基于性能选择的一个值。</p></li><li><p><strong>Not in Context - Consolidation strategy Limitations</strong> 虽然包含答案的文档已经从数据库中检出，但却未能被纳入用于生成答案的上下文中。这种情况通常发生在数据库返回大量文档，并进行了整合处理以提取答案的情况下</p></li><li><p><strong>Not Extracted</strong> 虽然答案确实存在于上下文中，但大语言模型却未能抽取出正确的答案。这种情况通常发生在上下文中存在过多的干扰信息或者信息之间存在矛盾的时候。</p></li><li><p><strong>Wrong Format</strong> 问题需要以特定的格式（如表格或列表）提取信息，但大语言模型并未按照这个要求执行。</p></li><li><p><strong>Incorrect Specificity</strong> 虽然用户可以从响应中获取答案，但答案可能过于笼统或者过于详细，无法满足用户的实际需求。这种情况通常出现在 RAG 系统的设计者对某个问题有特定的预期结果，比如教师对学生的期望。在这种情况下，我们需要提供的不仅仅是答案，还应包含具体的教育内容。另外，当用户不清楚如何准确提问，或者提问过于宽泛时，也可能导致返回的答案过于模糊或过于详细。</p></li><li><p><strong>Incomplete</strong> 虽然不完整的答案并不算是错误，但却可能遗漏了一些原本可以从上下文中获取的信息。比如，如果一个问题是“文档 A、B 和 C 中都涵盖了哪些关键点？”，这种情况下，将问题分开来逐一提问可能会是一个更好的策略。</p></li></ul><h2 id="Lessons-and-Future-Research-Directions">Lessons and Future Research Directions</h2><p><img src="//s3.mindex.xyz/blog/Theses/18513d54285f06b15a9a5d8fb6b3e3cb.png" alt="表2："></p><p>我们从三个案例研究中学到的教训已在 表2 中列出。对于研究问题&quot;在构建 RAG 系统时，有哪些关键考虑因素？&quot;，我们的发现如下：根据我们的总结，我们找到了几个与 RAG 有关的潜在研究领域，具体如下：</p><h3 id="Chunking-and-Embeddings">Chunking and Embeddings</h3><p>文档分块看似简单，然而分块的质量以多种方式影响检索过程，尤其是通过影响块的嵌入，进而影响块与用户查询的相似性和匹配。有两种分块的方式：一种是基于启发式的分块（通过使用标点符号，段落结束等方式），另一种是语义分块（利用文本中的语义信息来确定块的开始和结束）。进一步的研究应探讨这两种方法之间的权衡，以及它们对关键下游过程，如嵌入和相似性匹配的影响。一个系统性的评估框架，对分块技术在诸如查询相关性和检索准确性等指标上的效果进行比较，将对这个领域有所贡献。</p><p>嵌入是另一个热门的研究领域，包括为多媒体和多模态块（如表格、图形、公式等）生成嵌入。通常在系统开发过程中或新文档被索引时，会创建一次块嵌入。查询预处理在很大程度上影响了 RAG 系统的性能，尤其是在处理负面或模糊查询时。我们需要进一步研究架构模式和方法，以应对嵌入的固有限制（匹配质量是领域特定的）。</p><h3 id="RAG-vs-Finetuning">RAG vs Finetuning</h3><p>大语言模型（LLMs）因其大量的训练数据和在发布前对模型进行的微调，被视为优秀的全球模型。但是，这些模型是通用的（可能并不了解你特定领域的具体知识），并且知识库并不是最新的（存在知识截止日期）。微调和 RAG 提供了两种可能的定制方式，每种方式都有其独特的权衡。微调需要收集内部数据集来调整和训练大语言模型。然而，你所有的数据都会被集成到模型中，你需要解决安全/隐私问题（谁能访问什么）。此外，随着基础模型本身的改进或者你获得新的数据添加到模型中，你需要再次进行微调。另一方面，RAG 系统似乎提供了一个实用的解决方案，允许你根据需要划分你的数据，并只把相关的数据片段纳入到上下文中，让大语言模型从这些上下文中生成答案。这方便了用新的文档持续更新知识，并且也给了用户对哪些数据片段可访问的控制权。然而，对于数据片段的嵌入、检索和上下文融合的最优策略，仍然是研究的热点。未来的研究应系统地比较微调和 RAG 的各种因素，包括准确性、延迟、运行成本和鲁棒性。</p><h3 id="Testing-and-Monitoring-RAG-systems">Testing and Monitoring RAG systems</h3><p>对于 RAG 系统，其软件工程的最佳实践仍在探索阶段。软件测试和测试用例的生成是其中需要进一步优化的领域。RAG 系统需要的问题和答案通常是特定于应用的，在对非结构化文档进行索引时，这些问题和答案往往无法直接获取。目前有一些新的研究尝试使用大语言模型从多个文档中生成问题。然而，如何生成与特定领域相关的、符合实际情况的问题和答案，这仍然是一个未解决的问题。</p><p>一旦获得了合适的测试数据，我们还需要质量度量标准来帮助工程师进行质量取舍。使用大语言模型的成本高昂，同时也带来了延迟问题，每次新版本的发布都会改变其性能特性。这种特性在机器学习系统中已经被研究过，但是针对基于大语言模型的系统（如RAGs）所需的适应性策略（如果有的话）尚未实施。另一种思路是将自适应系统的理念融入到 RAG 系统的监控和调整中，其他机器学习应用的初步工作已经开始尝试这种方法。</p><h2 id="CONCLUSION">CONCLUSION</h2><p>RAG 系统是一种革新性的信息检索技术，它巧妙地运用了大语言模型（LLM）。现在，软件工程师越来越多地通过实施语义搜索或参与新的代码相关任务，来与 RAG 系统进行互动。本文分享了我们在进行三个案例研究的过程中，包括对15000份文档和1000个问题的实证研究，所得到的宝贵经验与发现。这些发现为实践者提供了实施 RAG 系统时可能面临的挑战，为他们指明了方向。我们还对 RAG 系统的未来研究方向进行了探讨，包括：1) 如何进行分块和嵌入，2) RAG 与微调的关系，以及 3) 如何进行测试和监控。随着研究的深入，大语言模型将会拥有更多对工程师和研究人员有价值的新功能。本文是首次从软件工程的角度对 RAG 系统进行深入的探讨。</p><h2 id="Source">Source</h2><p><a href="https://arxiv.org/abs/2401.05856">Seven Failure Points When Engineering a Retrieval Augmented Generation System</a></p>]]></content>
    
    <summary type="html">
    
      Retrieval Augmented Generation System.
    
    </summary>
    
    
      <category term="Theses" scheme="https://neo1989.net/categories/Theses/"/>
    
    
      <category term="Coder" scheme="https://neo1989.net/tags/Coder/"/>
    
      <category term="AI" scheme="https://neo1989.net/tags/AI/"/>
    
      <category term="RAG" scheme="https://neo1989.net/tags/RAG/"/>
    
  </entry>
  
  <entry>
    <title>必读论文 · Attention Is All You Need (2017)</title>
    <link href="https://neo1989.net/Theses/THESIS-Attention-is-All-You-Need/"/>
    <id>https://neo1989.net/Theses/THESIS-Attention-is-All-You-Need/</id>
    <published>2024-02-26T09:11:53.000Z</published>
    <updated>2024-02-28T04:25:03.166Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract">Abstract</h2><p>主流的序列转换模型都建立在复杂的循环神经网络或卷积神经网络之上，它们都包含编码器和解码器。而且，最优秀的模型还会通过注意力机制（attention mechanism）将编码器和解码器连接起来。我们提出了一种新的网络架构——Transformer，它完全依赖于注意力机制，而不再需要复杂的循环和卷积过程。在两项机器翻译任务的实验中，这种模型在质量上表现出色，同时具有更高的并行性，训练时间也大大缩短。在WMT 2014年的英德翻译任务中，我们的模型达到了28.4的<a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a>分数，比现有的最好成绩（包括集成模型）提高了2个以上的BLEU分数。在WMT 2014年的英法翻译任务中，我们的模型在八个GPU上训练3.5天后，创造了41.8的SOTA BLEU新纪录，这只是最好模型训练成本的一小部分。我们还证明，无论是在大规模训练数据还是有限训练数据的情况下，Transformer都能成功应用于英语句法解析任务，从而证明了其良好的泛化性能。</p><h2 id="Introduction">Introduction</h2><p>循环神经网络，尤其是长短期记忆（Long Short-Term Memory）和门控循环神经网络（Gated Recurrent Neural Networks），在序列建模和转换问题上已经成为SOTA方法，这些问题包括语言建模和机器翻译。自那时起，大量的研究工作不断尝试突破循环语言模型和编码-解码架构的技术限制。</p><p>循环模型通常会根据输入和输出序列中的符号位置进行计算。它们会生成一系列的隐藏状态 $h_t$ ，这个状态是由前一状态 $h_{t-1}$ 和当前位置 $t$ 的输入共同决定的。这种固有的顺序性使得在单个训练样例中进行并行化变得不可能，这在处理长序列时尤其关键，因为内存限制使得无法在多个样例间进行批处理。最近的研究通过使用分解技巧和条件计算，不仅大大提升了计算效率，而且在后者的情况下，模型的性能也得到了提升。然而，顺序计算的基本限制仍然无法被克服。</p><p>注意力机制已经成为各种任务中序列建模和转导模型的关键部分，它可以在不考虑输入或输出序列中的距离的情况下，模拟出数据间的依赖关系。然而，除少数情况外，这种注意力机制通常都是与循环网络一起使用的。</p><p>在这项工作中，我们提出了 Transformer，这是一种新的模型架构，它不再依赖循环网络，而是完全依赖于注意力机制来处理输入和输出之间的全局依赖关系。Transformer 允许更高效的并行处理，只需在八个 P100 GPU 上训练短短十二小时，就能达到前所未有的翻译质量。</p><h2 id="Background">Background</h2><p>‘Extended Neural GPU’，‘ByteNet’ 和 ‘ConvS2S’ 都秉承了减少顺序计算的设计理念，它们都采用卷积神经网络作为基础模块，能够并行处理所有输入和输出的隐藏表示。然而，在这些模型中，如果想要建立两个任意输入或输出位置之间的关系，所需的计算步骤会随着位置间距离的增加而增加，‘ConvS2S’ 是线性增长，而 ‘ByteNet’ 则是对数增长。这使得模型在学习远距离位置间的关系时面临更大的困难。相比之下，Transformer 将这个问题简化为固定数量的操作，尽管这样做会因为平均注意力加权位置而降低有效的分辨率，但我们在第3.2节中介绍的多头注意力机制可以有效地解决这个问题。</p><p>自注意力，有时也被称为内部注意力，是一种将单一序列中不同位置的信息进行关联，以此来计算出序列的表征的注意力机制。自注意力已经在许多任务中取得了成功，这些任务包括理解阅读内容、进行抽象的总结、理解文本的内在含义，以及学习与具体任务无关的句子表征。</p><p>端到端记忆网络是基于循环注意力机制构建的，而不是依赖于序列对齐的循环机制。这种网络已经在简洁语言的问题回答和语言模型构建任务上展现出了优秀的性能。</p><p>据我们所知，Transformer 是首个完全依赖自注意力来计算其输入和输出表示的转换模型，它并未使用任何序列对齐的 RNN 或卷积。在接下来的部分，我们将详细介绍 Transformer，阐述自注意力的重要性，并探讨它相较于 ‘ICLR (2016)’，‘Neural machine translation in linear time (2017)’ 和 ‘Convolutional seq2seq learning (2017)’ 等模型的优势。</p><h2 id="Model-Architecture">Model Architecture</h2><p>大部分具有竞争力的神经序列转换模型都采用了编码器-解码器的结构。在此结构中，编码器将一个符号表示的输入序列 $(x_1, …, x_n)$ 映射到一个连续表示的序列 $z = (z_1, …, z_n)$。给定 $z$，解码器便逐个生成输出序列 $y = (y_1, …, y_n)$ 的符号。在每一步中，模型都是自回归的，即在生成下一个符号时，会利用之前生成的符号作为额外的输入。</p><p>Transformer 模型采用了如 图1 所示的结构，其中编码器和解码器部分都采用了堆叠的自注意力机制和逐点的全连接层。</p><p><img src="//s3.mindex.xyz/blog/Theses/d64b985edbb3a6d5a521cda18f3ab35f.png" alt="图1：Transformer - 模型架构。"></p><h3 id="Encoder-and-Decoder-Stacks">Encoder and Decoder Stacks</h3><p><strong>Encoder</strong>: 编码器由 $N = 6$ 个完全相同的层组成。每一层都由两个子层构成：第一个子层是多头自注意力机制，第二个子层是简单的位置相关的全连接前馈网络。我们采用了一种设计，即每个子层的输出都会与其输入进行残差连接，然后进行层归一化处理，即 $LayerNorm(x + Sublayer(x))$，其中 $Sublayer(x)$ 是子层自身的功能。为了实现这种残差连接，模型中所有的子层以及嵌入层都会输出维度为 $d_{model} = 512$ 的结果。</p><p><strong>Decoder</strong>: 解码器的构造与编码器类似，也是由 6 个完全相同的层组成。但在每一层中，解码器除了拥有编码器的两个子层外，还增加了第三个子层，这个子层的作用是对编码器所有层的输出进行多头自注意力处理。就像编码器一样，我们在每个子层的输入和输出之间添加了残差连接，并进行层归一化处理。为了防止解码器的自注意力子层处理时，后面的位置能看到前面的信息，我们对其进行了修改。通过这种方式，加上输出嵌入向后偏移一个位置，我们可以确保在预测第 $i$ 个位置的输出时，只能使用位置 $i$ 之前的已知输出。</p><h3 id="Attention">Attention</h3><p>注意力函数可以理解为，它接收一个查询和一组键值对，然后生成一个输出结果。这个查询、键、值以及输出结果都可以被视为向量。输出结果实际上是值向量的加权和，而每个值的权重则是由查询和相应键的匹配程度决定的。</p><p><img src="//s3.mindex.xyz/blog/Theses/77f1cfcd5ed58276e8d605972e6ce520.png" alt="图2：（左图）缩放的点积注意力；（右图）多头注意力，有多个并行运行的注意力层构成"></p><h4 id="Scaled-Dot-Product-Attention">Scaled Dot-Product Attention</h4><p>我们将这种特定的注意力机制称为“缩放点积注意力”（见 图2）。输入由维度为 $d_k$ 的查询项（queries）和键（keys），以及维度为 $d_v$ 的数值（values）组成。我们首先计算各query与所有keys的点积，然后各自除以 $\sqrt{d_k}$，最后通过 softmax 函数得出各个数值的权重。</p><p>在实际应用中，我们会同时对一组查询进行注意力函数的计算，这些查询被整合成一个矩阵 Q。同样，键和值也被整合成矩阵 K 和 V。我们按照以下方式计算得出输出矩阵：<br>$$<br>Atteention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}}) V<br>$$</p><p>最常用的两种注意力机制是加性注意力和点积（乘性）注意力。点积注意力与我们所使用的算法几乎一样，只不过有一个 $\frac{1}{\sqrt{d_k}}$ 的缩放因子。加性注意力则是通过一个单隐藏层的前馈网络来计算相似度函数。虽然这两种方法在理论上的复杂度差不多，但在实际应用中，<strong>点积注意力因为能够利用高度优化的矩阵乘法代码，所以运行速度更快，也更节省存储空间</strong>。</p><p>对于较小的 $d_k$ 值，这两种注意力机制的表现类似，但是当 $d_k$ 值增大时，如果不进行缩放处理，加性注意力的表现会优于点积注意力。我们推测，<strong>对于较大的 $d_k$ 值，点积的结果可能会变得非常大，这会使 $softmax$ 函数进入到梯度极小的区域。为了抵消这种影响，我们将点积的结果乘以 $\frac{1}{\sqrt{d_k}}$ 进行缩放</strong>。</p><h4 id="Multi-Head-Attention">Multi-Head Attention</h4><p>我们发现，直接对 $d_m$ 维的键（keys）、值（values）和查询（queries）进行单一的自注意力（attention）处理不如将它们线性地投影到 $d_k$、$d_k$ 和 $d_v$ 维度更有利。这种线性投影我们会进行 $h$ 次，每次都使用不同的学习到的线性投影。然后，我们在每个投影后的键、值和查询上并行地执行自注意力函数，得到 $d_v$  维的输出值。这些输出值会被连接起来，然后再次投影，得到最终的结果，这个过程在 图2 中有详细的展示。</p><p>多头注意力（Multi-head attention）的设计使模型能够在不同的位置，同时关注不同的信息表示子空间。而如果只使用单一的注意力机制，这种能力就会被平均化操作所抑制。</p><p>$$<br>MultiHead(Q, K, V) = Concat(head_1, …, head_h) W^O \\<br>where \enspace head_i = Attention(QW_{i}^Q, KW_{i}^K, VW_{i}^V)<br>$$</p><p>在这里，所说的投影其实就是参数矩阵。其中 $W_{i}^Q \in \mathbb{R}^{d_{model} \times d_k}$，$W_{i}^K \in \mathbb{R}^{d_{model} \times d_k}$，$W_{i}^V \in \mathbb{R}^{d_{model} \times d_v}$，$W_{i}^O \in \mathbb{R}^{d_{model} \times hd_v}$。</p><p>在我们的研究中，我们采用了 $h = 8$ 个并行的注意力层，也就是我们所说的8个&quot;头&quot;。对于这8个&quot;头&quot;，我们都设定了 $d_k = d_v = \frac{d_{model}}{h} = 64$。由于每个&quot;头&quot;的数据规模缩小了，所以总的计算成本与使用全数据规模的单一注意力层差不多。</p><h4 id="Applications-of-Attention-in-our-Model">Applications of Attention in our Model</h4><p>Transformer 在三种不同的方式中使用了多头注意力：</p><ul><li><p>在“编码器-解码器注意力”层中，查询来自前一个解码器层，而记忆键和值来自编码器的输出。这使得解码器中的每个位置都能关注输入序列中的所有位置。这模仿了序列到序列模型中典型的编码器-解码器注意力机制，如 ‘Google’s neural machine translation system, (2016)’, ‘Neural machine translation by jointly learning to align and translate (2014)’, ‘Convolutional seq2seq learning (2017)’</p></li><li><p>编码器由多个自注意力层组成。在每一个自注意力层里，用于生成注意力分数的键（keys）、值（values）和查询（queries）都源自同一处，即编码器前一层的输出。这样的设计使得编码器当前层的每一个元素都能够接收并处理前一层所有元素的信息。</p></li><li><p>解码器内部的自注意力层同样使得每个位置能够接收到该位置之前所有位置的信息。为了维持解码器的自回归特性，我们必须防止信息从右向左流动。这一目标是通过在缩放点积注意力机制中进行操作实现的：我们会对softmax函数的输入进行遮蔽处理，即将那些不应该被当前位置所接收的信息的权重设置成极小值（负无穷），从而有效地切断了这些不合规则的信息连接。</p></li></ul><h3 id="Position-wise-Feed-Forward-Networks">Position-wise Feed-Forward Networks</h3><p>除了自注意力（Self-attention）子层之外，我们的编码器和解码器的每一层还包括一个独立且对每个位置都相同处理的全连接前馈神经网络。这个网络由两个全连接层（linear transformations）构成，在两层之间使用了ReLU激活函数。</p><p>$$<br>FFN(x) = max(0, xW_1 + b_1)W_2 + b_2<br>$$</p><p>尽管不同位置上的线性变换是一致的，但从一层到另一层，它们会使用不同的参数集。换一种方式来说，就像是使用了卷积核尺寸为 $1$ 的两个卷积操作。模型的输入和输出维度 $d_{model} = 512$，而内部层的维度 $d_{ff} = 2048$。</p><h3 id="Embeddings-and-Softmax">Embeddings and Softmax</h3><p>就像其他的序列转换模型一样，我们利用学习得到的嵌入技术（embeddings）将输入的Token和输出的Token转化为维度为 $d_{model}$ 的向量。我们也采用常规的线性变换学习方法和softmax函数，来把解码器的输出转换成预测下一个Token可能性的概率值。在我们的模型中，我们采用了一个与’Using the output embedding to improve language models (2016)'相似的方法，即在两个嵌入层和softmax之前的线性变换中共享相同的权重矩阵。在嵌入层，我们还会将这些权重与 $\sqrt{d_{model}}$ 相乘。</p><h3 id="Positional-Encoding">Positional Encoding</h3><p>因为我们的模型既不使用递归结构也不使用卷积操作，为了使模型能够理解序列中Token的顺序信息，我们必须提供关于Token在序列中的相对或绝对位置的信息。为了做到这一点，在编码器和解码器的最底层，我们向输入的嵌入数据中添加了“位置编码”。这些位置编码的维度（$d_{model}$）与嵌入数据的维度相同，使得它们可以直接相加。至于位置编码的选择，既有通过学习得到的，也有固定不变的多种方案。</p><p>在这项研究中，我们采用了频率各异的正弦与余弦函数：</p><p>$$<br>PE_{(pos, 2i)} = sin(\frac{pos}{1000^{2i/d_{model}}}) \\<br>PE_{(pos, 2i+1)} = cos(\frac{pos}{1000^{2i/d_{model}}})<br>$$</p><p>在这个公式中，$pos$ 表示序列中的位置，$i$ 代表维度。 换句话说，位置编码的每个维度都对应域一个正弦波形。这些波形的波长按几何数级递增，范围 从 $2\pi$ 到 $10000 \cdot 2\pi$。我们选择这种函数是基于一个假设：它能够让模型轻松地根据 Token 之间的相对位置进行自注意力学习。因为无论偏移量 k 如何变化，位置编码 $PE_{pos+k}$ 都能够用位置编码 $PE_{pos}$ 的线性组合来表示。这样一来，模型就能够通过简单的数学变换来识别和处理序列中 Token 的位置关系。</p><p>我们还试验了采用学习型的位置嵌入（learned positional embeddings）方法，结果显示两种方法得出的成果相差无几（参见 表3 第（E）行）。我们选择了基于正弦波的方法，因为这可能使模型能够处理超出训练时序列长度的数据。</p><h2 id="Why-Self-Attention">Why Self-Attention</h2><p>在这一部分，我们将自注意力层与循环层和卷积层进行了比较。这些层通常用于处理符号表示的变长序列（$x_1$, …, $x_n$）到另一个等长序列（$z_1$, …, $z_n$）的映射问题，其中 $x_i, z_i \in \mathbb{R}^d$ 空间中的向量，比如这样的映射在典型的序列转换编码器或解码器的隐藏层中非常常见。我们选择使用自注意力的动机是基于三个我们所期望的特性。</p><p>在考量每一层的运算效率时，我们首先要评估的是该层的总体计算复杂度。 其次，我们会考察计算任务中可以并行处理的部分，这部分的大小可以通过必须顺序执行的操作次数来衡量。</p><p>第三个考量因素是网络内部处理长程数据依赖时信号传递的路径长度。在众多序列转换任务中，学习这种长程依赖关系是一个核心挑战。能否有效学习这种依赖关系，关键在于信号在网络中传递的路径有多长，无论是前向传递还是后向传递。简而言之，输入与输出序列之间任意两点的路径越短，网络学习长程依赖就越容易。因此，我们也对比了由不同类型的层构成的网络中，任意两个输入和输出位置之间的最大路径长度。</p><p><img src="//s3.mindex.xyz/blog/Theses/84163f518d756c1a1ca877da25396d5b.png" alt="表1：对于不同类型的层，其最大路径长度、每个层的复杂度以及最小序列操作数量各不相同。这里，n 代表序列的长度，d 代表特征维度，k 是卷积核的大小，而 r 则是自注意力限制区域的大小。"></p><p>如 表1 所展示的，自注意力层能够通过一系列固定数量的操作，将所有位置相互连接起来，相比之下，递归层（recurrent layer）则需要 $O(n)$ 次操作。在计算复杂度上，自注意力层在序列长度 $n$ 小于其表示空间的维度 $d$ 的情况下，比递归层更为高效，而这种情况在当前机器翻译中的 SOTA 模型所使用的句子表示，如 <strong>word-piece</strong> 和 <strong>byte-pair</strong> 表示法中非常普遍。为了在处理极长序列的任务时提高计算效率，自注意力可以被限制在仅考虑输入序列中，围绕各自输出位置的大小为 $r$ 的局部邻域内。这种做法会导致最大路径长度变为 $O(n/r)$ 。我们计划在未来的研究中进一步探索这一方法。</p><p>在我们的模型中，单层卷积网络由于核宽度 $k$ 小于序列长度 $n$，不能直接将每个输入位置与输出位置完全连接起来。如果使用连续的核，要实现完全连接需要叠加大约 $n/k$ 层卷积网络；而采用膨胀卷积的话，大约需要 $log_k(n)$ 层。这样会使得网络内任意两点间的最长路径长度增加。一般来说，卷积层的计算成本比循环层要高，大概高出 $k$ 倍。不过，采用可分离卷积可以大幅降低计算复杂度，降至 $O(k · n · d + n · d^2)$。即便核宽度 $k$ 等于 n，可分离卷积的计算复杂度也仅相当于自注意力层和点对点前馈网络层相结合的复杂度，这正是我们模型所采用的策略。</p><p>另外，自注意力还有一个额外好处，那就是能够促成模型的可解释性更强。我们对模型中的注意力分布进行了详细检查，并在附录中展示并讨论了若干例子。我们发现，不仅单独的注意力头确实学会了执行不同的任务，而且许多注意力头的行为似乎还与句子的句法和语义结构密切相关。</p><h2 id="Training">Training</h2><p>本节将详细介绍我们的模型训练方案。</p><h3 id="Training-Data-and-Batching">Training Data and Batching</h3><p>我们使用了包含约450万个句子对的标准 ‘WMT 2014 English-German’ 数据集进行模型训练。这些句子通过字节对编码（byte-pair encoding）方法进行处理，形成了一个大约含有37000个 Token 的共用词汇表，用于源语言和目标语言。在英语-法语的训练中，我们采用了规模更大的 ‘WMT 2014 English-French’ 数据集，它包含了3600万句子，并且使用了包含32000个词片（word-piece）的词汇表来分割 Token。为了提高训练效率，我们按照句子的大致长度将它们分组打包，每个训练批次都包含了一组句子对，这些句子对总共大约包含25000个源语言 Token 和25000个目标语言 Token。</p><h3 id="Hardware-and-Schedule">Hardware and Schedule</h3><p>我们在一台搭载了8块 NVIDIA P100 GPUs 的计算机上对模型进行了训练。基础模型采用论文中详述的超参数，每个训练步骤耗时约0.4秒。基础模型总共训练了100,000步，持续了12小时。至于我们的大型模型（详见 表3 最后一行），每步训练时间为1.0秒。这些大型模型训练了300,000步，用时3.5天。</p><h3 id="Optimizer">Optimizer</h3><p>我们选用了 Adam 优化器，并设置参数 $β_1 = 0.9, β_2 = 0.98$ 以及 $ε = 10^{-9}$。在整个训练过程中，我们按照特定的公式调整了学习率</p><p>$$<br>l_{rate} =  d_{model}^{-0.5} \cdot min(step\_num^{-0.5}, step\_num \cdot warmup\_steps^{-1.5})<br>$$</p><p>这意味着在训练的最初阶段（前 4000 步），我们会逐步增加学习速率，之后则根据训练步数增长的平方根逐渐减慢增速。这里的“逐步增加”是指学习速率会按照一个固定的规律线性上升，而“逐渐减慢增速”则是随着步数的增加，增加的幅度会越来越小。</p><h3 id="Regularization">Regularization</h3><p>在训练过程中，我们使用了三种不同的正则化手段来防止模型过拟合：</p><p><strong>Residual Dropout</strong>  在将每个子层的输出与其输入相加并进行规范化处理之前，我们会使用 Dropout 技术。此外，在编解码器的嵌入向量和位置编码相加的部分，我们也采用了 Dropout。对于基础模型，我们设置的 $P_{dropout} = 0.1$。</p><p><strong>Label Smoothing</strong> 在训练过程中，我们使用了$ε_{ls} = 0.1$的标签平滑技术。尽管这样做会增加模型的预测困难度（即提高了困惑度），使得模型的预测更加保守，但它实际上提升了模型的准确率和BLEU评分。</p><h2 id="Result">Result</h2><h3 id="Machine-Translation">Machine Translation</h3><p><img src="//s3.mindex.xyz/blog/Theses/3d4e0e9e97745a2a482c9d4068d2cc63.png" alt="表2：在将英语翻译成德语和法语的 newstest2014 测试中，Transformer 模型的表现超越了以往最先进的模型，取得了更高的 BLEU 评分，而且所需的训练成本仅为过去模型的一小部分。"></p><p>在WMT 2014的英德翻译任务上，我们的大型Transformer模型（在表2中标记为Transformer (big)）的性能超越了此前所有公布过的最好模型（包括那些集成模型），其BLEU评分高达28.4，刷新了此前的最佳成绩。该模型的具体配置详见 表3 的最后一栏。该模型的训练仅用了8个P100 GPU花费了3.5天。甚至我们的基础版模型也超越了所有先前公布的模型，而且训练成本远低于其他任何有竞争力的模型。</p><p><img src="//s3.mindex.xyz/blog/Theses/8cdbbb740de70e749ed7562ec46484d6.png" alt="表3：Transformer 模型的不同版本在英德翻译的开发测试集 newstest2013 上的表现各有差异。未列出的值与基础模型相同。所有的性能指标都是针对这个特定的测试集。我们根据字节对编码（Byte-Pair Encoding, BPE）计算的困惑度是基于pre_wordpiece，因此与通常基于单词计算的困惑度不同，不应直接比较二者。"></p><p>在 WMT 2014 的英法翻译任务中，我们的大型 Transformer 模型取得了 41.0 的 BLEU 分数，不仅超过了此前所有公开的单模型记录，而且其训练成本还不足先进模型的四分之一。这个专为英法翻译训练的 Transformer（大型）模型，采用了 $P_{dropout} = 0.1$，相较于常规的 0.3 有所降低。</p><p>在基础模型的训练中，我们采用了一个特殊的方法：将最后 5 次保存的模型参数（每 10 分钟保存一次）进行平均，以此得到最终的单一模型。而对于大型模型，我们则平均了最后 20 次的保存点。在模型推理时，我们使用了大小为 4 的 beam search 技术，并设置了序列长度惩罚因子（$α = 0.6$），这些超参数都是在开发数据集上通过多次试验确定的。此外，我们把模型生成文本的最大长度限制在 $输入文本长度 + 50 个词$ 以内，不过如果能够提前得出结论，我们也会尽早结束生成过程。</p><p>表2 汇总了我们的研究成果，并把我们的翻译质量和训练成本与文献中报道的其他模型架构做了对比。我们估计了训练一个模型所需要的浮点运算量，这是通过计算训练时间、使用的 GPU 数目以及每个 GPU 的单精度浮点运算能力的平均值来得出的。</p><h3 id="Model-Variations">Model Variations</h3><p>为了评判 Transformer 各部分的重要性，我们对基础模型进行了多种修改，并在开发集 newstest2013 上测试了这些改动对英译德翻译性能的影响。我们采用了之前章节描述的 Beam Search 策略，但没有进行 checkpoint 的平均处理。相关的结果展示在 表3 中。</p><p>在 表3 的行 (A) 中，我们调整了 Transformer 中的注意力机制的头数 (attention heads) 和对应键 (key) 与值 (value) 的维数，正如<a href="#Multi-Head-Attention">Multi-Head Attention</a> 节所详述，同时确保整体的计算量保持不变。虽然仅使用一个头的注意力机制的翻译质量比最优参数配置低了 0.9 BLEU 分，但过多的头数也会导致翻译质量的降低。</p><p>在表 3 的行（B）中，我们发现当减少了用于计算注意力的关键参数大小 $d_k$  后，模型的性能有所下降。这暗示了评估模型各部分之间的相互关系并非易事，可能需要一个比简单的点乘运算更为复杂的计算方式来提升效果。进一步地，从行（C）和（D）的数据可以看出，一如所料，模型规模越大，其表现通常越好；而且，使用dropout技术能有效防止模型过度学习特定数据的问题。在行（E）中，我们尝试将模型中用于捕捉不同位置信息的正弦波形位置编码替换成了通过学习得到的位置嵌入，结果显示，新模型的表现与原始模型相差无几。</p><h3 id="English-Constituency-Parsing">English Constituency Parsing</h3><p>为了探究 Transformer 是否能够适应其他种类的任务，我们对其在英文成分句法分析（一种分析句子结构的任务）上的表现进行了实验。这项任务具有其独特的挑战性：它要求输出结果具有严格的结构性，并且输出的长度通常会显著超过输入的长度。而且，传统的循环神经网络（RNN）基于序列的模型在数据量不大的情况下，还未能达到最先进（SOTA）的水平。</p><p>我们在Penn Treebank的大约有4万条WSJ数据集上训练了一个有4层且模型维度 $d_{model} = 1024$ 的 Transformer。同时，我们还尝试了半监督学习的方式，利用了大约 1700 万句的高质量语料库，包括 BerkleyParser 语料库。在 ‘WSJ only’ 训练中，我们使用了 16000 个Token的词汇表；而在半监督学习中我们使用了32000个Token的词汇表。</p><p>在开发数据集上，我们只进行了有限的实验来确定 dropout 设置（这包括自注意力和残差连接的设置，详见第 5.4 节）、学习速率和 beam 宽度，所有其他的参数设置都遵循了原先用于英语到德语翻译的基本模型。在模型进行推断时，我们把最大输出长度设定为输入长度加上 300。无论是在只使用WSJ数据集的实验还是在半监督学习的设定中，我们都采用了 21 的 beam 宽度和 0.3 的长度惩罚系数（α）。</p><p>如 表4 所示，尽管我们的模型没有进行特定任务的细致调优，但它的表现出乎意料地出色，其结果超过了除了递归神经网络语法（Recurrent Neural Network Grammar，RNN Grammar）以外的所有以往公布过的模型。</p><p><img src="//s3.mindex.xyz/blog/Theses/84f649a70e83efb38b0934d80efc1adb.png" alt="表4：Transformer 模型在英文成分句法分析方面表现出了良好的适应性和准确度。"></p><p>与基于循环神经网络（RNN）的序列对序列模型不同，Transformer 在只使用包含 4 万句子的华尔街日报（WSJ）训练集进行训练时，其性能甚至超过了 Berkeley-Parser。</p><h2 id="Conclusion">Conclusion</h2><p>在这篇文章中，我们首次介绍了 Transformer 模型，这是一个创新的序列转录模型，它完全依赖于注意力机制（attention mechanisms），用多头自注意力（multi-headed self-attention）技术替代了传统编解码器结构中常用的循环网络层。</p><p>在翻译任务中，Transformer 的训练速度显著快于那些基于循环或卷积层的结构。在 WMT 2014 的英德和英法翻译挑战中，我们的模型都达到了新的行业最高水平（SOTA）。特别是在英德翻译任务中，我们的最佳模型的表现甚至超越了此前所有公开的模型集合。</p><p>我们对注意力机制模型的未来发展前景感到非常期待，并打算将其应用于更多领域。我们的计划是将 Transformer 应用到文本以外的其他类型的数据输入和输出，例如图像、音频和视频，并且研究能够有效处理这些大型数据的局部和有限制的注意力机制。此外，我们还致力于研究如何让内容生成变得更加非线性，这也是我们的研究目标之一。</p><p>我们用来训练和评估模型的代码可以在 <a href="https://github.com/tensorflow/tensor2tensor">github</a> 找到。</p><h2 id="Source">Source</h2><p><a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a></p>]]></content>
    
    <summary type="html">
    
      Transformer.
    
    </summary>
    
    
      <category term="Theses" scheme="https://neo1989.net/categories/Theses/"/>
    
    
      <category term="Coder" scheme="https://neo1989.net/tags/Coder/"/>
    
      <category term="AI" scheme="https://neo1989.net/tags/AI/"/>
    
      <category term="NLP" scheme="https://neo1989.net/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>必读论文 · BERT (2019)</title>
    <link href="https://neo1989.net/Theses/THESIS-bert/"/>
    <id>https://neo1989.net/Theses/THESIS-bert/</id>
    <published>2024-02-22T13:44:02.000Z</published>
    <updated>2024-02-26T09:39:49.614Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract">Abstract</h2><p>我们要介绍的是一种新的语言表示模型，名为 BERT ，一种基于Transformer双向编码表征器。与近期的语言表现模型不同，BERT 的设计目标是从未经标注的文本中预训练深度双向表示（deep bidirectional representations），这意味着它在所有层级上同时考虑左右两侧的上下文信息。因此，只需对预训练的 BERT 模型增加一层输出层进行微调，就能构建出适用于各种任务的SOTA模型，如问题回答和语言推断，而无需对原有结构进行大量的任务相关的改动。</p><p>BERT 的设计理念十分简洁，而且在实践中展现出强大的性能。它在十一个自然语言处理任务中刷新了最佳成绩，这包括将 GLUE 的得分提升到了 80.5%（相较于之前提升了 7.7 个百分点），将 MultiNLI 的准确率提升到 86.7%（相较于之前提升了 4.6%），将 SQuAD v1.1 的问题回答测试 F1 分数提升到 93.2（相较于之前提升了 1.5 点），以及将 SQuAD v2.0 的测试 F1 分数提升到 83.1（相较于之前提升了 5.1 点）</p><h2 id="Introduction">Introduction</h2><p>预训练的语言模型已经被证明在提升许多自然语言处理任务的性能方面具有显著效果。这包括一些句子级别的任务，如自然语言推理和改写，这些任务试图通过深入分析句子来预测它们之间的关系。还有一些是Token级别的任务，如命名实体识别和问题回答，这些任务要求模型能够在Token级别给出精确的输出结果。</p><p>目前，我们有两种策略可以将预训练的语言表示应用到下游任务中：一种是基于特征的方法，另一种是微调方法。基于特征的方法，比如ELMo，会使用一种特别设计的架构，这种架构将预训练的表示作为额外的特征。而微调方法，比如生成预训练Transformer（OpenAI GPT），只引入极少的针对特定任务的参数，并通过对所有预训练参数进行微调来训练下游任务。这两种策略在预训练阶段有着共同的目标，都是通过单向语言模型来学习和掌握通用的语言表达方式。</p><p>我们认为，现有的技术方法限制了预训练模型的潜力，特别是在进行模型微调的过程中。最主要的限制在于，传统的语言模型都是单向的，这就限制了我们在预训练阶段可以选择的架构类型。举个例子，在 OpenAI GPT 中，作者们采用了一种从左到右的架构，其中每个单词（Token）只能在 Transformer 的自注意力（self-attention）层中关注到其前面的单词。对于句子级别的任务，这样的限制并不是最理想的，而且在将微调的方法应用于例如问答这类需要处理单词级别的任务时，这样的限制可能会带来很大的问题，因为在这种情况下，能够融合来自前后两个方向的上下文信息是非常关键的。</p><p>在本论文中，我们提出了一种名为BERT的方法，这是一种基于Transformer的双向编码表示，以此改进了微调方法。BERT采用了一种受Cloze(完形填空)任务启发的预训练策略，称为&quot;掩码语言模型&quot;（MLM），以解决之前提到的单向性问题。在掩码语言模型中，我们会随机遮挡输入中的部分tokens，然后尝试仅根据其上下文来预测这些被遮挡的词的原始词汇id。与传统的自左向右的语言模型预训练不同，MLM能够同时考虑左右两个方向的上下文，这使得我们可以预训练一个深度的双向Transformer。除了掩码语言模型，我们还引入了一种&quot;下一句预测&quot;的任务，以便同时预训练文本对的表示。</p><p>我们的论文主要贡献如下：</p><ul><li><p>我们强调了双向预训练在语言表示中的重要性。与 ‘Radford et al. (2018)’ 采用的单向语言模型预训练不同，BERT 通过使用掩码语言模型来实现深度双向表示的预训练。这与 ‘Peters et al.(2018a)’ 他们通过简单组合独立训练的左向右和右向左的语言模型的方法形成了鲜明对比。</p></li><li><p>我们发现，预训练的表示能够减少对大量精细设计的任务特定架构的依赖。BERT 是首个基于微调的表示模型，它在众多的句子级别和 token 级别的任务上都达到了SOTA性能，超过了许多专为特定任务设计的架构。</p></li><li><p>BERT 提升了十一个 NLP 任务的 SOTA 水平。此<a href="https://github.com/google-research/bert">链接</a>可以找到相关的代码和预训练模型。</p></li></ul><h2 id="Related-Work">Related Work</h2><p>预训练通用语言表达的研究历史悠久，本节我们将简单回顾一下这个领域中最常用的一些方法。</p><h3 id="基于特征无监督的方法">基于特征无监督的方法</h3><p>学习广泛适用的词表征是几十年来的研究热点，涵盖了非神经网络模型和神经网络模型。预训练的词嵌入是现代自然语言处理系统的重要组成部分，它们相比从零开始训练的词嵌入，可以带来显著的性能提升。在预训练词嵌入向量的过程中，我们通常采用了从左到右的语言模型预测目标，以及在上下文中区分正确和错误词汇的目标。</p><p>这些技术已经被扩展应用到更大的语言单位上，如句子或者段落的嵌入表示。在训练句子表示的过程中，以往的研究主要采用了几种方法：一种是通过目标函数对候选的下一句进行排序；另一种是在给定前一句的表示后，从左到右生成下一句的单词；还有一种是利用去噪自动编码器派生的目标函数。</p><p>ELMo及其前身在另一维度上拓展了传统的词嵌入研究。它们从左向右和右向左的语言模型中提取出对上下文敏感的特征。每个Token的上下文表示是由其左向右和右向左的表示拼接而成。ELMo通过将上下文词嵌入与特定任务的架构相结合，成功地提升了一些主要NLP任务（包括问题回答，情感分析，和命名实体识别）的SOTA水平。‘Melamud et al. (2016)’ 提出了一种新的学习上下文表示的方法，他们设计了一个任务，通过长短期记忆网络（LSTMs）来预测左右上下文中的一个词。这种方法在某种程度上与ELMo类似，它们的模型都是基于特征的，而不是深度双向的。‘Fedus et al. (2018)’ 证明使用Cloze任务可以有效地提升文本生成模型的稳定性和鲁棒性。</p><h3 id="基于微调的无监督方法">基于微调的无监督方法</h3><p>就像基于特征的方法一样，这个方向的初步工作只是从未标记的文本中预训练了词嵌入参数。</p><p>近期，一种新型的句子或文档编码器开始受到关注，它能生成具有上下文信息的 Token 表示，并且这种编码器可以通过无标签的文本进行预训练，然后在有监督的下游任务中进行微调。这种方法的优点在于，我们只需要学习少量的参数。正是因为这个优势，OpenAI 的 GPT 在 GLUE 基准的许多句子级任务中创下了前所未有的 SOTA 成果。而且，从左到右的语言建模和自动编码器等目标已经被用于这种模型的预训练。</p><h3 id="从有监督数据中进行迁移学习">从有监督数据中进行迁移学习</h3><p>一些研究已经证明，从大规模数据集的监督任务，如自然语言推理和机器翻译，进行迁移学习是有效的。在计算机视觉领域，研究也展示了大型预训练模型在迁移学习中的重要性，一种有效的策略就是微调那些使用 ImageNet 数据集预训练过的模型。</p><h2 id="BERT">BERT</h2><p>本节将详细介绍BERT及其实现过程。我们的框架分为两个步骤：预训练和微调。在预训练阶段，模型会在各种预训练任务上对无标签数据进行训练。微调阶段，首先使用预训练的参数对BERT模型进行初始化，然后利用下游任务的标签数据对所有参数进行微调。尽管所有的下游任务都使用同样的预训练参数进行初始化，但每个任务都会有自己单独的经过微调的模型。图 1 中的问答示例将在本节中作为持续进行的示例进行讲解。</p><p><img src="//s3.mindex.xyz/blog/Theses/65ee5b6bf0176abff3884c1c91aeca99.png" alt="图1: BERT 的预训练和微调过程的总览。除了输出层外，预训练和微调阶段使用的网络架构是一样的。同样的预训练模型参数被用于初始化不同下游任务的模型。在微调阶段，所有的参数都会被进一步调整。[CLS] 是一个特殊的符号，我们在每个输入样例的开始位置添加它，而 [SEP] 则是一个用于分隔不同部分的特殊 Token。"></p><p>BERT的一个独特特点是，无论是在哪种任务中，其架构都保持一致。预训练阶段的架构和最终应用于下游任务的架构之间的差别极其微小。</p><ul><li><p><strong>Model Architecture</strong></p><p>BERT 的模型架构是一种多层双向 Transformer 编码器，这种架构基于 ‘Vaswani 等人 (2017)’ 的原始实现，并已经在 ‘tensor2tensor’ 库中公开。由于 Transformer 的使用已经非常普遍，且我们的实现几乎与原始的完全一致，因此我们不会详细描述这个模型架构的背景。如需进一步了解，读者可以参考 ‘Vaswani 等人 (2017)’ 的文章，或者阅读像是 “The Annotated Transformer” 这样的优秀教程。</p><p>在我们的研究中，我们以 L 来表示层数，以 H 来表示隐藏层的大小，以 A 来表示自注意力头的数量。主要的性能结果我们将以两种模型规模来展示：‘BERT_BASE’ (L=12, H=768, A=12, 总参数量=110M) 和 ‘BERT_LARGE’ (L=24, H=1024, A=16, 总参数量=340M)。</p><p>我们选择 BERT_BASE 的原因是为了与 OpenAI GPT 的模型大小做出比较。然而，最关键的区别在于，BERT Transformer 采用了双向自注意力机制（即每个 Token 可以关注到其左右两侧的上下文），而 GPT Transformer 则采用了受限的自注意力机制（即每个 Token 只能关注到其左侧的上下文）。</p></li><li><p><strong>Input/Output Representations</strong></p><p>为了让 BERT 能够处理各种下游任务，我们设计了一种输入表示方式，这种方式可以在一个 Token 序列中清晰地表示出单个句子，也可以表示出两个有关联的句子（例如，⟨ Question, Answer ⟩）。在我们的研究中，“句子”可以是一段连续的文本片段，而不仅限于实际的语言学意义上的句子。“序列”则是指输入给BERT的 Token序列，这可能是一个独立的句子，或者是两个句子组合在一起。</p><p>我们采用了WordPiece嵌入方法，其词汇表规模为30000个Token。每个序列的第一个Token总是一个特殊的分类Token（[CLS]）。对应这个Token的最后一个隐藏状态被用作分类任务中的序列总体表示。我们会将一对句子组合成一个单独的序列。我们通过两种方式来区分这些句子。首先，我们使用一个特殊的Token（[SEP]）来分隔它们。其次，我们为每个Token添加一个训练得到的嵌入，用来标识它是属于句子A还是句子B。如图 1 所示，我们将输入的嵌入记做E，[CLS]标记的最后一个隐向量记做C，以及第 i 个输入token的最后一个隐向量记做 $ T_i $ 。</p><p>对于一个特定的token，我们通过将对应的token、分段、和位置的嵌入相加，来构建它的输入表示。图2即为这种构建方式的可视化展示。</p></li></ul><p><img src="//s3.mindex.xyz/blog/Theses/51c91502fae0b24682733616c21a384c.png" alt="图2：BERT 的输入表示方法。输入嵌入是 token 嵌入、分段嵌入和位置嵌入的总和。"></p><h3 id="Pre-training-BERT">Pre-training BERT</h3><p>我们的方法与 ‘Peters et al. (2018a)’ 和 ‘Radford et al. (2018)’ 的方法有所不同，他们采用的是传统的顺序（从左至右或从右至左）语言模型进行 BERT 的预训练。而我们则选择使用两种特定的无监督学习任务来预训练 BERT，这些任务将在本节中详细介绍。你可以在图 1 的左侧部分看到这个预训练步骤的示意图。</p><ul><li><p><strong>Task #1: Masked LM</strong></p><p>直观上看，深度双向模型必然比单向模型（从左到右或从右到左）或者是简单地将一个从左到右的模型和一个从右到左的模型拼接在一起的方法更强大。然而，遗憾的是，我们通常只能以从左到右或从右到左的方式来训练标准的条件语言模型，因为如果允许模型同时考虑两个方向的信息，每个单词就能间接地“看到”自己，这就使得模型可以轻易地在多层次的上下文中预测出目标单词。</p><p>为了训练出深度的双向表示，我们采用了一种简单的方法：随机遮蔽输入中的一部分 tokens，然后预测这些被遮蔽的 tokens。我们把这个过程称为 “遮蔽语言模型”（Masked LM，简称 MLM），在学术界，这种任务有时也被称为 “填空任务”（Cloze task）。在这个过程中，对应被遮蔽 tokens 的最后一层隐藏向量会被输入到一个 softmax 函数中，这个函数会输出一个覆盖整个词汇表的概率分布，这与传统的语言模型是一样的。在我们的所有实验中，我们会随机遮蔽每个序列中 15% 的所有 WordPiece tokens（词片 tokens）。与 “降噪自编码器”（Denoising Auto-encoders）不同的是，我们只预测被遮蔽的词，而不是重构整个输入。</p><p>尽管这种方法让我们可以得到一个预训练的双向模型，但它也带来了一个问题，那就是在预训练和微调阶段出现了不匹配，因为在微调阶段并没有使用 [MASK] token。为了解决这个问题，我们在“遮蔽”单词时，并不总是用 [MASK] token 来替换。在生成训练数据时，我们会随机选取 15% 的 token 位置进行预测。如果选中了第 i 个 token，那么我们会这样替换它：80% 的情况下用 [MASK] token 替换，10% 的情况下用随机的 token 替换，剩下 10% 的情况下保持原样。然后，我们会用交叉熵损失函数来预测 $T_i$ 的原始 token。</p></li><li><p><strong>Task #2: Next Sentence Prediction (NSP)</strong></p><p>如问题回答（QA）和自然语言推理（NLI）等许多重要的下游任务，都是基于理解两个句子之间的关系，而这种关系并非能直接通过语言模型获取。为了训练出能理解句子关系的模型，我们采用了预训练方法，针对一个“下一句预测任务”，该任务可以简单地从任何单语语料库中生成。具体来说，当我们为每个预训练样本选择句子 A 和句子 B 时，有 50% 的概率 B 是真正紧跟在 A 后面的句子（我们标记为“IsNext”），另外 50% 的概率 B 是从语料库中随机抽取的句子（我们标记为“NotNext”）。如图 1 所示，C 被用于下一句预测（NSP）。尽管它很简单，但我们在第 5.1 节证明，这种预训练方式对于 QA 和 NLI 这两种任务都大有裨益。</p><p>NSP 任务与 ‘Jernite et al. (2017)’ 和 ‘Logeswaran and Lee (2018)’ 的研究中使用的目标表示学习方法密切相关。但是，在以前的研究中，只有句子嵌入被应用到下游任务中，而 BERT 则将所有参数应用于初始化最终任务的模型参数。</p></li><li><p><strong>Pre-training data</strong></p><p>我们的预训练过程大致遵循了现有的语言模型预训练方法。在预训练语料库的选择上，我们使用了 BooksCorpus（8亿词）和英文维基百科（25亿词）。对于维基百科，我们只提取了文本段落，忽略了列表、表格和标题。与使用如’Billion Word Benchmark’这样的打乱的句子级别语料库不同，选择文档级别的语料库以提取长的连贯序列是非常关键的。</p></li></ul><h3 id="Fine-tuning-BERT">Fine-tuning BERT</h3><p>BERT的微调过程相当直观，这得益于Transformer中的自注意力机制，它使得BERT能够处理许多下游任务，无论这些任务是涉及单个文本还是文本对，只需要更改相应的输入和输出即可。对于涉及文本对的应用，常见的做法是先独立地对每段文本进行编码，然后再应用双向交叉注意力，这种做法可以参见 ‘Parikh et al. (2016)’ 和 ‘Seo et al. (2017)’ 的研究。然而，BERT采用了自注意力机制，将这两个阶段融为一体。也就是说，通过自注意力机制对连接后的文本对进行编码，实际上已经包含了两个句子之间的双向交叉注意力。</p><p>对于每项任务，我们只需将特定任务的输入和输出接入到 BERT 中，并进行全面的参数微调。在输入端，预训练时用到的句子 A 和句子 B 在不同任务中有不同的对应关系，例如：（1）在改述任务中，它们对应于一对待改述的句子；（2）在蕴含(entailment)任务中，它们对应于假设和前提两部分；（3）在问答任务中，它们对应于问题和答案段落；（4）在文本分类或序列标记任务中，它们对应于一段文本和一个空标记。在输出端，token 的表示形式会被用于 token 级别的任务，如序列标记或问答，而 [CLS] 的表示形式会被用于分类任务，如蕴含或情感分析。</p><p>相较于预训练，微调的计算资源和时间消耗更少。无论是在单个 Cloud TPU 上，还是使用 GPU，只需最多一小时或几小时，就可以重现本文中所有的结果，前提是使用完全相同的预训练模型。关于任务特定的详细内容，我们已在第4节的对应小节中进行了描述。</p><h3 id="Experiments">Experiments</h3><p>在本节中，我们将为大家展示 BERT 在 11 个自然语言处理任务上的微调成果。</p><h4 id="GLUE">GLUE</h4><p>General Language Understanding Evaluation（GLUE）基准测试是汇集了多种自然语言理解任务的一项测试。</p><p>为了对 GLUE 进行微调，我们将输入序列（无论是单个句子还是句子对）处理为第3节所描述的形式，并使用与第一个输入 token ([CLS]) 相对应的最终隐藏向量 $ C \in \mathbb{R}^{H} $ 作为整体的表达形式。微调过程中新引入的唯一参数是分类层的权重 $ W \in \mathbb{R}^{K * H}$，其中 K 是标签的数量。我们用 C 和 W 来计算常规的分类损失，如 $ log(softmax(CW^{T}))$。</p><p><img src="//s3.mindex.xyz/blog/Theses/7f0168120059ef69a4c7b0a8ea572fe6.png" alt="表1：GLUE 测试结果。"></p><p>如 表1 所示，BERT_BASE 和 BERT_LARGE 在所有任务中均表现优秀，相较于先前的最先进技术，平均准确度分别提高了4.5% 和 7.0%。值得注意的是，除了注意力掩蔽(masking)的差异，BERT_BASE 和 OpenAI GPT 在模型架构上几乎完全相同。在最大且被广泛报告的 GLUE 任务 MNLI 中，BERT 实现了4.6%的绝对准确度提升。在官方 GLUE 排行榜10中，BERT_LARGE 的得分为80.5，而在本文写作时，OpenAI GPT 的得分为72.8。</p><p>BERT_LARGE 在所有任务中都显著优于 BERT_BASE，尤其在训练数据非常少的任务中表现更为出色。我们将在第5.2节更深入地探讨模型大小对性能的影响。</p><h4 id="SQuAD-v1-1">SQuAD v1.1</h4><p>斯坦福问答数据集（SQuAD v1.1）包含了10万对由众包产生的问题和答案。给定一个问题和一个包含答案的维基百科段落，任务就是要在段落中预测出答案文本的位置。</p><p>如图 1 所示，在问答任务中，我们将输入的问题和段落打包成一个序列，其中问题使用 A 嵌入，段落使用 B 嵌入。在模型的微调阶段，我们引入了两个特殊的向量，一个叫做&quot;起始向量&quot; S，另一个叫做&quot;结束向量&quot; E。这两个向量的作用是帮助我们计算出单词i作为答案开始部分的概率。通过计算 $T_i$ 和 $S$ 的点积，然后在段落中所有单词上进行 softmax 运算转化成概率。最后我们得到的概率就表示这个单词作为答案开始部分的可能性。</p><p>公式表示为 $ P_i = \frac{e^{S · T_i}}{\sum_{j}{e^{S · T_j}}}$ 。</p><p>对于答案的结束部分，我们也使用一种类似的计算方法。这个方法会给从位置 i 到位置 j 的一段文字打分， 定义为 $S · T_i + E · T_j$，其中 $j ≥ i$ 的最高得分范围被用作预测的答案。训练目标是正确的开始和结束位置的对数似然之和。我们进行了 3 轮的微调，学习率为 5e-5，批量大小为 32。</p><p>表2 展示了领先的排行榜成绩以及顶级已发布系统的表现。SQuAD 排行榜上的最佳成绩并未提供最新的公开系统描述，并且在训练他们的系统时，可以使用任何公开的数据。因此，我们在自己的系统中通过先在 TriviaQA 上进行模型微调（fine-tuning），再在 SQuAD 上进行微调，以实现适当的数据增强策略。</p><p><img src="//s3.mindex.xyz/blog/Theses/2196b4faa7855fb90e7be4193ca78081.png" alt="表2：SQuAD 1.1 的结果。BERT ensemble是有7套系统组成，使用了不同的预训练阶段的checkpoints和微调的seeds"></p><p>我们表现最好的系统在集成模式下，F1 分数比排行榜顶部的系统高出1.5个点，作为单一系统，也高出1.3个F1分数。事实上，我们的单一 BERT 模型在 F1 分数上甚至超过了顶级的集成系统。即使没有 TriviaQA 的微调数据，我们的 F1 分数也只会下降0.1-0.4个点，但仍然以很大的优势领先于所有现有的系统。</p><h4 id="SQuAD-v2-0">SQuAD v2.0</h4><p>SQuAD 2.0 任务在 SQuAD 1.1 问题定义的基础上进行了扩展，允许在给定的段落中可能不存在短答案，这使得问题更具现实性。</p><p>为了完成这项任务，我们采用了一种简单的策略，将SQuAD v1.1的BERT模型进行了扩展。对于那些没有答案的问题，我们将其答案的开始和结束都定位在 [CLS] Token 上。也就是说，答案的开始和结束的可能位置被扩展，包括了 [CLS] Token 的位置。在进行预测时，我们会比较无答案范围的得分 ($s_{null} = S·C + E·C$) 和最佳非空答案范围的得分 ($s_{\hat{i},j} = max_{j \geq i} S·T_i + E·T_j$)。只有当 $s_{null} &gt; s_{\hat{i},j} + \tau$时，我们才会预测出一个非空的答案。这个阈值 $τ$ 是我们在开发数据集上通过最大化 F1 分数来选择的。对于这个模型，我们没有使用 TriviaQA 的数据进行训练。我们进行了两个周期的微调，使用的学习率为5e-5，批量大小为48。</p><p><img src="//s3.mindex.xyz/blog/Theses/9046b856a7ab91a6243235b6c92dede8.png" alt="表3：SQuAD 2.0 的结果。我们排除了所有包含 BERT 作为一部分的项目。"></p><p>我们在 表3 中展示了与先前的排行榜成绩和已发表的顶级研究相比的结果，但并未包括那些使用 BERT 作为组成部分的系统。我们发现，与之前最好的系统相比，F1 分数提高了 5.1。</p><h3 id="SWAG">SWAG</h3><p>Situations With Adversarial Generations (SWAG) 数据集包含了 113k 个句子配对填充示例，这些示例被用于评估基于实际常识的推理能力。给定一个句子，任务是在四个选项中选择最有可能的接续。</p><p>在对 SWAG 数据集进行微调时，我们构造了四个输入序列，每个序列包含给定的句子（A）和一个可能的延续（B）的连接。唯一引入的任务特定参数是一个向量，其与 [CLS] token 表示 C 的点积代表每个选项的得分，该得分通过 softmax 层进行归一化。我们对模型进行了3轮微调，学习率为2e-5，批量大小为16。结果在 表4 中展示。BERT_LARGE 的表现超过了 ESIM+ELMo (作者的基线) 27.1%，超过了 OpenAI GPT 8.3%。</p><p><img src="//s3.mindex.xyz/blog/Theses/8432ea7f4389fd068a343d25edca5776.png" alt="表4：SWAG 的开发集和测试集的准确率。人类的表现是通过在 SWAG 论文中报告的 100 个样本来衡量的。"></p><h3 id="Ablation-Studies">Ablation Studies</h3><p>在这一部分，我们通过消融实验，探讨了 BERT 的多个关键要素，以便更好地理解它们各自的重要性。</p><h4 id="Effect-of-Pre-training-Tasks">Effect of Pre-training Tasks</h4><p>我们通过评估两个使用与 BERT_BASE 完全相同的预训练数据、微调方案和超参数的预训练目标，展示了 BERT 的深度双向性的重要性:</p><p><strong>No NSP</strong>: 一种双向模型，该模型使用 “masked LM”（MLM）进行训练，但不包括 “next sentence prediction”（NSP）任务。</p><p><strong>LTR &amp; No NSP</strong>: 一个只考虑左侧上下文的模型，它采用的是标准的从左到右（Left-to-Right，LTR）语言模型训练方式，而不是被遮蔽的语言模型（Masked Language Model，MLM）。在微调阶段，我们也坚持了这种“只看左边”的规则，因为如果不这样做，预训练和微调阶段的处理方式就会不一致，这可能导致模型在实际任务中的表现下降。另外，这个模型在预训练阶段并没有执行“下一句预测”（Next Sentence Prediction，NSP）任务。这个模型可以直接和 OpenAI 的 GPT 进行比较，不过我们使用了更大的训练数据集，我们自己的输入数据表示方法，以及我们自己的微调策略。</p><p>我们首先研究了 NSP 任务带来的影响。在 表5 中，我们展示了去掉 NSP 在 QNLI、MNLI 和 SQuAD 1.1 上显著降低了性能。接下来，我们通过比较“No NSP”和“LTR &amp; No NSP”来评估训练双向表示的影响。LTR 模型在所有任务上的表现都比 MLM 模型差，其中在 MRPC 和 SQuAD 上的下降尤为显著。</p><p>对于 SQuAD 任务，我们可以直观地理解，一个从左到右（LTR）的模型在预测单个字符（token）时表现会很差，因为这些字符级别的隐含状态缺乏右侧的上下文信息。为了尽可能地提升这个从左到右的系统，我们在其上增加了一个随机初始化的双向长短期记忆网络（BiLSTM）。这确实在 SQuAD 任务上取得了显著的改善，但是与预训练的双向模型相比，其结果仍然相差甚远。而且，BiLSTM 在 GLUE 任务上的表现反而下降了。</p><p>我们意识到，也可以像 ELMo 那样，分别训练从左到右（LTR）和从右到左（RTL）的模型，然后将每个字符（token）的表示形式作为这两个模型的结合。但是，这种方式存在以下问题：(a) 它的成本是单个双向模型的两倍；(b) 对于像问答（QA）这样的任务，这种方式并不直观，因为从右到左的模型无法根据问题来决定答案；© 它的能力不如深度双向模型，因为深度双向模型可以在每一层都同时使用左右两侧的上下文信息。</p><h4 id="Effect-of-Model-Size">Effect of Model Size</h4><p>在这一部分，我们研究了模型规模对微调任务精度的影响。我们训练了多个BERT模型，这些模型在层数、隐藏单元和注意力头的数量上有所不同，但在超参数和训练流程上，它们与前文描述的保持一致。</p><p>如 表6 所示，我们给出了在选定的GLUE任务上的结果。在这个表格中，我们给出了在进行5次随机微调后，开发集（Dev Set）准确度的平均值。我们可以看到，模型规模更大的BERT模型能在所有四个数据集上都带来准确度的显著提升，即使是在只有3600个标注训练样本，与预训练任务大相径庭的MRPC数据集上也是如此。同时，令人惊讶的是，我们在已经相对于现有研究来说规模较大的模型基础上，还能取得如此显著的提升。例如，'Vaswani et al. (2017)'探索的最大的Transformer模型是(L=6, H=1024, A=16)，编码器的参数有100M，而我们在文献库中找到的最大的Transformer模型是(L=64, H=512, A=2)，参数有235M。相比之下，BERT_BASE模型包含了110M参数，BERT_LARGE模型包含了340M参数。</p><p><img src="//s3.mindex.xyz/blog/Theses/c46e2f0f3b153c2c018d6a32ca759608.png" alt="表6：对BERT模型大小进行消融实验。#L = 层数的数量；#H = 隐藏层大小；#A = 注意力头的数量。“LM (ppl)”是保留训练数据的被遮蔽的语言模型困惑度。"></p><p>大家都知道，如果我们增加模型的规模，将会在大规模任务，如机器翻译和语言建模，上取得持续的改进。这一点可以通过查看 表6 中展示的预留训练数据的语言模型复杂度得到证实。然而，我们认为，这是第一项有力地证明，只要模型得到了充分的预训练，即使在非常小规模的任务上，极大地增加模型规模也能带来显著改进的研究。在 ‘Peters et al. (2018b)’ 的研究中，他们针对预训练的双向语言模型大小从两层增加到四层的影响，展示了混合的结果。而 ‘Melamud et al. (2016)’ 则提到，将隐藏维度从 200 增加到 600 有所帮助，但是进一步增加到 1000 并未带来更多的改进。这两项研究都采用了基于特征的方法。我们的假设是，当模型直接在下游任务上进行微调，并且只使用极少量的随机初始化的附加参数时，即使下游任务数据非常少，任务特定的模型也能从更大，更具表达力的预训练表示中受益。</p><h4 id="Feature-based-Approach-with-BERT">Feature-based Approach with BERT</h4><p>我们迄今为止展示的所有BERT结果都是采用了微调策略，也就是在预训练模型的基础上增加了一个简单的分类层，并在具体任务上对所有参数进行了统一的微调。然而，基于特征的方法，也就是从预训练模型中提取出固定的特征，也有其独特的优点。首先，不是所有的任务都能被Transformer编码器架构轻松地表达出来，因此有时需要添加特定于任务的模型架构。其次，一种有效的计算策略是先预计算一次训练数据的复杂表示，然后在这个表示的基础上使用更经济的模型进行多次实验。</p><p>在这一部分，我们将 BERT 模型应用于 CoNLL-2003 命名实体识别 (NER) 任务，以此来对比两种不同的方法。在为 BERT 模型提供输入的过程中，我们采用了一种能够保留字母大小写的 WordPiece 模型，并且还包括了数据所能提供的最大的文档环境信息。遵循常规的做法，我们将这个任务设定为一个标记任务，但是在模型的输出部分，我们并未使用条件随机场（CRF）层。在对 NER 标签集进行 token 级别的分类时，我们选择了第一个子 token 的表示作为输入。</p><p>为了探究微调方法的影响，我们采用了一种基于特征的方法：从 BERT 的一个或多个层中提取激活值，而不对 BERT 的任何参数进行微调。这些上下文嵌入被作为输入送入一个随机初始化的两层 768 维的 BiLSTM，然后再进入分类层。</p><p><img src="//s3.mindex.xyz/blog/Theses/f31d3b1d7cf7187e0aba53f8323dbf12.png" alt="表7："></p><p>结果见 表7。BERT_LARGE 的表现与最先进的方法相媲美。表现最好的方法是将预训练的 Transformer 模型中最顶层的四个隐藏层的 token 表示进行拼接，这仅比微调整个模型的 F1 分数低 0.3。这证明了 BERT 对于微调和基于特征的方法都是有效的。</p><h2 id="Conclusion">Conclusion</h2><p>近期的研究发现，通过使用语言模型进行迁移学习，且在预训练阶段引入大量无监督数据，可以显著提升语言理解系统的性能。特别地，这种方法甚至使得资源匮乏的任务也能从深度单向模型（Deep Unidirectional Models）中获益。我们的主要贡献在于，我们将这些研究成果推广到了深度双向模型（Deep Bidirectional Models），使得同一个预训练模型能够成功应对各种各样的自然语言处理（NLP）任务。</p><h2 id="Source">Source</h2><p><a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></p>]]></content>
    
    <summary type="html">
    
      Bidirectional Encoder Representations from Transformers.
    
    </summary>
    
    
      <category term="Theses" scheme="https://neo1989.net/categories/Theses/"/>
    
    
      <category term="Coder" scheme="https://neo1989.net/tags/Coder/"/>
    
      <category term="AI" scheme="https://neo1989.net/tags/AI/"/>
    
      <category term="NLP" scheme="https://neo1989.net/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>好好说话</title>
    <link href="https://neo1989.net/Notes/NOTE-communication/"/>
    <id>https://neo1989.net/Notes/NOTE-communication/</id>
    <published>2024-02-18T08:24:01.000Z</published>
    <updated>2024-02-18T13:52:30.585Z</updated>
    
    <content type="html"><![CDATA[<h3 id="乔哈里视窗">乔哈里视窗</h3><p>将沟通的信息比作一个窗子，它被分为4个区域：公开区、隐蔽区、盲目区、未知区，人的有效沟通就是这四个区域的有机融合。</p><p>公开区：自己知道，他人知道；往往关系越近、共同信息知晓越多的两个人公开区域会越大。<br>盲点区：自己不知道，他人知道；在很多情况下，我们都会有盲点区，自身的学识、所处的环境等都会造成我们与对方所了解的信息不对等。<br>隐秘区：自己知道，他人不知道；造成隐蔽区的原因在于我们能不好意思跟其他人说、忘了对其他人说、没沟通清楚造成误解、误以为别人知道等。<br>未知区：自己不知道，他人不知道；</p><h3 id="沟通漏斗">沟通漏斗</h3><ul><li>你心里想的，100%</li><li>你说出来的，80%</li><li>别人听到的，60%</li><li>别人听懂的，40%</li><li>别人执行的，20%</li></ul><h3 id="FIRE-接收模型">FIRE 接收模型</h3><p>首先注意到<strong>事实</strong>，并对这些事实<strong>进行解读</strong>，根据解读的结果，经历情绪的<strong>反应</strong>，期望得到想要的<strong>结果</strong></p><p>FIRE模型能帮助我们认清哪些事实，哪些是主观想法。它最大的好处就是，当你听到一个难以入耳的反馈时，它能帮助你平静理性的展开分析，从而得到一个有效的解决方案。</p><p>F-事实：确实存在的事情，具体、公正、客观、不带感情色彩。事实是真实谈话的基础<br>I-解读：事件发生，我们依据经验对事实进行解读，得出这一事实的目的或意义<br>R-反应：根据解读结果，我们会产生相应的情绪反应<br>E-结果：经历情绪反应后，我们就会期望某种结果</p><h3 id="PREP-沟通法则">PREP 沟通法则</h3><p>先说<strong>结论</strong>，再说<strong>原因</strong>，接着用<strong>事例</strong>辅助证明观点。最后重复<strong>结论</strong>，构成一次完整的表述。</p><p>P-结论：结论先行，沟通中的黄金法则。抛出明确的观点，让对方清楚接下来的谈话是围绕哪个结论展开<br>R-依据：通过有效的数据，有力的事实验证结论的可靠性。<br>E-事例：用事例引起倾听者的共情和想象<br>P-重述结论：强化双方对结论的共识</p><h3 id="STAR-叙事模型">STAR 叙事模型</h3><p>S-情境：所发生的事情的背景，在所阐述的事实中所发生的背景情况<br>T-任务：在背景环境下所承担的角色及所执行的任务，以及要达成的目标<br>A-行动：在任务当中如何去操作执行任务的，重点是行动过程<br>R-结果：付诸行动，完成任务所达到的效果，一般是可量化的指标</p><h3 id="SCQRTV-方案模型">SCQRTV 方案模型</h3><p>该模型符合人对事物的体验路径，与大脑思考策略执行的逻辑契合度极高，能够让倾听者更容易接受你的想法。</p><p>体验路径：感官 - 情感 - 思考 - 行为 - 识别<br>思考路径：是什么 - 怎么了 - 为什么 - 怎么办 - 结果如何<br>执行路径：分析 - 判断 - 推理 - 决策 - 评估</p><p>S-情境：客观地描述时间情境，明确问题<br>C-冲突：提出与现实相违背的内容的疑问<br>R-原因：分析事件的原因与动机<br>T-策略：解决问题的方法，进行决策<br>V-价值：产生价值，创造价值</p><h3 id="FFC-赞美法则">FFC 赞美法则</h3><p>赞美对方时，先说出<strong>内心的感受</strong>，然后陈述你的奇特感受和<strong>客观事实</strong>，最后将被赞美人和同类让<strong>进行对比</strong>，让对方认为就是这样</p><p>F-感受：从细节出发，说出内心的感受。<br>F-事实：陈述带给你这种感受的客观事实。<br>C-对比：与相似的人/事进行对比，突出对方的优点。</p><h3 id="RIDE-说服模型">RIDE 说服模型</h3><p>利用人们心理<strong>趋利避害</strong>的天然潜意识，通过暴露风险，阐述利益，继而引入差异性及影响，来说服他人接受你的观点</p><p>R-风险： 不采纳方案会带来的风险<br>I-利益：采纳方案带来的利益，从之前的方案抛出风险，降低对方的预期，继而引入利益点，提高预期，会使对方更好地接受<br>D-差异：事实举例说明自身建议与其他方案的差异之处<br>E-影响：方案本身所能带来的负面影响。太完美的东西反而不真实，小缺点瑕不掩瑜</p><h3 id="GROW-模型">GROW 模型</h3><p><strong>用提问代替说教</strong>，这样可以引导对方<strong>自己找到</strong>问题的解决方法。有效避免对方产生<strong>抵触情绪</strong>。</p><p>G-目标：明确要实现的目标，你想要什么？<br>R-现状：分析当前状况、聚焦目标。现在是什么情况？<br>Q-方案：找出可供选择的方案。有哪些方案？<br>W-意愿：强化意愿。你将要从什么动作开始？</p><h3 id="电梯演讲">电梯演讲</h3><p>麦肯锡认为，一般人们只能记住一二三，记不住四五六，所以凡是要归纳在3条以内。</p><p>Hook 吸引：通过现状、存在的问题、现状产生的原因、解决方案等吸引对方注意力。<br>Mutual Benefit 给利：提出具体解决方案，让对方意识到你的价值存在。<br>Call to Action 收网：指出上述方法的依据及理由，并留下联系方式。</p><h3 id="Tips">Tips</h3><p>明确双方所表达的语义是否一致，掌握好措辞；若不一致需及时了解，打破双方误解。<br>结论先行，也就是PREP核心思想。<br>阐述事情先讲背景，再讲内容。<br>在沟通之前，明确此次沟通的目的，了解所沟通对象的诉求。<br>不论沟通对象是谁，结构化表达，能够让对方更好地理解你说的话。若当面沟通无法阐述清楚，则预先打个腹稿或者以文字形式输出。<br>切莫自己一顿疯狂输出，也记得倾听对方的想法、方案。<br>区分哪些是真正的事实，哪些是对方/自己解读后的观点，基于客观事实和行为模式是寻求真相谈话的基础。<br>沟通方式、沟通模型仅仅只是招式，最重要的还是<strong>沟通的内容</strong></p>]]></content>
    
    <summary type="html">
    
      沟通和执行相差甚远的时候，多半是沟通模式出了问题
    
    </summary>
    
    
      <category term="Notes" scheme="https://neo1989.net/categories/Notes/"/>
    
    
      <category term="SoftSkills" scheme="https://neo1989.net/tags/SoftSkills/"/>
    
      <category term="Wisdom" scheme="https://neo1989.net/tags/Wisdom/"/>
    
  </entry>
  
  <entry>
    <title>18 Emotional Equations</title>
    <link href="https://neo1989.net/Notes/NOTE-18-Emotional-Equations/"/>
    <id>https://neo1989.net/Notes/NOTE-18-Emotional-Equations/</id>
    <published>2024-01-30T13:50:25.000Z</published>
    <updated>2024-02-18T13:53:59.519Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Dealing-with-Difficult-Times">Dealing with Difficult Times</h2><h3 id="绝望">绝望</h3><p>绝望 = 苦难 - 意义 （Despair = Suffing - Meaning）</p><p>绝望就是当承受的苦难变得毫无意义时的结果。</p><p>在一个人的低估时期，比如弗兰克（《活出生命的意义》的作者）被投入集中营时，苦难实际上是一个常量，所以为了降低绝望感，最好是把注意力转移到寻求更多的意义上。</p><h3 id="失望">失望</h3><p>失望 = 期望 - 现实（Disappointment = Expectations - Reality）</p><p>失望是你的期望和现实之间的差距。</p><p>应对失望的方法之一是，在最初试图改变某些事情的结果时保持乐观，然后随着时间的推移，一旦力有不逮就调低期望来振作精神，以对抗潜在的负面结果。另一种应对机制是稀释现实的重要性。问问自己，这个结果对你来说究竟有多重要，真的重要吗？</p><h3 id="遗憾">遗憾</h3><p>遗憾 = 失望 + 责任感 （Regret = Disappointment +  Responsibility）</p><p>遗憾是对不幸的个人选择而导致的结果的不满。即没能力改变现实的失望，再被个人选择的责任感放大。遗憾中有期望和向往，这是一种更加成熟的情绪，失望与遗憾的主要区别就在于你的责任感。</p><h3 id="猜忌">猜忌</h3><p>猜忌 = 不信任 / 自尊 （Jealousy = Mistrust / Self-esteem）</p><p>有两个关键因素影响着人们的猜忌心理：你不信任的程度和你的自尊心。</p><p>猜忌是害怕失去原本属于自己的东西，常在爱恨情仇中出现。妒忌则是见到别人拥有你想有的东西时感到的挫折。爱情中的猜忌通常包含三个主体：你、你的爱人和你的情敌。而妒忌一般只涉及你自己和拥有你想要的东西的那个人。猜忌中隐藏着对失去的害怕而妒忌中隐藏着对得到的期待。</p><h3 id="妒忌">妒忌</h3><p>妒忌 = (傲慢 + 虚荣) / 慈悲（Envy = (Pride + Vanity) / Kindness）</p><p>妒忌和自我觉知有很大的关联。妒忌和自恋师承一脉。</p><p>一个自我觉知膨胀的人会很傲慢和虚荣。可以直接反制妒忌的美德是慈悲或者慷慨的精神，当极度妒忌某人时，注入一些慈悲心将会帮助我们淡化不满并让它转化为动力，比如让自己更努力工作去获得类似的成就，或者转变为认同，比如走出仔细，国懿仲沉浸在为他人感到开心的更加广阔的人生。</p><h3 id="焦虑">焦虑</h3><p>焦虑= 不确定性 * 无力感 （Anxiety = Uncertainty * Powerlessness）</p><p>这个方程中存在两个变量：你不知道的（不确定性）和你不能控制的（无力感）。通常二者是相互影响的：你感觉越不确定，你就会感觉越无力。</p><p>因为感觉无力会使人精神衰弱，所以这个方程运用乘法产生一个指数的结果。然而如果你能改变其中一个变量，减小到接近零，你就可以明显降低你的焦虑。</p><p>一般来说，少一点焦虑不只是会让你感觉好一点，还会让你更好地对待生活。对某件事情十分确定却感到无力去改变它时，我们是会感觉很不自在但你更多是会逆来顺受，而不会感到焦虑。同样，感觉不确定却充满力量，意味着你对任何迎面而来的失去都有应对的勇气和信心，那也意味着你的焦虑消除了。</p><h2 id="Getting-the-Most-out-of-Your-Work-life">Getting the Most out of Your Work life</h2><h3 id="使命">使命</h3><p>使命 = 快乐 / 痛苦 （Calling = Pleasure / Pain）</p><p>你越是生活在使命中，就能感受到快乐而忽略掉痛苦。<br>你越是生活在使命中，快乐就越能主宰痛苦。</p><h3 id="工作狂">工作狂</h3><p>工作狂 = 你在逃避什么？/ 你为何而活？（Workaholism = What are you running from? / What are you living for?）</p><p>工作狂是上瘾的一种形式，简单来说，各种成瘾都和我们在逃避什么相关。<br>通常我们会沉醉于哪些能够改善我们心情的事物（包括工作），一定程度上是因为我们迫切需要逃脱那些正在吞噬我们的情绪或恐惧。在你剥下任何成瘾症的表层情绪后，你会发现一些隐藏的共同情绪，比如自卑、不可爱、羞耻以及诸如害怕亲密、失败甚至成功等各种恐惧。</p><p>从“工作——休息——工作”循环中抽离出来，反思你究竟为什么而活，反思在我们的生命中，还有哪些细微的愉快感受值得我们更多的关注与投入，能够帮助我们从失衡的状态拉回来，从一种习惯性行为的舒服中得到释放。</p><h3 id="心流">心流</h3><p>心流 = 技能 / 挑战 （Flow = Skill / Challenge）</p><p>当参加有组织」有方向和有明确目标的活动时，我们所具备的技能能应对所感知到的挑战，达到平衡状态时，就会处于一种心流状态。<br>能让我们体验到心流的地方之一就是在工作中。在工作中达到心流状态意味着你将所有情绪投入到某项能够是你达到巅峰表现的活动中了。<br>进入心流状态与失去自我意识有关。这不是说你得迷失自我，更不是值你昏迷不醒。是意味着，有那么亦可，你意识不到你自己的存在。平时我们是在对自己的意识、脑子里想什么，以及绳梯感觉如何都极度清醒的状态中生活的。但是当我们处于心流状态时，我们暂时切断了自己与这些感受的联系，让我们去拓宽“我们是谁”和“我们能做什么”的观念。</p><h3 id="好奇心">好奇心</h3><p>好奇心 = 惊奇 + 敬畏 （Curiosity = Wonder + Awe）</p><p>好奇先通常是没有预设目标的行为，它是大脑的养分。有大量证据显示，好奇心好似血管内的血液，是一种让我们永保青春、不可或却并给予生命肯定的情绪。<br>好奇心的两个组成部分是：惊奇和敬畏。纯粹的好奇心蕴含着高度的敬意和公平，我们只有满怀惊奇与敬畏，才会乐于去学习、去爱、去犯错和去生活。心理学家托德·卡什丹将好奇心比作“成长的引擎”。</p><h2 id="Defining-Who-You-Are">Defining Who You Are</h2><h3 id="真实性">真实性</h3><p>真实性 = 自我觉知 * 勇气 （Autheniticity = (Self-Awwareness) * Courage ）</p><p>要认识到你自己需要两种基本工具，把你的真实自我从大理石中雕琢出来，它们就是自我觉知的勇气。两者都极为重要。没有勇气的自我觉知意味着你认识了自己，但是其他人并没有认识你。有勇气却缺乏自我觉知的人会表现得装腔作势。因此这是一个乘法运算，而不是简单的加法。</p><h3 id="自恋">自恋</h3><p>$自恋 = 特权 * {(自尊心)}^2 $ （Narcissism = Entitlement * (self-esteem)**2）</p><p>自恋的人自尊心强到极致，一个有正常自尊心的人会关心别人，而自恋者则太过关注自己，以至于与周围的人断了关联，只会关注他人是如何看待或者服务自己的。<br>自尊心极强的人还会产生特权思想，当想着自己很独特时，你会相信自己有权享受特殊待遇。</p><h3 id="正直">正直</h3><p>正直 = 真实 * 无形 * 可靠 （Integrity = Autheniticity * Invisibility * Reliability ）</p><p>有三个情绪变量可以组合成正直，这就是真实、无形和可靠。<br>正直是“完整”的内在感觉，就是那种我们身上的特点合而为一的感觉。正直不需要观众，一个正直的人就算没有人在注意，也会做正当的事。 可靠包括兼容性、忠诚，还有言行一致。无论你面临什么样的情况，正直都能够跟你的价值观进行可靠的结合。如果你看到了一个人的正直，那么他很有可能在践行你所钦佩的生活和做人的方式。</p><h2 id="Finding-Contentment">Finding Contentment</h2><h3 id="幸福">幸福</h3><p>幸福 = 拥有的 / 想要的 （Happiness = Wanting what you have / Having what you want）</p><p>成功和幸福经常被混为一谈，但是成功是策略上的最大化和最优化，而幸福则倾向于对现状的知足和感恩。心理学家在临床研究中表明，幸福感当中最重要的一部分是表达和感受恩典。该调查同时表明，哪些“策略上的最大化者”（受成功激励的人）的幸福感远远不及那些“知足者”。</p><p>幸福的人更关注“舒适的生活”而不是“更好的生活”。</p><h3 id="喜悦">喜悦</h3><p>喜悦 = 爱 - 恐惧 （Joy = Love - Fear）</p><p>寻求爱可能毫无所得，但寻求喜悦可能却是获得爱的一种方式。爱就像一种电流，我们可以选择关闭或者打开，这一切只是基于我们是否愿意生活在黑暗的恐惧之中，只要我们生活在爱中，喜悦的情绪就会缓缓流入。</p><h3 id="活力">活力</h3><p>活力 = 积极的频率 / 消极的频率 （Thriving = Frequency of Positive / Frequency of Negative）</p><p>活力是积极频率与消极频率的比，且要大于等于3.</p><p>巴西的社会学家 Marcial Losada 和心理学的领军人物 芭芭拉·弗雷德里克森 进行了一场关于积极情绪的实验，实验表明，一旦积极情绪与消极情绪的比例达到3:1，人们就会感到充满希望，情绪高昂，这个比例被心理学家称为“洛萨达比例”或“洛萨达线”。</p><h3 id="信仰">信仰</h3><p>信仰 = 信念 / 智力 （Faith = Belif / Intellect）</p><p>我们所有人都会信仰或者信赖某些事物，无神论者也一样，信仰存在于他们的思想中、本质中、宇宙中，以及所有事物中。<br>信仰和信念经常被当作同义词，但其实前者是一种可能没有明显证据的信赖，而后者则混杂有经验证据。越理性智力水平越高，对于某些事物的信仰就越弱，这就是很多无神论者有些可能会认为信仰宗教的人没有智力的原因。<br>信仰并不嫩解开我们所有的疑惑，有时可能只是让我们愉快地忽视了问题的存在。但是信仰能够给我们一定程度的信心，更加自由地感受生活。想萨姆·哈里斯这样的无神论者也承认：“信仰能让我们当中的很多人平静地承担起生命中的苦楚，而这是我们在纯理性的世界中力有不逮的。”<br>多项事实证明，在很多情况下，药用安慰剂能够发挥很大作用，部分好似因为我们相信的到了某种能够治愈我们的药而产生的信仰。</p><h3 id="智慧">智慧</h3><p>智慧 = 经历的开方 （$Wisdom = \sqrt{Experience}$）</p><p>智慧就是简化生活的复杂性，将分散的东西集中到核心。<br>察觉到规律并将其简化为普遍真理，然后创造成简单的认知模式，在无意识情况下运用到待人处世中。智慧之美在于它的简单。<br>大多数研究人员关于智慧的研究都一致地显示出，智慧的一个品质便是『经历』。这也是为什么我们会认为那些已经有几十年生活经历的人会比年轻人更加智慧的原因。</p><h2 id="Reference">Reference</h2><p><a href="https://medium.com/@hashim.alzain/emotional-equations-book-summary-6348cc98ab81">Emotional Equations</a></p>]]></content>
    
    <summary type="html">
    
      保持平静的简单秘诀。
    
    </summary>
    
    
      <category term="Notes" scheme="https://neo1989.net/categories/Notes/"/>
    
    
      <category term="SoftSkills" scheme="https://neo1989.net/tags/SoftSkills/"/>
    
      <category term="Health" scheme="https://neo1989.net/tags/Health/"/>
    
      <category term="Wisdom" scheme="https://neo1989.net/tags/Wisdom/"/>
    
  </entry>
  
  <entry>
    <title>Way2AI · Building Advanced RAG</title>
    <link href="https://neo1989.net/Way2AI/Way2AI-Building-Advanced-RAG/"/>
    <id>https://neo1989.net/Way2AI/Way2AI-Building-Advanced-RAG/</id>
    <published>2024-01-24T12:01:43.000Z</published>
    <updated>2024-02-29T14:24:02.398Z</updated>
    
    <content type="html"><![CDATA[<p><img src="//s3.mindex.xyz/blog/Courses/fa53038bd6116d6d7897b88d8b3e59b7.png" alt="A comprehensive RAG CheatSheet detailing motivations for RAG as well as techniques and strategies for progressing beyond Basic or Naive RAG builds."></p><h2 id="Basic-RAG">Basic RAG</h2><p>主流的 RAG 主要涉及从外部知识库召回文档，并将这些文档连同用户的查询一起传递给大语言模型，以此生成回应。<br>也就是说，RAG 包含了 <strong>召回部分</strong>、<strong>外部知识库</strong> 以及 <strong>生成部分</strong> 三个组成部分。</p><p>LlamaIndex Basic RAG 示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> SimpleDirectoryReader, VectorStoreIndex</span><br><span class="line"></span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">documents = SimpleDirectoryReader(input_dir=<span class="string">&quot;...&quot;</span>).load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># build VectorStoreIndex that takes care of chunking documents</span></span><br><span class="line"><span class="comment"># and encoding chunks to embeddings for future retrieval</span></span><br><span class="line">index = VectorStoreIndex.from_documents(documents=documents)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The QueryEngine class is equipped with the generator</span></span><br><span class="line"><span class="comment"># and facilitates the retrieval and generation steps</span></span><br><span class="line">query_engine = index.as_query_engine()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use your Default RAG</span></span><br><span class="line">response = query_engine.query(<span class="string">&quot;A user&#x27;s query&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="Success-Requirements-for-RAG">Success Requirements for RAG</h2><p>要想让一个RAG被认定为成功（即能为用户的问题提供有用且相关的答案），实际上有两个核心要求：</p><ul><li><strong>召回</strong> 必须是用户查询最相关的文档。</li><li><strong>生成</strong> 必须能够充分利用召回的文档来有效的回答用户查询。</li></ul><h2 id="Advanced-RAG">Advanced RAG</h2><p>一旦我们明确了成功的标准，就可以说，构建先进的 RAG 主要是要运用更精细的技术和策略（应用于召回或生成组件），以确保最终达到这些标准。<br>进一步说，我们可以把这些精细的技术分为两类：一类是独立解决两大成功要求中的一项（或多或少）的技术，另一类则是同时应对这两大要求的技术。</p><h3 id="召回">召回</h3><p>接下来，我们将简述几种更高级的技术，这些技术能帮助我们实现第一个要求：</p><h4 id="Chunk-Size-Optimization">Chunk-Size Optimization</h4><p>因为大语言模型的上下文长度有限，所以在构建外部知识库时，我们需要将文档切分成多个部分。如果切分的部分过大或过小，都可能给生成组件带来问题，从而导致生成的回答不准确。</p><p>LlamaIndex Chunk Size Optimization <a href="https://github.com/run-llama/llama_index/blob/main/docs/examples/param_optimizer/param_optimizer.ipynb">示例</a>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> ServiceContext</span><br><span class="line"><span class="keyword">from</span> llama_index.param_tuner.base <span class="keyword">import</span> ParamTuner, RunResult</span><br><span class="line"><span class="keyword">from</span> llama_index.evaluation <span class="keyword">import</span> SemanticSimilarityEvaluator, BatchEvalRunner</span><br><span class="line"></span><br><span class="line"><span class="comment">### Recipe</span></span><br><span class="line"><span class="comment">### Perform hyperparameter tuning as in traditional ML via grid-search</span></span><br><span class="line"><span class="comment">### 1. Define an objective function that ranks different parameter combos</span></span><br><span class="line"><span class="comment">### 2. Build ParamTuner object</span></span><br><span class="line"><span class="comment">### 3. Execute hyperparameter tuning with ParamTuner.tune()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Define objective function</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">objective_function</span>(<span class="params">params_dict</span>):</span><br><span class="line">    chunk_size = params_dict[<span class="string">&quot;chunk_size&quot;</span>]</span><br><span class="line">    docs = params_dict[<span class="string">&quot;docs&quot;</span>]</span><br><span class="line">    top_k = params_dict[<span class="string">&quot;top_k&quot;</span>]</span><br><span class="line">    evals_qs = params_dict[<span class="string">&quot;eval_qs&quot;</span>]</span><br><span class="line">    ref_response_strs = params_dict[<span class="string">&quot;ref_response_strs&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># build RAG pipeline</span></span><br><span class="line">    index = _build_index(chunk_size, docs)  <span class="comment"># hlper function</span></span><br><span class="line">    query_engine = index.as_query_engine(similarity_top_k=top_k)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># perform inference with RAG pipeline on a privoded questions `eval_qs`</span></span><br><span class="line">    pred_response_objs = get_responses(</span><br><span class="line">        eval_qs, query_engine, show_progress=true</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># perform evaluations of predictions by comparing them to reference</span></span><br><span class="line">    <span class="comment"># response `ref_response_strs`</span></span><br><span class="line">    evaluator = SemanticSimilarityEvaluator(...)</span><br><span class="line">    eval_batch_runner = BatchEvalRunner(</span><br><span class="line">        &#123;<span class="string">&quot;semantic_similarity&quot;</span>: evaluator&#125;, workers=<span class="number">2</span>, show_progress=<span class="literal">True</span></span><br><span class="line">    )</span><br><span class="line">    eval_results = eval_batch_runner.evaluate_responses(</span><br><span class="line">        evals_qs, responses=pred_response_objs, reference=ref_response_strs</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># get semantic similarity metric</span></span><br><span class="line">    mean_score = np.array(</span><br><span class="line">        [r.score <span class="keyword">for</span> r <span class="keyword">in</span> eval_results[<span class="string">&quot;semantic_similarity&quot;</span>]]</span><br><span class="line">    ).mean()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> RunResult(score=mean_score, params=params_dict)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. Build ParamTuner object</span></span><br><span class="line">param_dict = &#123;<span class="string">&quot;chunk_size&quot;</span>: [<span class="number">256</span>, <span class="number">512</span>, <span class="number">1024</span>]&#125;</span><br><span class="line">fixed_param_dict = &#123;</span><br><span class="line">    <span class="string">&quot;top_k&quot;</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="string">&quot;docs&quot;</span>: docs,</span><br><span class="line">    <span class="string">&quot;evals_qs&quot;</span>: evals_qs[:<span class="number">10</span>],</span><br><span class="line">    <span class="string">&quot;ref_response_strs&quot;</span>: ref_response_strs[:<span class="number">10</span>],</span><br><span class="line">&#125;</span><br><span class="line">param_tuner = ParamTuner(</span><br><span class="line">    param_fn=objective_function,</span><br><span class="line">    param_dict=param_dict,</span><br><span class="line">    fixed_param_dict=fixed_param_dict,</span><br><span class="line">    show_progress=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. Execute hyperparameter search</span></span><br><span class="line">results = param_tuner.tune()</span><br><span class="line">best_result = results.best_run_result</span><br><span class="line">best_chunk_size = results.best_run_result.params[<span class="string">&quot;chunk_size&quot;</span>]</span><br></pre></td></tr></table></figure><h4 id="Structured-External-Knowledge">Structured External Knowledge</h4><p>在复杂的情况下，我们可能需要构建一个比基本向量索引更有结构的外部知识库，这样才能在处理有明显区别的外部知识源时，进行递归召回或者路径召回。</p><p>LlamaIndex Recursive Retrieval <a href="https://docs.llamaindex.ai/en/stable/examples/retrievers/recursive_retriever_nodes.html">示例</a>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> SimpleDirectoryReader, VectorStoreIndex</span><br><span class="line"><span class="keyword">from</span> llama_index.node_parser <span class="keyword">import</span> SentenceSplitter</span><br><span class="line"><span class="keyword">from</span> llama_index.schema <span class="keyword">import</span> IndexNode</span><br><span class="line"></span><br><span class="line"><span class="comment">### Recipe</span></span><br><span class="line"><span class="comment">### Build a recursive retriever that retrieves using small chunks</span></span><br><span class="line"><span class="comment">### but passes associated larger chunks to the generation stage</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">documents = SimpleDirectoryReader(</span><br><span class="line">    input_file=<span class="string">&quot;...&quot;</span></span><br><span class="line">).load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># build parent chunks via NodeParser</span></span><br><span class="line">node_parser = SentenceSplitter(chunk_size=<span class="number">1024</span>)</span><br><span class="line">base_nodes = node_parser.get_nodes_from_documents(documents)</span><br><span class="line"></span><br><span class="line"><span class="comment"># define smaller child chunks</span></span><br><span class="line">sub_chunk_sizes = [<span class="number">256</span>, <span class="number">512</span>]</span><br><span class="line">sub_node_parsers = [</span><br><span class="line">    SentenceSplitter(chunk_size=c, chunk_overlap=<span class="number">20</span>) <span class="keyword">for</span> c <span class="keyword">in</span> sub_chunk_sizes</span><br><span class="line">]</span><br><span class="line">all_nodes = []</span><br><span class="line"><span class="keyword">for</span> base_node <span class="keyword">in</span> base_nodes;</span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> sub_node_parsers:</span><br><span class="line">        sub_nodes = n.get_nodes_from_documents([base_node])</span><br><span class="line">        sub_inodes = [</span><br><span class="line">            IndexNode.from_text_node(sn, base_node.node_id) <span class="keyword">for</span> sn <span class="keyword">in</span> sub_nodes</span><br><span class="line">        ]</span><br><span class="line">        all_nodes.extend(sub_inodes)</span><br><span class="line">    <span class="comment"># also add original node to node</span></span><br><span class="line">    original_node = IndexNode.from_text_node(base_node, base_node.node_id)</span><br><span class="line">    all_nodes.append(original_node)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># define a VectorStoreIndex with all of the nodes</span></span><br><span class="line">vector_index_chunk = VectorStoreIndex(</span><br><span class="line">    all_nodes, service_context=service_context</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># define a VectorStoreIndex with all of the nodes</span></span><br><span class="line">vector_index_chunk = VectorStoreIndex(</span><br><span class="line">    all_nodes, service_context=service_context</span><br><span class="line">)</span><br><span class="line">vector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># build RecursiveRetriever</span></span><br><span class="line">all_node_dict = &#123;n.node_id: n <span class="keyword">for</span> n <span class="keyword">in</span> all_nodes&#125;</span><br><span class="line">retriever_chunk = RecursiveRetriever(</span><br><span class="line">    <span class="string">&quot;vector&quot;</span>,</span><br><span class="line">    retriever_dict=&#123;<span class="string">&quot;vector&quot;</span>: vector_retriever_chunk&#125;,</span><br><span class="line">    node_dict=all_nodes_dict,</span><br><span class="line">    verbose=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># build RetrieverQueryEngine using recursive_retriever</span></span><br><span class="line">query_engine_chunk = RetrieverQueryEngine.from_args(</span><br><span class="line">    retriever_chunk, service_context=service_context</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># perform inference with advanced RAG (i.e. query engine)</span></span><br><span class="line">response = query_engine_chunk.query(</span><br><span class="line">    <span class="string">&quot;Can you tell me about the key concepts for safety finetuning&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="Other-useful-links">Other useful links</h4><p>我们提供了一些指南，展示了在复杂情况下如何应用其他高级技术来确保准确的召回。以下是其中一些选定的链接：</p><ul><li><a href="https://docs.llamaindex.ai/en/stable/examples/query_engine/knowledge_graph_rag_query_engine.html">Building External Knowledge using Knowledge Graphs</a></li><li><a href="https://docs.llamaindex.ai/en/stable/examples/vector_stores/elasticsearch_auto_retriever.html">Performing Mixed Retrieval with Auto Retrievers</a></li><li><a href="https://docs.llamaindex.ai/en/stable/examples/retrievers/simple_fusion.html">Building Fusion Retrievers</a></li><li><a href="https://docs.llamaindex.ai/en/stable/examples/finetuning/embeddings/finetune_embedding.html">Fine-tuning Embedding Models used in Retrieval</a></li><li><a href="https://docs.llamaindex.ai/en/stable/examples/query_transformations/HyDEQueryTransformDemo.html">Transforming Query Embeddings (HyDE)</a></li></ul><h3 id="生成">生成</h3><p>与上一节类似，我们提供了一些高级技术的示例，这些技术的目的是确保召回到的文档能够很好地对齐LLM的生成器。</p><h4 id="Information-Compression">Information Compression</h4><p>大语言模型（LLM）不仅受到上下文长度的限制，而且如果召回到的文档中含有太多的无关信息（也就是噪声），可能会使生成的回答质量下降。</p><p>LlamaIndex Information Compression <a href="https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/LongLLMLingua.html">示例</a> ：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> SimpleDirectoryReader, VectorStoreIndex</span><br><span class="line"><span class="keyword">from</span> llama_index.query_engine <span class="keyword">import</span> RetrieverQueryEngine</span><br><span class="line"><span class="keyword">from</span> llama_index.postprocessor <span class="keyword">import</span> LongLLMLinguaPostprocessor</span><br><span class="line"></span><br><span class="line"><span class="comment">### Recipe</span></span><br><span class="line"><span class="comment">### Define a Postprocessor object, here LongLLMLinguaPostprocessor</span></span><br><span class="line"><span class="comment">### Build QueryEngine that uses this Postprocessor on retrieved docs</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define Postprocessor</span></span><br><span class="line">node_postprocessor = LongLLMLinguaPostprocessor(</span><br><span class="line">    instruction_str=<span class="string">&quot;Given the context, please answer the final question&quot;</span>,</span><br><span class="line">    target_token=<span class="number">300</span>,</span><br><span class="line">    rank_method=<span class="string">&quot;longllmlingua&quot;</span>,</span><br><span class="line">    additional_compress_kwargs=&#123;</span><br><span class="line">        <span class="string">&quot;condition_compare&quot;</span>: <span class="literal">True</span>,</span><br><span class="line">        <span class="string">&quot;condition_in_question&quot;</span>: <span class="string">&quot;after&quot;</span>,</span><br><span class="line">        <span class="string">&quot;context_budget&quot;</span>: <span class="string">&quot;+100&quot;</span>,</span><br><span class="line">        <span class="string">&quot;reorder_context&quot;</span>: <span class="string">&quot;sort&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define VectorStoreIndex</span></span><br><span class="line">documents = SimpleDirectoryReader(input_dir=<span class="string">&quot;...&quot;</span>).load_data()</span><br><span class="line">index = VectorStoreIndex.from_documents(documents)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define QueryEngine</span></span><br><span class="line">retriever = index.as_retriever(similarity_top_k=<span class="number">2</span>)</span><br><span class="line">retriever_query_engine = RetrieverQueryEngine.from_args(</span><br><span class="line">    retriever, node_postprocessor=[node_postprocessor]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Used your advanced RAG</span></span><br><span class="line">response = retriever_query_engine.query(<span class="string">&quot;A user&#x27;s query&quot;</span>)</span><br></pre></td></tr></table></figure><h4 id="Result-Re-Rank">Result Re-Rank</h4><p>大语言模型（LLM）存在被称为“<a href="https://arxiv.org/abs/2307.03172">中间迷失</a>”的现象，即模型主要关注输入提示的两端。因此，在将召回到的文档传递给生成部分之前，对它们进行重新排序是有帮助的。</p><p>LlamaIndex Re-Ranking For Better Generation <a href="https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/CohereRerank.html">示例</a>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> SimpleDirectoryReader, VectorStoreIndex</span><br><span class="line"><span class="keyword">from</span> llama_index.postprocessor.cohere_rerank <span class="keyword">import</span> CohereRerank</span><br><span class="line"><span class="keyword">from</span> llama_index.postprocessor <span class="keyword">import</span> LongLLMLinguaPostprocessor</span><br><span class="line"></span><br><span class="line"><span class="comment">### Recipe</span></span><br><span class="line"><span class="comment">### Define a Postprocessor object, here CohereRerank</span></span><br><span class="line"><span class="comment">### Build QueryEngine that uses this Postprocessor on retrieved docs</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Build CohereRerank post retrieval processor</span></span><br><span class="line">api_key = os.environ[<span class="string">&quot;COHERE_API_KEY&quot;</span>]</span><br><span class="line">cohere_rerank = CohereRerank(api_key=api_key, top_n=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Build QueryEngine (RAG) using the post processor</span></span><br><span class="line">documents = SimpleDirectoryReader(<span class="string">&quot;...&quot;</span>).load_data()</span><br><span class="line">index = VectorStoreIndex.from_documents(documents=documents)</span><br><span class="line">query_engine = index.as_query_engine(</span><br><span class="line">    similarity_top_k=<span class="number">10</span>,</span><br><span class="line">    node_postprocessor=[cohere_rerank],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use your advanced RAG</span></span><br><span class="line">response = query_engine.query(</span><br><span class="line">    <span class="string">&quot;What did Sam Altman do in this essay?&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="召回-生成">召回&amp;生成</h3><p>在这一部分，我们研究了一些高级方法，这些方法利用召回和生成的相互配合，旨在提高召回效果，同时生成出更精确的对用户查询的回应。</p><h4 id="Generator-Enhanced-Retrieval">Generator-Enhanced Retrieval</h4><p>这些方法利用大语言模型的内在推理能力，在进行召回之前优化用户的查询，以便更准确地找出生成有用回应所需的信息。</p><p>LlamaIndex Generator-Enhanced Retrieval <a href="https://docs.llamaindex.ai/en/stable/examples/query_engine/flare_query_engine.html">示例</a>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> llama_index.query_engine <span class="keyword">import</span> FLAREInstructQueryEngine</span><br><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> (</span><br><span class="line">    VectorStoreIndex,</span><br><span class="line">    SimpleDirectoryReader,</span><br><span class="line">    ServiceContext,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">### Recipe</span></span><br><span class="line"><span class="comment">### Build a FLAREInstructQueryEngine which has the generator LLM play</span></span><br><span class="line"><span class="comment">### a more active role in retrieval by prompting it to elicit retrieval</span></span><br><span class="line"><span class="comment">### instructions on what it needs to answer the user query.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Build FLAREInstructQueryEngine</span></span><br><span class="line"></span><br><span class="line">documents = SimpleDirectoryReader(<span class="string">&quot;...&quot;</span>).load_data()</span><br><span class="line">index = VectorStoreIndex.from_documents(documents=documents)</span><br><span class="line">index_query_engine = index.as_query_engine(similarity_top_k=<span class="number">2</span>)</span><br><span class="line">service_context = ServiceContext.from_defaults(llm=OpenAI(model=<span class="string">&quot;gpt-4&quot;</span>)</span><br><span class="line">flare_query_engine = FLAREInstructQueryEngine(</span><br><span class="line">    query_engine=index_query_engine,</span><br><span class="line">    service_context=service_context,</span><br><span class="line">    max_iterations=<span class="number">7</span>,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use your advanced RAG</span></span><br><span class="line">response = flare_query_engine(</span><br><span class="line">    <span class="string">&quot;Can you tell me about the author&#x27;s trajectory in the startup world?&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="Iterative-Retrieval-Generator-RAG">Iterative Retrieval-Generator RAG</h4><p>在一些复杂的场景下，我们可能需要进行多步骤的推理，才能给出对用户查询的有用且相关的回答。</p><p>LlamaIndex Iterative Retrieval-Generator <a href="https://docs.llamaindex.ai/en/stable/examples/evaluation/RetryQuery.html#retry-query-engine">示例</a>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index.query_engine <span class="keyword">import</span> RetryQueryEngine</span><br><span class="line"><span class="keyword">from</span> llama_index.evaluation <span class="keyword">import</span> RelevancyEvaluator</span><br><span class="line"></span><br><span class="line"><span class="comment">### Recipe</span></span><br><span class="line"><span class="comment">### Build a RetryQueryEngine which performs retrieval-generation cycles</span></span><br><span class="line"><span class="comment">### until it either achieves a passing evaluation or a max number of </span></span><br><span class="line"><span class="comment">### cycles has been reached</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Build RetryQueryEngine</span></span><br><span class="line">documents = SimpleDirectoryReader(<span class="string">&quot;...&quot;</span>).load_data()</span><br><span class="line">index = VectorStoreIndex.from_documents(documents=documents)</span><br><span class="line">base_query_engine = index.as_query_engine()</span><br><span class="line">query_response_evaluator = RelevancyEvaluator() <span class="comment"># evaluator to critique retrieval-generation cycles</span></span><br><span class="line"></span><br><span class="line">retry_query_engine = RetryQueryEngine(</span><br><span class="line">    base_query_engine, query_response_evaluator</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use your advanced rag</span></span><br><span class="line">retry_response = retry_query_engine(<span class="string">&quot;A user&#x27;s query&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="RAG的评估指标">RAG的评估指标</h2><p>对 RAG 系统进行评估，无疑是非常重要的。在<a href="https://arxiv.org/pdf/2312.10997.pdf">《Retrieval-Augmented Generation for Large Language Models: A Survey》</a>中，作者们提出了7个评估指标，这些指标在CheetSheet右上角部分有所体现。</p><p>llama-index 库包含了一些评估抽象，还集成了对 RAGAs 的支持，以帮助开发者从这些评估指标的角度，理解他们的 RAG 系统在多大程度上达到了预期的成功要求。下面，我们列举了一些精选的评估笔记本指南:</p><ul><li><a href="https://docs.llamaindex.ai/en/latest/examples/evaluation/answer_and_context_relevancy.html">Answer Relevancy and Context Relevancy</a></li><li><a href="https://www.notion.so/LlamaIndex-Platform-0754edd9af1c4159bde12649c184c8ef?pvs=21">Faithfulness</a></li><li><a href="https://github.com/run-llama/llama_index/blob/main/docs/examples/evaluation/retrieval/retriever_eval.ipynb">Retrieval Evaluation</a></li><li><a href="https://docs.llamaindex.ai/en/stable/examples/evaluation/batch_eval.html">Batch Evaluations with BatchEvalRunner</a></li></ul><h2 id="Reference">Reference</h2><p>希望在你阅读完这篇博客文章后，能有更多的信心和准备，去运用这些精妙的技术来打造先进的 RAG 系统！</p><p><a href="https://blog.llamaindex.ai/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b">A Cheat Sheet and Some Recipes For Building Advanced RAG</a></p>]]></content>
    
    <summary type="html">
    
      一份全面的 RAG 速查手册，详细阐述了选择 RAG 的理由，以及如何运用技巧和策略，超越基础或初阶的 RAG 构建。
    
    </summary>
    
    
      <category term="Way2AI" scheme="https://neo1989.net/categories/Way2AI/"/>
    
    
      <category term="Coder" scheme="https://neo1989.net/tags/Coder/"/>
    
      <category term="AI" scheme="https://neo1989.net/tags/AI/"/>
    
      <category term="RAG" scheme="https://neo1989.net/tags/RAG/"/>
    
  </entry>
  
  <entry>
    <title>正则表达式</title>
    <link href="https://neo1989.net/CheatSheet/CHEATSHEET-Regular-Expressions/"/>
    <id>https://neo1989.net/CheatSheet/CHEATSHEET-Regular-Expressions/</id>
    <published>2024-01-20T08:56:50.000Z</published>
    <updated>2024-01-26T16:29:50.084Z</updated>
    
    <content type="html"><![CDATA[<p>正则表达式用于描述文本模式，因此可以用来检测文本中是否存在特定模式，从更长的字符串中提取出子字符串，或者对文本进行一些调整。正则表达式可以非常简洁，用来描述特定的单词，也可以更复杂一些，用来查找像 URL 中的顶级域名这样的不明确的字符模式。</p><p>本文是基于Python的解析引擎。</p><h2 id="定义">定义</h2><ul><li><p>原字符：原字符是正则表达式中最基础的元素。它直接对应你写下的字符。比如，如果你想要代表一个 “r”，你直接写 r 就可以了。</p></li><li><p>特殊字符：特殊字符用于告诉正则表达式引擎，接下来的字符有特殊的含义。我们通常在特殊字符前面加一个 \ ，它们可以用来表示一行的开头，一行的结尾，或匹配任何单独的字符。</p></li><li><p>字符集：字符集是用来告诉正则表达式引擎，去寻找一组字符中的任意一个。它由 [ 和 ] 表示，你想要寻找的字符就放在这两个括号之间。</p></li><li><p>捕获组：捕获组是由一对圆括号表示的。它们可以让你把多个正则表达式归为一组，然后对这个组应用其他正则表达式的功能，比如量词（后面会提到）。</p></li></ul><h2 id="锚点">锚点</h2><p>锚点用于定位字符的前后位置。</p><table><thead><tr><th style="text-align:center">语法</th><th style="text-align:center">描述</th><th style="text-align:center">示例</th><th style="text-align:center">示例可匹配</th><th style="text-align:center">示例不可匹配</th></tr></thead><tbody><tr><td style="text-align:center">^</td><td style="text-align:center">匹配行首</td><td style="text-align:center">^r</td><td style="text-align:center"><strong>r</strong>abbit <br/> <strong>r</strong>accoon</td><td style="text-align:center">parrot <br/> ferret</td></tr><tr><td style="text-align:center">$</td><td style="text-align:center">匹配行尾</td><td style="text-align:center">t$</td><td style="text-align:center">rabbi<strong>t</strong> <br/> roo<strong>t</strong></td><td style="text-align:center">trap <br/> nice</td></tr><tr><td style="text-align:center">\A</td><td style="text-align:center">匹配行首</td><td style="text-align:center">\Ar</td><td style="text-align:center"><strong>r</strong>abbit <br/> <strong>r</strong>accoon</td><td style="text-align:center">parrot <br/> ferret</td></tr><tr><td style="text-align:center">\Z</td><td style="text-align:center">匹配行尾</td><td style="text-align:center">t\Z</td><td style="text-align:center">rabbi<strong>t</strong> <br/> roo<strong>t</strong></td><td style="text-align:center">trap <br/> nice</td></tr><tr><td style="text-align:center">\b</td><td style="text-align:center">匹配词首或词尾</td><td style="text-align:center">\bfox\b</td><td style="text-align:center">the <strong>fox</strong> ran</td><td style="text-align:center">foxskin</td></tr><tr><td style="text-align:center">\B</td><td style="text-align:center">匹配非空格字符中间的字符</td><td style="text-align:center">\Bee\B</td><td style="text-align:center">b<strong>ee</strong>f</td><td style="text-align:center">tree</td></tr></tbody></table><h2 id="匹配字符类型">匹配字符类型</h2><p>你可以根据字符的类型进行匹配，比如字母、数字等，而不仅仅是特定的字符。</p><table><thead><tr><th style="text-align:center">语法</th><th style="text-align:center">描述</th><th style="text-align:center">示例</th><th style="text-align:center">示例可匹配</th><th style="text-align:center">示例不可匹配</th></tr></thead><tbody><tr><td style="text-align:center">.</td><td style="text-align:center">除了换行之外的所有内容</td><td style="text-align:center">c.e</td><td style="text-align:center"><strong>cle</strong>an <br/> <strong>che</strong>ap</td><td style="text-align:center">acert <br/> cent</td></tr><tr><td style="text-align:center">\d</td><td style="text-align:center">匹配数字</td><td style="text-align:center">\d</td><td style="text-align:center"><strong>6060</strong> ~ <strong>228</strong> <br/> <strong>2</strong>b</td><td style="text-align:center">two <br/> +*+</td></tr><tr><td style="text-align:center">\D</td><td style="text-align:center">匹配非数字</td><td style="text-align:center">\D</td><td style="text-align:center">6060 <strong>~</strong> 228 <br/> 2<strong>b</strong></td><td style="text-align:center">12 <br/> 333</td></tr><tr><td style="text-align:center">\w</td><td style="text-align:center">匹配单词字符</td><td style="text-align:center">\wello\w</td><td style="text-align:center"><strong>hello呀</strong></td><td style="text-align:center">hell呀</td></tr><tr><td style="text-align:center">\W</td><td style="text-align:center">匹配非单词字符</td><td style="text-align:center">hell\W</td><td style="text-align:center"><strong>hell🎸</strong>no</td><td style="text-align:center">hello</td></tr><tr><td style="text-align:center">\s</td><td style="text-align:center">匹配空白</td><td style="text-align:center">hell\s</td><td style="text-align:center">‘<strong>hell\t</strong>no’</td><td style="text-align:center">hello</td></tr><tr><td style="text-align:center">\S</td><td style="text-align:center">匹配非空白</td><td style="text-align:center">hell\S</td><td style="text-align:center"><strong>hello</strong></td><td style="text-align:center">hell no</td></tr><tr><td style="text-align:center">\元字符</td><td style="text-align:center">对元字符进行转义以匹配元字符</td><td style="text-align:center">\.\.\.</td><td style="text-align:center">no <strong>…</strong> no</td><td style="text-align:center">world</td></tr></tbody></table><h2 id="字符集合">字符集合</h2><p>字符集合是一组或一系列的字符。</p><table><thead><tr><th style="text-align:center">语法</th><th style="text-align:center">描述</th><th style="text-align:center">示例</th><th style="text-align:center">示例可匹配</th><th style="text-align:center">示例不可匹配</th></tr></thead><tbody><tr><td style="text-align:center">[xy]</td><td style="text-align:center">匹配指定的任意字符</td><td style="text-align:center">r[ea]</td><td style="text-align:center">g<strong>ra</strong>y <br/> g<strong>re</strong>at</td><td style="text-align:center">grip <br/> groot</td></tr><tr><td style="text-align:center">[x-y]</td><td style="text-align:center">匹配一段连续的字符</td><td style="text-align:center">[a-e]</td><td style="text-align:center"><strong>a</strong>m<strong>be</strong>r <br/> <strong>b</strong>r<strong>a</strong>n<strong>d</strong></td><td style="text-align:center">fox <br/> zoo</td></tr><tr><td style="text-align:center">[^xy]</td><td style="text-align:center">匹配指定之外的字符</td><td style="text-align:center">r[ea]</td><td style="text-align:center">g<strong>ri</strong>p <br/> g<strong>ro</strong>ot</td><td style="text-align:center">gray <br/> great</td></tr><tr><td style="text-align:center">[^-]</td><td style="text-align:center">匹配指定的元字符</td><td style="text-align:center">4[\^\.]\d</td><td style="text-align:center"><strong>4.2</strong> <br/> <strong>4^3</strong></td><td style="text-align:center">44 <br/> 33</td></tr></tbody></table><h2 id="重复">重复</h2><p>你可以找出重复出现的字符，而不仅仅是单个的字符。</p><table><thead><tr><th style="text-align:center">语法</th><th style="text-align:center">描述</th><th style="text-align:center">示例</th><th style="text-align:center">示例可匹配</th><th style="text-align:center">示例不可匹配</th></tr></thead><tbody><tr><td style="text-align:center">x*</td><td style="text-align:center">匹配0个或多个</td><td style="text-align:center">ar*o</td><td style="text-align:center">cac<strong>ao</strong> <br/> c<strong>arro</strong>t</td><td style="text-align:center">arugula <br/> artichoke</td></tr><tr><td style="text-align:center">x+</td><td style="text-align:center">匹配1个或多个</td><td style="text-align:center">re+</td><td style="text-align:center">g<strong>ree</strong>n <br/> t<strong>ree</strong></td><td style="text-align:center">trap <br/> ruined</td></tr><tr><td style="text-align:center">x?</td><td style="text-align:center">匹配0个或1个</td><td style="text-align:center">ro?a</td><td style="text-align:center"><strong>roa</strong>st <br/> <strong>ra</strong>nt</td><td style="text-align:center">root <br/> rear</td></tr><tr><td style="text-align:center">x{m}</td><td style="text-align:center">匹配m次</td><td style="text-align:center">\we{2}\w</td><td style="text-align:center"><strong>deer</strong> <br/> <strong>seer</strong></td><td style="text-align:center">red <br/> enter</td></tr><tr><td style="text-align:center">x{m,}</td><td style="text-align:center">匹配m次或更多</td><td style="text-align:center">2{3,}4</td><td style="text-align:center"><strong>2222224</strong></td><td style="text-align:center">224</td></tr><tr><td style="text-align:center">x{m,n}</td><td style="text-align:center">匹配m到n之间的次数</td><td style="text-align:center">2{2,3}4</td><td style="text-align:center"><strong>224</strong> <br/> <strong>2224</strong></td><td style="text-align:center">24 <br/> 22224</td></tr><tr><td style="text-align:center">x+?</td><td style="text-align:center">尽可能少地匹配，懒惰模式</td><td style="text-align:center">re+?</td><td style="text-align:center">t<strong>re</strong>eeeee</td><td style="text-align:center">trout</td></tr></tbody></table><h2 id="捕获，选择与反向引用">捕获，选择与反向引用</h2><p>如果你想从一段字符串中提取特定的部分，你可以进行捕获操作，甚至可以给你捕获的这些部分命名。</p><table><thead><tr><th style="text-align:center">语法</th><th style="text-align:center">描述</th><th style="text-align:center">示例</th><th style="text-align:center">示例可匹配</th><th style="text-align:center">示例不可匹配</th></tr></thead><tbody><tr><td style="text-align:center">(x)</td><td style="text-align:center">捕获一个模式</td><td style="text-align:center">(iss)+</td><td style="text-align:center">M<strong>ississ</strong>ippi <br/> m<strong>iss</strong>ed</td><td style="text-align:center">mist <br/> persist</td></tr><tr><td style="text-align:center">(?:x)</td><td style="text-align:center">匹配但不捕获</td><td style="text-align:center">(?:ab)(cd)</td><td style="text-align:center">ab<strong>cd</strong></td><td style="text-align:center">accd</td></tr><tr><td style="text-align:center">(?P&lt;name&gt;x)</td><td style="text-align:center">捕获且命名</td><td style="text-align:center">(?P&lt;a&gt;\d)(?P&lt;b&gt;\d)\d*</td><td style="text-align:center"><strong>1325</strong> <br/> a: 1 <br/> b: 3</td><td style="text-align:center">2</td></tr><tr><td style="text-align:center">(x</td><td style="text-align:center">y)</td><td style="text-align:center">匹配多种可能的模式</td><td style="text-align:center">(re</td><td style="text-align:center">ba)</td></tr><tr><td style="text-align:center">\n</td><td style="text-align:center">引用之前的捕获，其中 n 是组索引，从 1 开始编号</td><td style="text-align:center">(b)(\w*)\1</td><td style="text-align:center"><strong>blob</strong> <br/> <strong>brib</strong>e</td><td style="text-align:center">bear <br/> bring</td></tr><tr><td style="text-align:center">(?P=name)</td><td style="text-align:center">引用已命名的捕获</td><td style="text-align:center">(?P&lt;a&gt;5)(\d*)(?P=a)</td><td style="text-align:center"><strong>51245</strong> <br/> <strong>55</strong></td><td style="text-align:center">523</td></tr></tbody></table><h2 id="前瞻后顾">前瞻后顾</h2><p>你可以设定一些特定的字符必须在你的匹配项前后出现，但这些字符并不会被包含进匹配结果中。</p><table><thead><tr><th style="text-align:center">语法</th><th style="text-align:center">描述</th><th style="text-align:center">示例</th><th style="text-align:center">示例可匹配</th><th style="text-align:center">示例不可匹配</th></tr></thead><tbody><tr><td style="text-align:center">(?=x)</td><td style="text-align:center">预览接下来的字符，但不把它们纳入匹配结果中</td><td style="text-align:center">an(?=an)</td><td style="text-align:center">b<strong>an</strong>ana</td><td style="text-align:center">band</td></tr><tr><td style="text-align:center">(?!x)</td><td style="text-align:center">预览下一个字符以避免匹配</td><td style="text-align:center">ai(?!n)</td><td style="text-align:center">f<strong>ai</strong>l</td><td style="text-align:center">faint</td></tr><tr><td style="text-align:center">(?&lt;=x)</td><td style="text-align:center">检查前面的字符以进行匹配，但不会把这些字符纳入匹配结果中</td><td style="text-align:center">(?&lt;=tr)a</td><td style="text-align:center">tr<strong>a</strong>il</td><td style="text-align:center">tail</td></tr><tr><td style="text-align:center">(?&lt;!x)</td><td style="text-align:center">查看前面的字符以避免匹配</td><td style="text-align:center">(?!tr)a</td><td style="text-align:center">be<strong>a</strong>r</td><td style="text-align:center">trail</td></tr></tbody></table><h2 id="Reference">Reference</h2><p><a href="https://www.datacamp.com/cheat-sheet/regular-expresso">Regular Expressions</a></p>]]></content>
    
    <summary type="html">
    
      能极大地提升我们对文本数据的处理能力。
    
    </summary>
    
    
      <category term="CheatSheet" scheme="https://neo1989.net/categories/CheatSheet/"/>
    
    
      <category term="Coder" scheme="https://neo1989.net/tags/Coder/"/>
    
      <category term="AI" scheme="https://neo1989.net/tags/AI/"/>
    
      <category term="NLP" scheme="https://neo1989.net/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Way2AI · 语义搜索</title>
    <link href="https://neo1989.net/Way2AI/Way2AI-Semantic-Search/"/>
    <id>https://neo1989.net/Way2AI/Way2AI-Semantic-Search/</id>
    <published>2024-01-10T04:21:28.000Z</published>
    <updated>2024-01-13T06:55:59.489Z</updated>
    
    <content type="html"><![CDATA[<p>语义搜索通过理解搜索查询的内容来提高搜索准确性。与传统搜索引擎不同，传统搜索引擎仅根据词法匹配查找文档，而语义搜索还可以找到同义词。</p><h3 id="背景">背景</h3><p>语义搜索的基本思想是将语料库中的所有条目（无论是句子、段落还是文档）都嵌入到一个向量空间中。</p><p>在搜索时，查询会被嵌入到相同的向量空间中，然后从语料库中找到与查询最接近的嵌入。这些嵌入应该与查询具有高度语义重叠。</p><p><img src="//s3.mindex.xyz/blog/Courses/a88a6ad41612242bacf9371252618da4.png" alt=""></p><h3 id="对称与非对称">对称与非对称</h3><p>对称语义搜索是指你的查询和语料库中的条目长度大致相同，并且具有相同数量的内容。一个例子是: 通过搜索类似的问题 “如何在线学习 Python？” ，你想找到一个像“如何在网络上学习 Python？”这样的条目。对于对称任务，你可能可以在语料库中翻找到查询和对应的条目。</p><p>非对称语义搜索是指你通常有一个简短的查询（例如一个问题或一些关键词），你想找到一个更长的段落来回答查询。像 “什么是 Python” 的查询，你想找到段落“Python 是一种解释型、高级且通用的编程语言。Python 的设计理念是……”。对于非对称任务，在语料库中翻找通常没有意义。</p><p>选择适合任务类型的模型非常重要。</p><p>适合对称语义搜索的模型：<a href="https://www.sbert.net/docs/pretrained_models.html#sentence-embedding-models">Pre-Trained Sentence Embedding Models</a></p><p>适合非对称语义搜索的模型：<a href="https://www.sbert.net/docs/pretrained-models/msmarco-v3.html">Pre-Trained MS MARCO Models</a></p><h3 id="Python">Python</h3><p>在数据量不大的语料库中（条目数量最多大约100万），我们有能力计算出搜索词与语料库内每一个条目之间的余弦相似度。</p><p>在接下来的示例中，我们创建了一个包括几个样本句子的小型语料库，并为这个语料库以及我们的搜索词分别计算了它们的嵌入向量。</p><p>接着，我们运用 <code>sentence_transformers.util.cos_sim()</code> 函数来测量搜索词与语料库中所有条目之间的余弦相似性。</p><p>面对庞大的语料库，对所有评分逐一排序实在是效率太低。所以，我们采用了 <code>torch.topk</code> 函数来直接提取得分最高的前 k 个条目。</p><p>下面是一个简单的示例；参见 <a href="https://github.com/UKPLab/sentence-transformers/tree/master/examples/applications/semantic-search/semantic_search.py">semantic_search.py</a>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">This is a simple application for sentence embeddings: semantic search</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">We have a corpus with various sentences. Then, for a given query sentence,</span></span><br><span class="line"><span class="string">we want to find the most similar sentence in this corpus.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">This script outputs for various queries the top 5 most similar sentences in the corpus.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer, util</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">embedder = SentenceTransformer(<span class="string">&#x27;all-MiniLM-L6-v2&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Corpus with example sentences</span></span><br><span class="line">corpus = [</span><br><span class="line">    <span class="string">&#x27;A man is eating food.&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;A man is eating a piece of bread.&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;The girl is carrying a baby.&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;A man is riding a horse.&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;A woman is playing violin.&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Two men pushed carts through the woods.&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;A man is riding a white horse on an enclosed ground.&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;A monkey is playing drums.&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;A cheetah is running behind its prey.&#x27;</span></span><br><span class="line">]</span><br><span class="line">corpus_embeddings = embedder.encode(corpus, convert_to_tensor=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Query sentences:</span></span><br><span class="line">queries = [<span class="string">&#x27;A man is eating pasta.&#x27;</span>, <span class="string">&#x27;Someone in a gorilla costume is playing a set of drums.&#x27;</span>, <span class="string">&#x27;A cheetah chases prey on across a field.&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity</span></span><br><span class="line">top_k = <span class="built_in">min</span>(<span class="number">5</span>, <span class="built_in">len</span>(corpus))</span><br><span class="line"><span class="keyword">for</span> query <span class="keyword">in</span> queries:</span><br><span class="line">    query_embedding = embedder.encode(query, convert_to_tensor=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># We use cosine-similarity and torch.topk to find the highest 5 scores</span></span><br><span class="line">    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[<span class="number">0</span>]</span><br><span class="line">    top_results = torch.topk(cos_scores, k=top_k)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n\n======================\n\n&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Query:&quot;</span>, query)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\nTop 5 most similar sentences in corpus:&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> score, idx <span class="keyword">in</span> <span class="built_in">zip</span>(top_results[<span class="number">0</span>], top_results[<span class="number">1</span>]):</span><br><span class="line">        <span class="built_in">print</span>(corpus[idx], <span class="string">&quot;(Score: &#123;:.4f&#125;)&quot;</span>.<span class="built_in">format</span>(score))</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    # Alternatively, we can also use util.semantic_search to perform cosine similarty + topk</span></span><br><span class="line"><span class="string">    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=5)</span></span><br><span class="line"><span class="string">    hits = hits[0]      #Get the hits for the first query</span></span><br><span class="line"><span class="string">    for hit in hits:</span></span><br><span class="line"><span class="string">        print(corpus[hit[&#x27;corpus_id&#x27;]], &quot;(Score: &#123;:.4f&#125;)&quot;.format(hit[&#x27;score&#x27;]))</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><h3 id="速度优化">速度优化</h3><p>要想让 <code>sentence_transformers.util.cos_sim()</code> 方法运行得更快，最好的做法是将 <code>query_embeddings</code> 和 <code>corpus_embeddings</code> 存在同一块 GPU 设备上。这样做可以明显提升处理性能。</p><p>另外，我们还可以对语料库嵌入进行标准化处理，使每个语料库嵌入的长度都为 1。这样，我们就可以通过点积运算来计算得分了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">corpus_embeddings = corpus_embeddings.to(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">corpus_embeddings = util.normalize_embeddings(corpus_embeddings)</span><br><span class="line"></span><br><span class="line">query_embeddings = query_embeddings.to(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">query_embeddings = util.normalize_embeddings(query_embeddings)</span><br><span class="line">hits = util.semantic_search(query_embeddings, corpus_embeddings, score_function=util.dot_score)</span><br></pre></td></tr></table></figure><h3 id="ElasticSearch">ElasticSearch</h3><p>从 7.3 版本开始，<a href="https://www.elastic.co/elasticsearch/">ElasticSearch</a> 推出了一个新功能，即能够索引密集向量 (dense vectors)，并将其用于对文档进行评分。所以，我们可以利用 ElasticSearch 对文档以及嵌入向量（embeddings）进行索引，以此在搜索时使用对应的嵌入向量寻找相关的文档信息。</p><p>ElasticSearch的一个优点是，它便于向索引中添加新的文档，而且能够和我们的向量一起存储其他数据。但缺点是它的性能较慢，这是因为它需要将搜索的嵌入内容和每一个已经存储的嵌入内容进行比较。这种操作的时间成本是线性的，对于大规模（超过 100k）的数据集来说，可能会慢得无法接受。</p><p>更多详细信息，请参见 <a href="https://github.com/UKPLab/sentence-transformers/tree/master/examples/applications/semantic-search/semantic_search_quora_elasticsearch.py">semantic_search_quora_elasticsearch.py</a>。</p><h3 id="近似最近邻点">近似最近邻点</h3><p>如果使用精确的最近邻搜索方法（如 <code>sentence_transformers.util.semantic_search</code> 所采用的方式），在一个巨大的语料库中进行查找，特别是这个语料库中包含数百万个嵌入，可能会花费大量的时间。</p><p>在这种情况下，近似最近邻（Approximate Nearest Neighor，ANN）可能会很有帮助。这里，数据被划分为相似的嵌入小部分。利用索引可以有效地进行搜索，甚至在有数百万的向量时也能在毫秒内检索到最高相似性的嵌入（即最近的邻居）。</p><p>不过，结果未必都是精确的。可能有些具有高度相似性的向量被遗漏了。这就是我们称它为“近似最近邻居”的原因。</p><p>所有的人工神经网络（ANN）方法都通常需要调整一到多个参数，以达到召回率与搜索速度的权衡。如果你追求极高的搜索速度，可能会错过一些重要的搜索结果。反之，如果你期望得到高召回率，搜索的速度就可能会变慢。</p><p>近似最近邻搜索库中，<a href="https://github.com/spotify/annoy" title="Annoy">Annoy</a>、<a href="https://github.com/facebookresearch/faiss" title="FAISS">FAISS</a> 和 <a href="https://github.com/nmslib/hnswlib/" title="hnswlib">hnswlib</a> 都很热门。但是，我个人更偏向 <code>hnswlib</code>，因为它不仅使用起来十分简单，性能卓越，而且包含了许多在实际应用中至关重要的特色功能。</p><p>示例：</p><ul><li><a href="https://github.com/UKPLab/sentence-transformers/tree/master/examples/applications/semantic-search/semantic_search_quora_hnswlib.py" title="semantic_search_quora_hnswlib.py">semantic_search_quora_hnswlib.py</a></li><li><a href="https://github.com/UKPLab/sentence-transformers/tree/master/examples/applications/semantic-search/semantic_search_quora_annoy.py" title="semantic_search_quora_annoy.py">semantic_search_quora_annoy.py</a></li><li><a href="https://github.com/UKPLab/sentence-transformers/tree/master/examples/applications/semantic-search/semantic_search_quora_faiss.py" title="semantic_search_quora_faiss.py">semantic_search_quora_faiss.py</a></li></ul><h3 id="召回和重排">召回和重排</h3><p>对于复杂的语义搜索场景，建议使用「召回和重排」流程：</p><p><img src="//s3.mindex.xyz/blog/Courses/3d66117e5374e1f95d858d7d422fc22e.png" alt=""></p><p>当我们有一个搜索请求时，我们会首先使用一个检索系统，这个系统能够找出大约 100 个可能的结果，这些结果可能与我们的搜索请求相关。在进行检索时，我们可以选择使用词汇搜索，比如说使用 ElasticSearch 这样的工具，或者我们也可以选择使用双向编码器进行深度检索。</p><p>但是，这个检索系统可能会找到一些与搜索请求并不太相关的文档。因此，在第二步，我们会使用一个基于交叉编码器的重新排序系统，这个系统会评估所有候选结果与搜索请求的相关性。</p><p>最终，我们将得到一个排名的结果列表，这个列表可以直接呈现给用户。</p><h4 id="召回-Bi-Encoder">召回: Bi-Encoder</h4><p>在寻找候选结果集的过程中，我们可以选择使用词汇搜索（比如 ElasticSearch），或者我们也可以选择使用在这个代码库中实现的双向编码器。</p><p>词汇搜索是在你的文档库中寻找与查询词完全匹配的内容，它无法识别同义词、缩写或拼写的不同形式。而语义搜索（也被称为密集检索）则是将搜索的关键词转化为向量空间的形式，然后找出在这个向量空间中与其最接近的文档。</p><p>语义搜索弥补了词汇搜索的不足，能够识别同义词和缩写词。</p><h4 id="重排：Cross-Encoder">重排：Cross-Encoder</h4><p>检索器需要能够高效处理包含数百万条目的大型文档库。但是，有时候它可能会找出一些与查询无关的结果。</p><p>利用 Cross-Encoder 的重新排序技术，我们可以大幅提升搜索结果的质量。在这个过程中，我们会把搜索请求和可能的文档同时输入到 Transformer 网络中，然后网络会输出一个介于 0 到 1 之间的分数，这个分数代表了文档与搜索请求的匹配程度。</p><p><img src="s3.mindex.xyz/blog/Courses/73b1bebb8fcf7b548f1828585c696898.png" alt=""></p><p>Cross-Encoders的优势在于它们能提供更出色的性能，这是因为它们能在处理查询和文档时运用注意力机制。</p><p>如果我们要对大量的（查询，文档）对进行评分，那将会非常耗时。所以，我们采用的策略是使用检索器先生成一组可能的候选者，比如 100 个，然后再通过 Cross-Encoder 对这些候选者进行重新排序。</p><h3 id="完整示例">完整示例</h3><h4 id="相似问题检索">相似问题检索</h4><p><a href="https://github.com/UKPLab/sentence-transformers/tree/master/examples/applications/semantic-search/semantic_search_quora_pytorch.py">semantic_search_quora_pytorch.py</a> [<a href="https://colab.research.google.com/drive/11GunvCqJuebfeTlgbJWkIMT0xJH6PWF1?usp=sharing">Colab Version</a>] 是一个基于Quora重复问题数据集的应用案例。通过它，用户可以输入任何问题，然后代码会运用 <code>sentence_transformers.util.semantic_search</code> 方法从数据集中找出与输入问题最相近的问题。模型是 distilbert-multilingual-nli-stsb-quora-ranking，它的主要任务是去识别类似的问题，并且它支持超过50种语言。所以，无论用户用这50多种语言中的何种来提问，都可以得到有效的答案。这是一个对称的搜索任务，因为搜索查询的长度和内容与语料库中的问题相同。</p><h4 id="相似出版物检索">相似出版物检索</h4><p><a href="https://github.com/UKPLab/sentence-transformers/tree/master/examples/applications/semantic-search/semantic_search_publications.py">semantic_search_publications.py</a> [<a href="https://colab.research.google.com/drive/12hfBveGHRsxhPIUMmJYrll2lFU4fOX06?usp=sharing">Colab Version</a>] 这个示例演示了如何找到与某篇科学论文相似的其他论文。我们的语料库由在 EMNLP 2016 - 2018 会议上发表的所有论文组成。在搜索过程中，我们会输入最近发表的论文的标题和摘要，然后在我们的语料库中寻找相关的论文。我们使用的是 <a href="https://arxiv.org/abs/2004.07180">SPECTER</a> 模型。这个搜索任务是对称的，因为我们的语料库中的论文和我们搜索的内容都是由标题和摘要组成。</p><h4 id="问答检索">问答检索</h4><p><a href="https://github.com/UKPLab/sentence-transformers/tree/master/examples/applications/semantic-search/semantic_search_wikipedia_qa.py">semantic_search_wikipedia_qa.py</a> [<a href="https://colab.research.google.com/drive/11GunvCqJuebfeTlgbJWkIMT0xJH6PWF1?usp=sharing">Colab Version</a>]：这个例子展示了一个在 <a href="https://ai.google.com/research/NaturalQuestions/">Natural Questions dataset</a> 数据集上进行训练的模型。这个数据集包含了大约十万条真实的 Google 搜索请求，以及从维基百科获取并附带注解的段落，这些段落提供了问题的答案。这是一个非对称搜索任务的典型例子。在这个例子中，我们使用了体积较小的 <a href="https://simple.wikipedia.org/wiki/Main_Page">Simple English Wikipedia</a> 作为语料库，这样它就可以轻松地加载到内存中。</p><p><a href="https://github.com/UKPLab/sentence-transformers/tree/master/examples/applications/retrieve_rerank/retrieve_rerank_simple_wikipedia.py">retrieve_rerank_simple_wikipedia.py</a> [<a href="https://colab.research.google.com/github/UKPLab/sentence-transformers/blob/master/examples/applications/retrieve_rerank/retrieve_rerank_simple_wikipedia.ipynb">Colab Version </a>]：这个脚本采用了 <strong>召回和重排</strong> 的策略，是一个非对称搜索任务的典型例子。我们把所有维基百科的文章切分成各个段落，并用双向编码器进行编码处理。当有新的查询或问题输入时，我们也用同样的双向编码器进行编码，然后找出与之余弦相似度最高的段落。然后，我们用一个交叉编码器对找到的候选段落进行重新排序，最终将得分最高的5个段落展示给用户。我们使用的模型是在 <a href="https://github.com/microsoft/MSMARCO-Passage-Ranking/">MS Marco Passage Reranking datase</a> 数据集上进行训练的，这个数据集包含了大约 500k 来自 Bing 搜索的真实查询。</p><h3 id="Reference">Reference</h3><p><a href="https://www.sbert.net/examples/applications/semantic-search/README.html">Semantic Search</a></p>]]></content>
    
    <summary type="html">
    
      语义搜索通过理解搜索查询的内容来提高搜索准确性。
    
    </summary>
    
    
      <category term="Way2AI" scheme="https://neo1989.net/categories/Way2AI/"/>
    
    
      <category term="Coder" scheme="https://neo1989.net/tags/Coder/"/>
    
      <category term="AI" scheme="https://neo1989.net/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>《我就是你啊》</title>
    <link href="https://neo1989.net/Notes/NOTE-Sept-graines-de-lumiere-dans-le-coeur-des-guerriers/"/>
    <id>https://neo1989.net/Notes/NOTE-Sept-graines-de-lumiere-dans-le-coeur-des-guerriers/</id>
    <published>2024-01-06T12:20:47.000Z</published>
    <updated>2024-02-18T13:50:18.460Z</updated>
    
    <content type="html"><![CDATA[<p>必要前提：记住“武力对抗”会适得其反。在整个余人交流的过程中，都要避免陷入<strong>解释</strong>、<strong>威胁</strong>和<strong>人身攻击</strong>的怪圈当中。</p><h3 id="第一步：平复自己的情绪">第一步：平复自己的情绪</h3><p>当我们感觉内心出现了想要攻击对方的冲动时，我们需要尽力控制住它。比如，我们可以通过以下几种方法做到这一点：</p><ul><li>纠正对事实的误判；</li><li>通过深呼吸来分散注意力；</li><li>或只需收住自己想要伸出的拳头；</li><li>或其他任何一种可能奏效的方法。</li></ul><p>在与人交流的过程中，每当你感到内心再次燃起了这种冲动，就需要在脑海里回顾这一步。完成这一步只需要几秒钟的时间，这大概是最难完成，也是最重要的一步。</p><h3 id="第二步：平复他人的情绪">第二步：平复他人的情绪</h3><p>如果与你对话的人能够保持冷静，那就好说了，你就可以直接跳过这一步。但是如果对方不冷静呢，你又该怎么做？答案是 “什么也不要做”，或者说 “几乎什么也不要做”。尤其不要和对方说“你冷静点儿！”或者“你生气是没有用的！”。此时你应该遵循“<strong>不唱反调，不做评判</strong>”的原则。具体如何做到这一点呢？你可以用 “同意” “好的” “是的” “没错” 等来回复对方。这些字眼可以向对方传达一种信息：“你这样说以及你选择以这样的方式说，自然有你的道理。我愿意与你探讨这个问题。”这样做你会收获到惊人的效果：对方的情绪起初会有些波动，但随后便会逐渐稳定，直到最后慢慢平复。实现这一步，只需要你说出 “<strong>我同意</strong>” 的一刹那就够了。 如果你成功控制住了自己的情绪，又成功平复了他人的情绪，那就可以进入下一步了。</p><h3 id="第三步：试着理解他人而非让他人被理解">第三步：试着理解他人而非让他人被理解</h3><p>如何做到这一步呢？最简单的方法就是 “<strong>向对方提问</strong>”。最有效的问题就是：“你为什么步同意我的观点呢？”之后便要倾听他的回答，并试着站在他们的角度看问题，甚至是设身处地地为他人的利益着想。努力去理解和接受别人的观点，而非将自己的观点强加于人。</p><p>你要学会从他们在做解释时所说的话语中寻找双方的“共识”，并欣然接受对方的观点。这是双方达成“共识”的先决条件。这时候你多一些对别人的“私心”：让自己多为对方的利益考虑！。</p><p>一旦你理解了他人的想法，解决方法便会自己现身，分歧也就迎刃而解了。但通常来说，做到这一点还不够，你需要继续完成下一步…</p><h3 id="第四步：通过复述别人的话来让对方明白“你以及理解了对方的观点”">第四步：通过复述别人的话来让对方明白“你以及理解了对方的观点”</h3><p>如果你想让别人倾听你的观点，你需要先让对方发言。然后再用自己的话将你所理解的对方的观点讲一遍。之后问对方 “我说得对吗？”。这样你会收获意想不到的神奇效果——对方会眉头上扬，露出满意的笑容，大赞一声“对啊！”。而后他便会闭上嘴，听你说话。复述有两个好处：第一，你可以检验一下自己是否真的理解了对方的观点；第二，让你的对话者知道自己被人理解了，进而打消继续争论的念头。</p><p>但实现这一步有一个前提条件——不要因为用错了一个词，让你之前的努力都付之东流。这个词就是接下来这一步的关键词。这个词的使用也是一门艺术。</p><h3 id="第五步：使用表并列的词汇提出自己的观点，而非将双方观点对立">第五步：使用表并列的词汇提出自己的观点，而非将双方观点对立</h3><p>如何做到这一点呢？你可以运用以下这些字眼，比如：就我而言、对我来说、与此同时、从我的角度出发…而不要用极其生硬的 “没错，但是…”。然后等到双方都明确了对方的观点之后，问问你自己 “如何才能让对方的诉求得到满足，同时又能达到自己的目的呢？”。如此一来，你就可以发挥两个人的聪明材质，来寻求解决方案。接下来，我们开始进入第六步。</p><h3 id="第六步：提出解决方案">第六步：提出解决方案</h3><p>采用可能的双赢方案。如果我们自己找不到可行的方案，试着问问别人有没有好主意吧。让拿回我们可以一起针对其进行讨论。</p><p>如果找不到任何双赢的方法，我们可以采用妥协折中的方式解决问题。人们往往会接受折中的方案，因为这样至少恩纳锅够建立友好写作的关系。</p><p>那么，如果连折中的方案也不存在呢？这种情况非常罕见，但并非绝不可能发生。此时，可以与对方协商，再花点时间一起探讨可能的出路。尽管最终不一定能找到解决方案，但至少维持了良好的关系。而这种良性关系对于未来协作的达成至关重要。</p><p><img src="https://s3.mindex.xyz/blog/Notes/bf65eb5d1adba66e1f624e828eaf5b7f.png" alt=""></p><h3 id="Reference">Reference</h3><p>[1] <a href="https://book.douban.com/subject/35445960/">我就是你啊 : 走进他人内心的7项修炼</a></p>]]></content>
    
    <summary type="html">
    
      化解一场纷争需要经历哪些重要的步骤？
    
    </summary>
    
    
      <category term="Notes" scheme="https://neo1989.net/categories/Notes/"/>
    
    
      <category term="SoftSkills" scheme="https://neo1989.net/tags/SoftSkills/"/>
    
      <category term="Wisdom" scheme="https://neo1989.net/tags/Wisdom/"/>
    
  </entry>
  
  <entry>
    <title>日落收集 (二)</title>
    <link href="https://neo1989.net/SeizeTheDay/COLLECTION-sunsets-2/"/>
    <id>https://neo1989.net/SeizeTheDay/COLLECTION-sunsets-2/</id>
    <published>2023-12-31T14:34:15.000Z</published>
    <updated>2024-02-18T05:53:03.288Z</updated>
    
    <content type="html"><![CDATA[<h3 id="May-20-2023">May 20, 2023</h3><p><img src="//s3.mindex.xyz/blog/Notes/a8dcfd31636d678b6bc786345a7342a9.png" alt="西湖·太子湾公园 | 浙江"></p><h3 id="May-13-2023">May 13, 2023</h3><p><img src="//s3.mindex.xyz/blog/Notes/02be63a08b4d3f50fe9f022c13f21291.png" alt="清水路·环湖大道 | 苏州"></p><h3 id="Apr-15-2023">Apr 15, 2023</h3><p><img src="//s3.mindex.xyz/blog/Notes/97765437415756031a4b064691e3fc5e.png" alt="清水路·环湖大道 | 苏州"></p><h3 id="Mar-11-2023">Mar 11, 2023</h3><p><img src="//s3.mindex.xyz/blog/Sunsets/d1c296dc199be5df7087034673e4267a.png" alt="On the Rock @ NamPhrae | Thailand"></p><h3 id="Mar-10-2023">Mar 10, 2023</h3><p><img src="//s3.mindex.xyz/blog/Sunsets/3454d0d46192236de9293e1261e6a65c.png" alt="Route 107 | Thailand"></p><h3 id="Mar-4-2023">Mar 4, 2023</h3><p><img src="//s3.mindex.xyz/blog/Sunsets/7d8d79718363def5e1f35fc64c131589.png" alt="米堆山 | 苏州"></p><h3 id="Jan-30-2023">Jan 30, 2023</h3><p><img src="//s3.mindex.xyz/blog/Sunsets/cb9d279f773c498fb81893d84e3801a1.png" alt="滨江中路 | 上海"></p>]]></content>
    
    <summary type="html">
    
      日落尤其温柔，人间皆是浪漫。
    
    </summary>
    
    
      <category term="SeizeTheDay" scheme="https://neo1989.net/categories/SeizeTheDay/"/>
    
    
  </entry>
  
  <entry>
    <title>高效做事的底层逻辑</title>
    <link href="https://neo1989.net/Notes/NOTE-work-efficiently/"/>
    <id>https://neo1989.net/Notes/NOTE-work-efficiently/</id>
    <published>2023-12-15T09:26:25.000Z</published>
    <updated>2023-12-17T06:03:20.899Z</updated>
    
    <content type="html"><![CDATA[<h2 id="第一步：WOOP模型，让你对目标动力十足">第一步：WOOP模型，让你对目标动力十足</h2><p><strong>W</strong>ish: 明确愿望和目标是什么？<br><strong>O</strong>utcome: 实现愿望后有什么收获？<br><strong>O</strong>bstacle: 追求目标过程中有哪些障碍？<br><strong>P</strong>lan: 制定什么样的计划来克服那些障碍？</p><h2 id="第二步：SMART法则，设定更科学的目标">第二步：SMART法则，设定更科学的目标</h2><p><strong>S</strong>pecific: 目标设定必须明确具体，很多目标之所以不能实现，就是因为设定之初模棱两可。<br><strong>M</strong>easureable: 所谓可衡量，就是要有一组明确的数据。用数据作为衡量目标是否实现的标准。<br><strong>A</strong>ttainable: 设定的目标要在自己的能力范围之内。<br><strong>R</strong>elevant: 所设立ide目标要与其他目标相关联。<br><strong>T</strong>ime-bound: 目标是要有时间限制的。设定一个目标完成的期限，促进目标的达成。</p><h2 id="第三步：用GRAI定期复盘">第三步：用GRAI定期复盘</h2><p><strong>G</strong>oal: 当初立了哪些flag。期望的结果是什么？<br><strong>R</strong>esult: 对照目标，完成的怎么样了？<br><strong>A</strong>nalysis: 成功或失败的关键原因是什么？<br><strong>I</strong>nsight: 得失的体会是什么？是否有规律性的东西值得思考并指导下一次行动计划？</p><h2 id="第四步：用PDCA不断优化">第四步：用PDCA不断优化</h2><p><strong>P</strong>lan:<br>- 分析现状，找出问题<br>- 分析产生问题的影响因素<br>- 找出主要因素<br>- 设定目标，指定计划</p><p><strong>D</strong>o: 按照预订计划，努力实现预期目标</p><p><strong>C</strong>heck: 评估结果，检查效果，分析原因</p><p><strong>A</strong>ction:<br>- 将成功经验进行标准化及流程制定，作为下次行动的参考<br>- 总结经验和问题，为开展新一轮PDCA提供依据</p>]]></content>
    
    <summary type="html">
    
      4个步骤让你效率暴涨。
    
    </summary>
    
    
      <category term="Notes" scheme="https://neo1989.net/categories/Notes/"/>
    
    
      <category term="SoftSkills" scheme="https://neo1989.net/tags/SoftSkills/"/>
    
  </entry>
  
  <entry>
    <title>查理·芒格 语录</title>
    <link href="https://neo1989.net/Notes/NOTE-Charles-Thomas-Munger/"/>
    <id>https://neo1989.net/Notes/NOTE-Charles-Thomas-Munger/</id>
    <published>2023-11-29T07:36:36.000Z</published>
    <updated>2023-12-17T09:21:12.799Z</updated>
    
    <content type="html"><![CDATA[<h2 id="关于认知">关于认知</h2><ul><li>变化总在发生，你不去迎接进步的变化，就会等到退步的变化。</li><li>我们能取得今时今日的成就，不是因为我们的能力比别人高出多少，而是我们比别人更清楚自己能力的大小。</li><li>决定结果的主要有两个因素：一个是形势，一个是人。形势太强，任凭你有多大能力，都无济于事。</li><li>一个人，手里拿着锤子，看什么都像钉子。</li><li>只要做好准备，在人生中抓住几个机会。迅速地采取适当的行动，去做简单而合乎逻辑的事情，这辈子的财富就会得到极大的增长。</li><li>我们很清楚自己的不足，很清楚有很多试我们做不到，所以我们谨小慎微地留在我们的“能力圈”中。“能力圈”是沃伦提出的概念。沃伦和我都认为，我们的“能力圈”是一个非常小的圆圈。</li><li>在显示世界中，学会看透本质，我们能活得更从容。探究本质并非朝夕之功，必须有板凳要坐十年冷的精神。</li><li>如果你想要说服别人，要诉诸利益，而非诉诸理性。</li><li>卓越的人很少，有机会追随他们，和他们走到一起，或许值得付出溢价，将来可能获得丰厚的回报。</li><li>保持理性是一种道德律令。在不该犯傻的时候千万别犯傻。</li><li>和被人比是比不过来的，无论做什么，都是一山更比一山高，强中自有强中手。</li><li>所有人都看好的机会，最容易发生踩踏，造成的损失最惨烈。</li><li>每一天都追求比醒来的那一刻多增长一分智慧；每一天都追求有能力承担更大的责任；每一天都追求尽善尽美地完成所有工作。日复一日，年复一年，你终将出人头地。</li><li>按照我的经验，解决问题的最佳方法是不让问题出现。</li><li>所有人的潜意识里都有这样的偏见：给别人提建议时，以为是在为别人考虑，其实是从自己的利益出发。</li><li>我们能成功，不是因为我们善于解决难题，而是因为我们善于远离难题。我们只是找简单的事做而已。</li><li>反过来想，总是反过来想。</li><li>如何才能成功？严格自律、遵守道德，找到志同道合的人，抓住难得的大机会，说出来都是些很简单的道理。</li><li>我不会因为人性而感到意外，也不会花太多时间感受背叛，我总是低下头调整自己去适应这类事情，我不喜欢任何成为受害者的感受。我不是受害者，我是幸存者。</li><li>人类都试图变得精明，而我只想证明自己并不是在做傻事，但这比许多人想想的要困难的多。</li></ul><h2 id="关于成长">关于成长</h2><ul><li>想要得到一件东西，最稳妥的方法就是让自己配得上它。</li><li>找出你最擅长的事情，然后持之以恒，乐此不疲地去把它做好。</li><li>承认无知是智慧的开始。</li><li>一个不能从别人的经验汇总学习的人，一辈子注定一只摔跟头。</li><li>把问题彻底想明白，问题就解决了一半。</li><li>我不会质疑过去，而是从过去中学习，为未来做决定。</li><li>如果你真想成功，真想取得别人无法取得的成就，就甘坐冷板凳，日复一日地阅读。如果你想拥有良好的认知能力，如果你想比别人更具智慧，能在艰难时刻有更好的表现，除了拿出大量时间思考，别无他法。</li><li>我这辈子遇到的聪明人没有不每天阅读的——一个都没有。</li><li>独学而无友，则孤陋寡闻。所有人都需要找到志同道合的人，相互切磋、共同进步。</li><li>我们成功源自我的长期专注。</li><li>在过去的任何一年，如果你一次都没有推翻过自己最中意的想法，那么这一年就算浪费了。</li><li>我喜欢能够坦然承认自己很愚蠢的人。我知道，如果正面承认自己的错误，我会表现得更好。这是一个非常棒的学习窍门。</li><li>我见识过很多取得很大成就的人。虽然他们既不是最聪明的人，甚至也不是最勤奋的人，但他们都是很善于学习的人。</li><li>极度专业化才是成功之道。比起理解整个世界来说，大多数人更加擅长专攻一个方面。</li><li>我做过很多傻事，我一直在和自己的成见做斗争。消除错误的想法是一件好事，我把消除错误的想法作为自己的一种追求。</li><li>进步不总是肉眼可见，而是往往出现在不经意间，但进步总是源于长期坚持，源于每一天的努力。</li><li>如果不终身学习，你们将不会取得很高的成就。光靠已有的知识，你们在生活中走不了多远。</li><li>只要能达到正确的终点，路途再颠簸，我都受得了。</li><li>脚踏实地，一步一个脚印，坚持不懈地长期努力，这是我的成功之道。</li></ul><h2 id="关于人生">关于人生</h2><ul><li>生活的铁律就是，只有20%的人能够取得比其他80%的人优秀的成绩。</li><li>不要同一头猪摔跤，因为这样你会把全身弄脏，而对方却乐此不疲。</li><li>你不必非常出色，只要在很长、很长的时间内保持比其他人聪明一点点就够了。</li><li>如果你的生活方式是正确的，那么到了晚年只会比年轻时更加幸福。</li><li>我会尽我所能逆流而上，而不是去预测潮汐何时到来。</li><li>如果你专注的时间周期足够长，你不断地为解决难题而努力，你就会跌跌撞撞地得到一个答案。这是人生的半个秘方。</li><li>任何人都会有错过机会的时候，这是命中注定的。我一直认为，改变不了的事情，不要太纠结。<strong>牢骚和抱怨是人生中的大忌。</strong></li><li>在生活中，很多人抱残守缺，他们满脑子的旧思想，新思想根本进不去。有句德国谚语说得好：“我们总是老的太快，聪明的太迟”。所有人都有这个问题。</li><li>身处逆境的时候，你要有一股咬紧牙关、埋头苦干的拼劲。怨天尤人、牢骚不断，只能越来越苦、越来越难。</li><li>想要什么，就立刻要得到，这样的人不但一事无成，还可能坠入深渊。</li><li>抵抗衰老的最佳措施就是在老之前好好生活。</li><li>生活总是以某种防护死伤害某人，又以某种方式帮助他人。面对生活中的打击，每个人都应该积极应对。</li><li>人生的困难一个接一个，每个困难都是对我们的一次考验，都是我们表现自己的机会。</li><li>很多人总是一味地逃避，不愿承受短期的痛苦。自找苦吃、主动吃眼前的苦，这才是正确的处世态度。</li><li>当逆境不期而至时，我们应该敢于迎难而上，这才是一种积极向上的人生态度。整天哼哼唧唧地怨天尤人，谁都救不了你。</li><li>坚持做有意义的事；坚持做有价值的人；坚持追求理智、正直、诚信，总有一天，一定能获得成功。</li><li>要想幸福，第一条，降低自己的预期。这一点是你自己能掌控的。</li><li>我觉得犯嫉妒这种罪的人最蠢，得不到一丁点快乐，整个人都被痛苦包围着，何必遭这份罪呢？</li><li>托马斯·卡莱尔有一句名言：“与其为朦胧的未来而烦恼忧虑，不如脚踏实地地、做好眼前的事。” 这句话说的很对。大多数时候，我们应该把眼前的事做好，尽人事，听天命。</li></ul><h2 id="关于商业管理">关于商业管理</h2><ul><li>最理想的公司，每年创造的现金高于净利润，能为所有者提供大量可自由支配的现金。</li><li>充分认清客观条件的限制，充分认识自身能力的限制，谨小慎微地在限制范围内活动，这是赚钱的诀窍。这个诀窍，与其说是“谦卑”，不如说是“有克制的贪婪”。</li><li>一家公司建立好了文化之后，就能走上良性循环的轨道。</li><li>为了防范风险，我们制定的规矩，恰恰是不赚最后一个铜板。</li><li>任何一家高杠杆的金融机构，无论管理者多么尽职尽责，都可能遭遇意外的损失。关键是遭遇意外之后，能否第一时间解决问题。在问题暴露出来以后，很多公司首先想到的是如何隐瞒，如何用会计手段蒙混过去。我们认为，应该不遮不掩、立刻解决。</li><li>即使拥有诚实守信的优良传统，时间久了，制度漏洞还是会毁掉优良传统。</li><li>裁员成本是一项巨大的隐形负债。很多公司因为裁员而支付的成本高达几亿、几十亿美金。公司明明要为缩小规模而付出成本，但这项成本并没有在资产负债表上体现出来。</li><li>我们从不签署允许我们懒惰的合同，以免我们走向堕落。</li><li>纵观商业史，很多公司辉煌过，赚过大钱，但是当它们被新的科技浪潮淘汰后，它们的家底很快就会耗光，最终走向消亡。</li><li>在服务业，只有全力以赴，为客户消除所有痛点，才能超越竞争对手。</li><li>经营一家公司，你懂的延迟满足，能把公司经营的越来越好。在人生中懂得延迟满足，你死的时候能很风光。</li><li>在沃伦眼中，优秀的管理者是这样的：你把他从火车上扔下去，扔到一个偏僻的小镇，不给他钱，他在这个小镇上诚实本分地经营，用不了多长时间，又发家致富了。</li><li>在与别人合作的过程中，沃伦和我都是首先以高标准要求自己。因为有优秀的人与我们一道努力，我们才能取得今天的成绩。</li><li>要找到优秀的伴侣，只有一个办法，就是自己得配得上。同样的道理，要找到优秀的人共事，你自己首先要是一个优秀的人。</li><li>我们不懂具体的软件业务，那我们怎么领导每日期刊公司呢？我们主要靠知人善任。</li><li>在做管理工作的过程中，最容易犯的错误是，已经发现该换人了，但迟迟下不了决心，拖了很长时间，才把不合适的人换掉。即使是有着多年管理经验的人，也很容易犯这个错误。</li><li>公司越大，越难建立起正确的文化。大公司特别容易患上官僚主义这个通病。</li><li>人们钻空子，肯定是因为激励制度有漏洞。</li><li>职业生涯的三条规则：不要销售你自己都不愿意买的东西；不要为你不尊重和不欣赏的人工作；只和你喜欢的人一起工作。</li><li>我们很少换人，不是因为我们软弱或愚蠢，而是因为我们一开始就把人选对了。</li><li>我愿意和优秀的人共事，不愿意和平庸的人为伍。</li><li>信任是你自己赢得的。你自己做事总是很靠谱，时间久了，别人自然会信任你。</li><li>我觉得在面对难题的时候，列一张清单非常有用。在单子上一列，所有问题一目了然，能把问题考虑得更周全，不会有什么遗漏。</li><li>凡是往简单处想，往认真处行。</li></ul><h2 id="关于投资理念">关于投资理念</h2><ul><li>真正做收购是好事多磨，要熬过辛苦的等待，经历反复的波折。</li><li>大多数时候，我们什么都不做。我们出手的时候很少。即使是出手的时候，我们也是如履薄冰，对可能承担的风险感到不安。</li><li>有些人收集邮票，而我收集疯狂和荒谬，然后避开它们。</li><li>钱多机会少，总比钱少机会多强。</li><li>我们只在很少的时候，能看透重大的机会。</li><li>我们始终把眼前所有的投资机会进行比较，力求找到当下最合理的投资逻辑，这才是重中之重。找到了最合理的同欧字逻辑之后，无论周期波动如何剧烈，是顺境还是逆境，我们都泰然自若。这就是我们的投资之道。</li><li>投资要选容错率高的好生意。有点管理问题，有点困难，有点错误，好生意照样还是好生意。</li><li>按我们这种方式投资，必须准确判断一家公司的前景。也就是说，你不但要能看出来，一家公司现在的生意是好生意，而且要能看出来，它在将来的很长时间里仍然是好生意。</li><li>买入好生意长期持有才是正道。</li><li>真正的好公司，现在的价格，大家可能觉得很贵，其实不贵。</li><li>格雷厄姆提出了安全边际的原则，这个概念永不过时。“市场是我们的仆人，不是我们的老师”。</li><li>做投资，一个是必须等大眼睛等待机会出现，另一个是机会出现时，必须果断出手。</li><li>钓鱼的第一条原则是，在有鱼的地方钓。钓鱼的第二条规则是，记住第一条规则。投资是同样的道理。</li><li>归根结底，投资只有价值投资一种。为什么这么说？因为我们每做一笔投资，把钱投进去，都是为了将来能获得更多的价值。</li><li>首先，要找自己能看懂的机会，不做自己看不懂的投资。然后，要踏踏实实地去做大量实际的工作。</li><li>成功的投资即需要进取心又需要耐心，而且还需要准备好在机会出现时抓住它，因为在这个世界上，机会不会持续很久。</li><li>我们能够成功，不是因为我们善于解决难题，而是因为我们善于远离难题。我们只是找到了容易做的事情。</li></ul>]]></content>
    
    <summary type="html">
    
      卓越的人很少，有机会追随他们，和他们走到一起...
    
    </summary>
    
    
      <category term="Notes" scheme="https://neo1989.net/categories/Notes/"/>
    
    
      <category term="Wisdom" scheme="https://neo1989.net/tags/Wisdom/"/>
    
  </entry>
  
  <entry>
    <title>SQ3R阅读法</title>
    <link href="https://neo1989.net/Notes/NOTE-SQ3R/"/>
    <id>https://neo1989.net/Notes/NOTE-SQ3R/</id>
    <published>2023-07-11T11:33:19.000Z</published>
    <updated>2023-07-11T11:39:47.879Z</updated>
    
    <content type="html"><![CDATA[<p><img src="//s3.mindex.xyz/tmp/fc643b514ad76d94a6f205de37e747f8.png" alt=""></p><h4 id="Survey">Survey</h4><p>快速扫描章节小标题，识别出来几个关键点，如果有章节小结的，重点阅读。</p><h4 id="Question">Question</h4><p>把章节的标题换成一个问题，阅读这章节的目的就是为了回答这个问题。</p><h4 id="Read">Read</h4><p>带着问题去阅读，阅读过程中始终记得为这个问题寻找答案</p><h4 id="Recite">Recite</h4><p>阅读完之后，用自己的话尝试解答这个问题，如果回答不出来，就重复以上四个步骤，直到回答出来位置。</p><h4 id="Review">Review</h4><p>最后再次回顾，并用自己的话来复述整本书的主要观点。</p>]]></content>
    
    <summary type="html">
    
      方法
    
    </summary>
    
    
      <category term="Notes" scheme="https://neo1989.net/categories/Notes/"/>
    
    
      <category term="SoftSkills" scheme="https://neo1989.net/tags/SoftSkills/"/>
    
  </entry>
  
  <entry>
    <title>Way2AI · Embeddings （下）</title>
    <link href="https://neo1989.net/Way2AI/Way2AI-Embeddings-2/"/>
    <id>https://neo1989.net/Way2AI/Way2AI-Embeddings-2/</id>
    <published>2023-07-06T05:02:57.000Z</published>
    <updated>2023-07-10T14:17:47.993Z</updated>
    
    <content type="html"><![CDATA[<h2 id="TL-DR">TL;DR</h2><p>上篇文章简单介绍了Embeddings，以及Glove。本篇将简单介绍加入Embedding层的CNN。</p><p>注意，所有的前置工作与<a href="https://neo1989.net/Way2AI/Way2AI-CNN/" title="卷积神经网络">《Way2AI · 卷积神经网络》</a>这篇文章里的介绍没有太大区别，最大的区别在于建模的时候加入了Embeddings层。</p><h2 id="Set-up">Set up</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pip install numpy==1.21.2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_seeds</span>(<span class="params">seed=<span class="number">1024</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Set seeds for reproducibility.&quot;&quot;&quot;</span></span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    random.seed(seed)</span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed_all(seed)  <span class="comment"># multi-GPU</span></span><br><span class="line"></span><br><span class="line">set_seeds(seed=<span class="number">1024</span>)</span><br><span class="line"></span><br><span class="line">cuda = <span class="literal">True</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span>(torch.cuda.is_available() <span class="keyword">and</span> cuda) <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">torch.set_default_tensor_type(&#123;<span class="string">&quot;cuda&quot;</span>: <span class="string">&quot;torch.cuda.FloatTensor&quot;</span>, <span class="string">&quot;cpu&quot;</span>: <span class="string">&quot;torch.FloatTensor&quot;</span>&#125;.get(<span class="built_in">str</span>(device)))</span><br></pre></td></tr></table></figure><h2 id="Load-data">Load data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">url = <span class="string">&quot;https://s3.mindex.xyz/datasets/news.csv&quot;</span></span><br><span class="line">df = pd.read_csv(url, header=<span class="number">0</span>)</span><br><span class="line">df = df.sample(frac=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">df[<span class="string">&quot;title&quot;</span>][:<span class="number">100</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># 0     Israel announces West Bank housing plan; barri...</span></span><br><span class="line"><span class="comment"># 1     Red Sox #39;s Feat: As far back as I can remember</span></span><br><span class="line"><span class="comment"># 2     J.P. Morgan Cancels IBM Outsourcing Deal (Reut...</span></span><br><span class="line"><span class="comment"># 3                          Intel Names Otellini New CEO</span></span><br><span class="line"><span class="comment"># 4     Branson Launches Virgin Atlantic Flights to Au...</span></span><br><span class="line"><span class="comment">#                             ...</span></span><br><span class="line"><span class="comment"># 95    Yahoo Profit Surges on Sales of Ads, Google Stock</span></span><br><span class="line"><span class="comment"># 96                                     DirecT Touchdown</span></span><br><span class="line"><span class="comment"># 97         Struggling Bucs Best Dismal Bears, 19-7 (AP)</span></span><br><span class="line"><span class="comment"># 98    Romania PM, Bucharest Mayor Battle for Preside...</span></span><br><span class="line"><span class="comment"># 99                      Glazer Quest for United Falters</span></span><br><span class="line"><span class="comment"># Name: title, Length: 100, dtype: object</span></span><br></pre></td></tr></table></figure><h2 id="Processing">Processing</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> PorterStemmer</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">nltk.download(<span class="string">&quot;stopwords&quot;</span>)</span><br><span class="line">STOPWORDS = stopwords.words(<span class="string">&quot;english&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (STOPWORDS[:<span class="number">5</span>])</span><br><span class="line">porter = PorterStemmer()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">text, stopwords=STOPWORDS</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Conditional preprocessing on our text unique to our task.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Lower</span></span><br><span class="line">    text = text.lower()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Remove stopwords</span></span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">r&quot;\b(&quot;</span> + <span class="string">r&quot;|&quot;</span>.join(stopwords) + <span class="string">r&quot;)\b\s*&quot;</span>)</span><br><span class="line">    text = pattern.sub(<span class="string">&quot;&quot;</span>, text)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Remove words in parenthesis</span></span><br><span class="line">    text = re.sub(<span class="string">r&quot;\([^)]*\)&quot;</span>, <span class="string">&quot;&quot;</span>, text)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Spacing and filters</span></span><br><span class="line">    text = re.sub(<span class="string">r&quot;([-;;.,!?&lt;=&gt;])&quot;</span>, <span class="string">r&quot; \1 &quot;</span>, text)</span><br><span class="line">    text = re.sub(<span class="string">&quot;[^A-Za-z0-9]+&quot;</span>, <span class="string">&quot; &quot;</span>, text) <span class="comment"># remove non alphanumeric chars</span></span><br><span class="line">    text = re.sub(<span class="string">&quot; +&quot;</span>, <span class="string">&quot; &quot;</span>, text)  <span class="comment"># remove multiple spaces</span></span><br><span class="line">    text = text.strip()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Apply to dataframe</span></span><br><span class="line">preprocessed_df = df.copy()</span><br><span class="line">preprocessed_df.title = preprocessed_df.title.apply(preprocess)</span><br></pre></td></tr></table></figure><h2 id="Split-data">Split data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">TRAIN_SIZE = <span class="number">0.7</span></span><br><span class="line">VAL_SIZE = <span class="number">0.15</span></span><br><span class="line">TEST_SIZE = <span class="number">0.15</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_val_test_split</span>(<span class="params">X, y, train_size</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Split dataset into data splits.&quot;&quot;&quot;</span></span><br><span class="line">    X_train, X_, y_train, y_ = train_test_split(X, y, train_size=TRAIN_SIZE, stratify=y)</span><br><span class="line">    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=<span class="number">0.5</span>, stratify=y_)</span><br><span class="line">    <span class="keyword">return</span> X_train, X_val, X_test, y_train, y_val, y_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Data</span></span><br><span class="line">X = preprocessed_df[<span class="string">&quot;title&quot;</span>].values</span><br><span class="line">y = preprocessed_df[<span class="string">&quot;category&quot;</span>].values</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create data splits</span></span><br><span class="line">X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(</span><br><span class="line">    X=X, y=y, train_size=TRAIN_SIZE)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_train: <span class="subst">&#123;X_train.shape&#125;</span>, y_train: <span class="subst">&#123;y_train.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_val: <span class="subst">&#123;X_val.shape&#125;</span>, y_val: <span class="subst">&#123;y_val.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_test: <span class="subst">&#123;X_test.shape&#125;</span>, y_test: <span class="subst">&#123;y_test.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;Sample point: <span class="subst">&#123;X_train[<span class="number">0</span>]&#125;</span> → <span class="subst">&#123;y_train[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># X_train: (84000,), y_train: (84000,)</span></span><br><span class="line"><span class="comment"># X_val: (18000,), y_val: (18000,)</span></span><br><span class="line"><span class="comment"># X_test: (18000,), y_test: (18000,)</span></span><br><span class="line"><span class="comment"># Sample point: ibm wins time talks pension case → Sci/Tech</span></span><br></pre></td></tr></table></figure><h2 id="Label-encoding">Label encoding</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LabelEncoder</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Label encoder for tag labels.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, class_to_index=&#123;&#125;</span>):</span><br><span class="line">        self.class_to_index = class_to_index <span class="keyword">or</span> &#123;&#125;  <span class="comment"># mutable defaults ;)</span></span><br><span class="line">        self.index_to_class = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> self.class_to_index.items()&#125;</span><br><span class="line">        self.classes = <span class="built_in">list</span>(self.class_to_index.keys())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.class_to_index)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;&lt;LabelEncoder(num_classes=<span class="subst">&#123;<span class="built_in">len</span>(self)&#125;</span>)&gt;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, y</span>):</span><br><span class="line">        classes = np.unique(y)</span><br><span class="line">        <span class="keyword">for</span> i, class_ <span class="keyword">in</span> <span class="built_in">enumerate</span>(classes):</span><br><span class="line">            self.class_to_index[class_] = i</span><br><span class="line">        self.index_to_class = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> self.class_to_index.items()&#125;</span><br><span class="line">        self.classes = <span class="built_in">list</span>(self.class_to_index.keys())</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">self, y</span>):</span><br><span class="line">        encoded = np.zeros((<span class="built_in">len</span>(y)), dtype=<span class="built_in">int</span>)</span><br><span class="line">        <span class="keyword">for</span> i, item <span class="keyword">in</span> <span class="built_in">enumerate</span>(y):</span><br><span class="line">            encoded[i] = self.class_to_index[item]</span><br><span class="line">        <span class="keyword">return</span> encoded</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decode</span>(<span class="params">self, y</span>):</span><br><span class="line">        classes = []</span><br><span class="line">        <span class="keyword">for</span> i, item <span class="keyword">in</span> <span class="built_in">enumerate</span>(y):</span><br><span class="line">            classes.append(self.index_to_class[item])</span><br><span class="line">        <span class="keyword">return</span> classes</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save</span>(<span class="params">self, fp</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(fp, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            contents = &#123;<span class="string">&#x27;class_to_index&#x27;</span>: self.class_to_index&#125;</span><br><span class="line">            json.dump(contents, fp, indent=<span class="number">4</span>, sort_keys=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load</span>(<span class="params">cls, fp</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(fp, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            kwargs = json.load(fp=fp)</span><br><span class="line">        <span class="keyword">return</span> cls(**kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Encode</span></span><br><span class="line">label_encoder = LabelEncoder()</span><br><span class="line">label_encoder.fit(y_train)</span><br><span class="line">NUM_CLASSES = <span class="built_in">len</span>(label_encoder)</span><br><span class="line"><span class="built_in">print</span>(label_encoder.class_to_index)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &#123;&#x27;Business&#x27;: 0, &#x27;Sci/Tech&#x27;: 1, &#x27;Sports&#x27;: 2, &#x27;World&#x27;: 3&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert labels to tokens</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;y_train[0]: <span class="subst">&#123;y_train[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line">y_train = label_encoder.encode(y_train)</span><br><span class="line">y_val = label_encoder.encode(y_val)</span><br><span class="line">y_test = label_encoder.encode(y_test)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;y_train[0]: <span class="subst">&#123;y_train[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># y_train[0]: Sci/Tech</span></span><br><span class="line"><span class="comment"># y_train[0]: 1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Class weights</span></span><br><span class="line">counts = np.bincount(y_train)</span><br><span class="line">class_weights = &#123;i: <span class="number">1.0</span>/count <span class="keyword">for</span> i, count <span class="keyword">in</span> <span class="built_in">enumerate</span>(counts)&#125;</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;counts: <span class="subst">&#123;counts&#125;</span>\nweights: <span class="subst">&#123;class_weights&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># counts: [21000 21000 21000 21000]</span></span><br><span class="line"><span class="comment"># weights: &#123;0: 4.761904761904762e-05, 1: 4.761904761904762e-05, 2: 4.761904761904762e-05, 3: 4.761904761904762e-05&#125;</span></span><br></pre></td></tr></table></figure><h2 id="Tokenizer">Tokenizer</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">from</span> more_itertools <span class="keyword">import</span> take</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Tokenizer</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, char_level, num_tokens=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 pad_token=<span class="string">&quot;&lt;PAD&gt;&quot;</span>, oov_token=<span class="string">&quot;&lt;UNK&gt;&quot;</span>,</span></span><br><span class="line"><span class="params">                 token_to_index=<span class="literal">None</span></span>):</span><br><span class="line">        self.char_level = char_level</span><br><span class="line">        self.separator = <span class="string">&quot;&quot;</span> <span class="keyword">if</span> self.char_level <span class="keyword">else</span> <span class="string">&quot; &quot;</span></span><br><span class="line">        <span class="keyword">if</span> num_tokens: num_tokens -= <span class="number">2</span> <span class="comment"># pad + unk tokens</span></span><br><span class="line">        self.num_tokens = num_tokens</span><br><span class="line">        self.pad_token = pad_token</span><br><span class="line">        self.oov_token = oov_token</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> token_to_index:</span><br><span class="line">            token_to_index = &#123;pad_token: <span class="number">0</span>, oov_token: <span class="number">1</span>&#125;</span><br><span class="line">        self.token_to_index = token_to_index</span><br><span class="line">        self.index_to_token = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> self.token_to_index.items()&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.token_to_index)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;&lt;Tokenizer(num_tokens=<span class="subst">&#123;<span class="built_in">len</span>(self)&#125;</span>)&gt;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit_on_texts</span>(<span class="params">self, texts</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.char_level:</span><br><span class="line">            texts = [text.split(<span class="string">&quot; &quot;</span>) <span class="keyword">for</span> text <span class="keyword">in</span> texts]</span><br><span class="line">        all_tokens = [token <span class="keyword">for</span> text <span class="keyword">in</span> texts <span class="keyword">for</span> token <span class="keyword">in</span> text]</span><br><span class="line">        counts = Counter(all_tokens).most_common(self.num_tokens)</span><br><span class="line">        self.min_token_freq = counts[-<span class="number">1</span>][<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> token, count <span class="keyword">in</span> counts:</span><br><span class="line">            index = <span class="built_in">len</span>(self)</span><br><span class="line">            self.token_to_index[token] = index</span><br><span class="line">            self.index_to_token[index] = token</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">texts_to_sequences</span>(<span class="params">self, texts</span>):</span><br><span class="line">        sequences = []</span><br><span class="line">        <span class="keyword">for</span> text <span class="keyword">in</span> texts:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> self.char_level:</span><br><span class="line">                text = text.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">            sequence = []</span><br><span class="line">            <span class="keyword">for</span> token <span class="keyword">in</span> text:</span><br><span class="line">                sequence.append(self.token_to_index.get(</span><br><span class="line">                    token, self.token_to_index[self.oov_token]))</span><br><span class="line">            sequences.append(np.asarray(sequence))</span><br><span class="line">        <span class="keyword">return</span> sequences</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sequences_to_texts</span>(<span class="params">self, sequences</span>):</span><br><span class="line">        texts = []</span><br><span class="line">        <span class="keyword">for</span> sequence <span class="keyword">in</span> sequences:</span><br><span class="line">            text = []</span><br><span class="line">            <span class="keyword">for</span> index <span class="keyword">in</span> sequence:</span><br><span class="line">                text.append(self.index_to_token.get(index, self.oov_token))</span><br><span class="line">            texts.append(self.separator.join([token <span class="keyword">for</span> token <span class="keyword">in</span> text]))</span><br><span class="line">        <span class="keyword">return</span> texts</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save</span>(<span class="params">self, fp</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(fp, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            contents = &#123;</span><br><span class="line">                <span class="string">&quot;char_level&quot;</span>: self.char_level,</span><br><span class="line">                <span class="string">&quot;oov_token&quot;</span>: self.oov_token,</span><br><span class="line">                <span class="string">&quot;token_to_index&quot;</span>: self.token_to_index</span><br><span class="line">            &#125;</span><br><span class="line">            json.dump(contents, fp, indent=<span class="number">4</span>, sort_keys=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load</span>(<span class="params">cls, fp</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(fp, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            kwargs = json.load(fp=fp)</span><br><span class="line">        <span class="keyword">return</span> cls(**kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Tokenize</span></span><br><span class="line">tokenizer = Tokenizer(char_level=<span class="literal">False</span>, num_tokens=<span class="number">5000</span>)</span><br><span class="line">tokenizer.fit_on_texts(texts=X_train)</span><br><span class="line">VOCAB_SIZE = <span class="built_in">len</span>(tokenizer)</span><br><span class="line"><span class="built_in">print</span> (tokenizer)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output </span></span><br><span class="line"><span class="comment"># &lt;Tokenizer(num_tokens=5000)&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Sample of tokens</span></span><br><span class="line"><span class="built_in">print</span> (take(<span class="number">5</span>, tokenizer.token_to_index.items()))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;least freq token&#x27;s freq: <span class="subst">&#123;tokenizer.min_token_freq&#125;</span>&quot;</span>) <span class="comment"># use this to adjust num_tokens</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># [(&#x27;&lt;PAD&gt;&#x27;, 0), (&#x27;&lt;UNK&gt;&#x27;, 1), (&#x27;39&#x27;, 2), (&#x27;b&#x27;, 3), (&#x27;gt&#x27;, 4)]</span></span><br><span class="line"><span class="comment"># least freq token&#x27;s freq: 14</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert texts to sequences of indices</span></span><br><span class="line">X_train = tokenizer.texts_to_sequences(X_train)</span><br><span class="line">X_val = tokenizer.texts_to_sequences(X_val)</span><br><span class="line">X_test = tokenizer.texts_to_sequences(X_test)</span><br><span class="line">preprocessed_text = tokenizer.sequences_to_texts([X_train[<span class="number">0</span>]])[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;Text to indices:\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  (preprocessed) → <span class="subst">&#123;preprocessed_text&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  (tokenized) → <span class="subst">&#123;X_train[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Text to indices:</span></span><br><span class="line"><span class="comment">#   (preprocessed) → ibm wins time talks pension case</span></span><br><span class="line"><span class="comment">#   (tokenized) → [ 31  32  69  26 715 100]</span></span><br></pre></td></tr></table></figure><h2 id="Padding">Padding</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pad_sequences</span>(<span class="params">sequences, max_seq_len=<span class="number">0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Pad sequences to max length in sequence.&quot;&quot;&quot;</span></span><br><span class="line">    max_seq_len = <span class="built_in">max</span>(max_seq_len, <span class="built_in">max</span>(<span class="built_in">len</span>(sequence) <span class="keyword">for</span> sequence <span class="keyword">in</span> sequences))</span><br><span class="line">    padded_sequences = np.zeros((<span class="built_in">len</span>(sequences), max_seq_len))</span><br><span class="line">    <span class="keyword">for</span> i, sequence <span class="keyword">in</span> <span class="built_in">enumerate</span>(sequences):</span><br><span class="line">        padded_sequences[i][:<span class="built_in">len</span>(sequence)] = sequence</span><br><span class="line">    <span class="keyword">return</span> padded_sequences</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2D sequences</span></span><br><span class="line">padded = pad_sequences(X_train[<span class="number">0</span>:<span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span> (padded.shape)</span><br><span class="line"><span class="built_in">print</span> (padded)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># (3, 8)</span></span><br><span class="line"><span class="comment"># [[3.100e+01 3.200e+01 6.900e+01 2.600e+01 7.150e+02 1.000e+02 0.000e+00</span></span><br><span class="line"><span class="comment">#   0.000e+00]</span></span><br><span class="line"><span class="comment">#  [3.568e+03 9.000e+00 4.520e+03 2.000e+00 1.000e+00 2.396e+03 7.760e+02</span></span><br><span class="line"><span class="comment">#   1.500e+01]</span></span><br><span class="line"><span class="comment">#  [1.000e+01 1.094e+03 7.600e+01 5.960e+02 5.740e+02 8.000e+02 0.000e+00</span></span><br><span class="line"><span class="comment">#   0.000e+00]]</span></span><br></pre></td></tr></table></figure><h2 id="Dataset">Dataset</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">FILTER_SIZES = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">2</span>, <span class="number">5</span>)) <span class="comment"># bi, tri and 4 grams</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Dataset</span>(torch.utils.data.Dataset):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, X, y, max_filter_size</span>):</span><br><span class="line">        self.X = X</span><br><span class="line">        self.y = y</span><br><span class="line">        self.max_filter_size = max_filter_size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;&lt;Dataset(N=<span class="subst">&#123;<span class="built_in">len</span>(self)&#125;</span>)&gt;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        X = self.X[index]</span><br><span class="line">        y = self.y[index]</span><br><span class="line">        <span class="keyword">return</span> [X, y]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">self, batch</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Processing on a batch.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Get inputs</span></span><br><span class="line">        batch = np.array(batch)</span><br><span class="line">        X = batch[:, <span class="number">0</span>]</span><br><span class="line">        y = batch[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Pad sequences</span></span><br><span class="line">        X = pad_sequences(X)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Cast</span></span><br><span class="line">        X = torch.LongTensor(X.astype(np.int32))</span><br><span class="line">        y = torch.LongTensor(y.astype(np.int32))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> X, y</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_dataloader</span>(<span class="params">self, batch_size, shuffle=<span class="literal">False</span>, drop_last=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="keyword">return</span> torch.utils.data.DataLoader(</span><br><span class="line">            dataset=self, batch_size=batch_size, collate_fn=self.collate_fn,</span><br><span class="line">            shuffle=shuffle, drop_last=drop_last, pin_memory=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create datasets</span></span><br><span class="line">max_filter_size = <span class="built_in">max</span>(FILTER_SIZES)</span><br><span class="line">train_dataset = Dataset(X=X_train, y=y_train, max_filter_size=max_filter_size)</span><br><span class="line">val_dataset = Dataset(X=X_val, y=y_val, max_filter_size=max_filter_size)</span><br><span class="line">test_dataset = Dataset(X=X_test, y=y_test, max_filter_size=max_filter_size)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;Datasets:\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  Train dataset:<span class="subst">&#123;train_dataset.__str__()&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  Val dataset: <span class="subst">&#123;val_dataset.__str__()&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  Test dataset: <span class="subst">&#123;test_dataset.__str__()&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">&quot;Sample point:\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  X: <span class="subst">&#123;train_dataset[<span class="number">0</span>][<span class="number">0</span>]&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  y: <span class="subst">&#123;train_dataset[<span class="number">0</span>][<span class="number">1</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Datasets:</span></span><br><span class="line"><span class="comment">#   Train dataset:&lt;Dataset(N=84000)&gt;</span></span><br><span class="line"><span class="comment">#   Val dataset: &lt;Dataset(N=18000)&gt;</span></span><br><span class="line"><span class="comment">#   Test dataset: &lt;Dataset(N=18000)&gt;</span></span><br><span class="line"><span class="comment"># Sample point:</span></span><br><span class="line"><span class="comment">#   X: [ 31  32  69  26 715 100]</span></span><br><span class="line"><span class="comment">#   y: 1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create dataloaders</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">train_dataloader = train_dataset.create_dataloader(batch_size=batch_size)</span><br><span class="line">val_dataloader = val_dataset.create_dataloader(batch_size=batch_size)</span><br><span class="line">test_dataloader = test_dataset.create_dataloader(batch_size=batch_size)</span><br><span class="line">batch_X, batch_y = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_dataloader))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;Sample batch:\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  X: <span class="subst">&#123;<span class="built_in">list</span>(batch_X.size())&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  y: <span class="subst">&#123;<span class="built_in">list</span>(batch_y.size())&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">&quot;Sample point:\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  X: <span class="subst">&#123;batch_X[<span class="number">0</span>]&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  y: <span class="subst">&#123;batch_y[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Sample batch:</span></span><br><span class="line"><span class="comment">#   X: [64, 10]</span></span><br><span class="line"><span class="comment">#   y: [64]</span></span><br><span class="line"><span class="comment"># Sample point:</span></span><br><span class="line"><span class="comment">#   X: tensor([ 31,  32,  69,  26, 715, 100,   0,   0,   0,   0])</span></span><br><span class="line"><span class="comment">#   y: 1</span></span><br></pre></td></tr></table></figure><h2 id="Model">Model</h2><p>可视化一下模型的前向传播.</p><ul><li>首先对输入tokenizer化 (batch_size, max_seq_len)</li><li>然后我们对tokenizered输入进行embed (batch_size, max_seq_len, embedding_dim)</li><li>接下来，使用filters（filter_size, vocab_size, num_filter)进行卷积，然后批归一化。我们讲使用三个不同size的filter（2, 3 和 4）分别充当bi-gram, tri-gram 和 4-gram 特征提取器。</li><li>紧跟着，应用一维max polling，从特征图中提取最相关信息以做出决策</li><li>再接一个含dropout的全连接层</li><li>最后再使用一个softmax全连接层以输出最终的类别概率</li></ul><p><img src="//s3.mindex.xyz/tmp/89231298b192a7831de7c18f7c52f6ad.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">EMBEDDING_DIM = <span class="number">100</span></span><br><span class="line">HIDDEN_DIM = <span class="number">100</span></span><br><span class="line">DROPOUT_P = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embedding_dim, vocab_size, num_filters,</span></span><br><span class="line"><span class="params">                 filter_sizes, hidden_dim, dropout_p, num_classes,</span></span><br><span class="line"><span class="params">                 pretrained_embeddings=<span class="literal">None</span>, freeze_embeddings=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 padding_idx=<span class="number">0</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(CNN, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Filter sizes</span></span><br><span class="line">        self.filter_sizes = filter_sizes</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Initialize embeddings</span></span><br><span class="line">        <span class="keyword">if</span> pretrained_embeddings <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.embeddings = nn.Embedding(</span><br><span class="line">                embedding_dim=embedding_dim, num_embeddings=vocab_size,</span><br><span class="line">                padding_idx=padding_idx)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).<span class="built_in">float</span>()</span><br><span class="line">            self.embeddings = nn.Embedding(</span><br><span class="line">                embedding_dim=embedding_dim, num_embeddings=vocab_size,</span><br><span class="line">                padding_idx=padding_idx, _weight=pretrained_embeddings)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Freeze embeddings or not</span></span><br><span class="line">        <span class="keyword">if</span> freeze_embeddings:</span><br><span class="line">            self.embeddings.weight.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Conv weights</span></span><br><span class="line">        self.conv = nn.ModuleList(</span><br><span class="line">            [nn.Conv1d(in_channels=embedding_dim,</span><br><span class="line">                       out_channels=num_filters,</span><br><span class="line">                       kernel_size=f) <span class="keyword">for</span> f <span class="keyword">in</span> filter_sizes])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># FC weights</span></span><br><span class="line">        self.dropout = nn.Dropout(dropout_p)</span><br><span class="line">        self.fc1 = nn.Linear(num_filters*<span class="built_in">len</span>(filter_sizes), hidden_dim)</span><br><span class="line">        self.fc2 = nn.Linear(hidden_dim, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs, channel_first=<span class="literal">False</span></span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Embed</span></span><br><span class="line">        x_in, = inputs</span><br><span class="line">        x_in = self.embeddings(x_in)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Rearrange input so num_channels is in dim 1 (N, C, L)</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> channel_first:</span><br><span class="line">            x_in = x_in.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Conv outputs</span></span><br><span class="line">        z = []</span><br><span class="line">        max_seq_len = x_in.shape[<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">for</span> i, f <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.filter_sizes):</span><br><span class="line">            <span class="comment"># `SAME` padding</span></span><br><span class="line">            padding_left = <span class="built_in">int</span>((self.conv[i].stride[<span class="number">0</span>]*(max_seq_len-<span class="number">1</span>) - max_seq_len + self.filter_sizes[i])/<span class="number">2</span>)</span><br><span class="line">            padding_right = <span class="built_in">int</span>(math.ceil((self.conv[i].stride[<span class="number">0</span>]*(max_seq_len-<span class="number">1</span>) - max_seq_len + self.filter_sizes[i])/<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Conv + pool</span></span><br><span class="line">            _z = self.conv[i](F.pad(x_in, (padding_left, padding_right)))</span><br><span class="line">            _z = F.max_pool1d(_z, _z.size(<span class="number">2</span>)).squeeze(<span class="number">2</span>)</span><br><span class="line">            z.append(_z)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Concat conv outputs</span></span><br><span class="line">        z = torch.cat(z, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># FC layers</span></span><br><span class="line">        z = self.fc1(z)</span><br><span class="line">        z = self.dropout(z)</span><br><span class="line">        z = self.fc2(z)</span><br><span class="line">        <span class="keyword">return</span> z</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Using-GloVe">Using GloVe</h2><p>先实现一些方便能够将预训练的GloVe加载到我们的模型中的公共方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_glove_embeddings</span>(<span class="params">embeddings_file</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Load embeddings from a file.&quot;&quot;&quot;</span></span><br><span class="line">    embeddings = &#123;&#125;</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(embeddings_file, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        <span class="keyword">for</span> index, line <span class="keyword">in</span> <span class="built_in">enumerate</span>(fp):</span><br><span class="line">            values = line.split()</span><br><span class="line">            word = values[<span class="number">0</span>]</span><br><span class="line">            embedding = np.asarray(values[<span class="number">1</span>:], dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">            embeddings[word] = embedding</span><br><span class="line">    <span class="keyword">return</span> embeddings</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_embeddings_matrix</span>(<span class="params">embeddings, word_index, embedding_dim</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Create embeddings matrix to use in Embedding layer.&quot;&quot;&quot;</span></span><br><span class="line">    embedding_matrix = np.zeros((<span class="built_in">len</span>(word_index), embedding_dim))</span><br><span class="line">    <span class="keyword">for</span> word, i <span class="keyword">in</span> word_index.items():</span><br><span class="line">        embedding_vector = embeddings.get(word)</span><br><span class="line">        <span class="keyword">if</span> embedding_vector <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            embedding_matrix[i] = embedding_vector</span><br><span class="line">    <span class="keyword">return</span> embedding_matrix</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create embeddings</span></span><br><span class="line">embeddings_file = <span class="string">&#x27;glove.6B.&#123;0&#125;d.txt&#x27;</span>.<span class="built_in">format</span>(EMBEDDING_DIM)</span><br><span class="line">glove_embeddings = load_glove_embeddings(embeddings_file=embeddings_file)</span><br><span class="line">embedding_matrix = make_embeddings_matrix(</span><br><span class="line">    embeddings=glove_embeddings, word_index=tokenizer.token_to_index,</span><br><span class="line">    embedding_dim=EMBEDDING_DIM)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;&lt;Embeddings(words=<span class="subst">&#123;embedding_matrix.shape[<span class="number">0</span>]&#125;</span>, dim=<span class="subst">&#123;embedding_matrix.shape[<span class="number">1</span>]&#125;</span>)&gt;&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &lt;Embeddings(words=5000, dim=100)&gt;</span></span><br></pre></td></tr></table></figure><h2 id="Experiments">Experiments</h2><p>接下来，我们将进行三个实验：</p><ul><li>随机初始化的embeddings (fine-tuned)</li><li>GloVe embeddings (frozen)</li><li>GloVe embeddings (fine-tuned)</li></ul><p>先定义我们的Trainer</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_fscore_support</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> Adam</span><br><span class="line"></span><br><span class="line">NUM_FILTERS = <span class="number">50</span></span><br><span class="line">LEARNING_RATE = <span class="number">1e-3</span></span><br><span class="line">PATIENCE = <span class="number">5</span></span><br><span class="line">NUM_EPOCHS = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Trainer</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model, device, loss_fn=<span class="literal">None</span>, optimizer=<span class="literal">None</span>, scheduler=<span class="literal">None</span></span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Set params</span></span><br><span class="line">        self.model = model</span><br><span class="line">        self.device = device</span><br><span class="line">        self.loss_fn = loss_fn</span><br><span class="line">        self.optimizer = optimizer</span><br><span class="line">        self.scheduler = scheduler</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">self, dataloader</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Train step.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Set model to train mode</span></span><br><span class="line">        self.model.train()</span><br><span class="line">        loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Iterate over train batches</span></span><br><span class="line">        <span class="keyword">for</span> i, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Step</span></span><br><span class="line">            batch = [item.to(self.device) <span class="keyword">for</span> item <span class="keyword">in</span> batch]  <span class="comment"># Set device</span></span><br><span class="line">            inputs, targets = batch[:-<span class="number">1</span>], batch[-<span class="number">1</span>]</span><br><span class="line">            self.optimizer.zero_grad()  <span class="comment"># Reset gradients</span></span><br><span class="line">            z = self.model(inputs)  <span class="comment"># Forward pass</span></span><br><span class="line">            J = self.loss_fn(z, targets)  <span class="comment"># Define loss</span></span><br><span class="line">            J.backward()  <span class="comment"># Backward pass</span></span><br><span class="line">            self.optimizer.step()  <span class="comment"># Update weights</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Cumulative Metrics</span></span><br><span class="line">            loss += (J.detach().item() - loss) / (i + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">eval_step</span>(<span class="params">self, dataloader</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Validation or test step.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Set model to eval mode</span></span><br><span class="line">        self.model.<span class="built_in">eval</span>()</span><br><span class="line">        loss = <span class="number">0.0</span></span><br><span class="line">        y_trues, y_probs = [], []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Iterate over val batches</span></span><br><span class="line">        <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">            <span class="keyword">for</span> i, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Step</span></span><br><span class="line">                batch = [item.to(self.device) <span class="keyword">for</span> item <span class="keyword">in</span> batch]  <span class="comment"># Set device</span></span><br><span class="line">                inputs, y_true = batch[:-<span class="number">1</span>], batch[-<span class="number">1</span>]</span><br><span class="line">                z = self.model(inputs)  <span class="comment"># Forward pass</span></span><br><span class="line">                J = self.loss_fn(z, y_true).item()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Cumulative Metrics</span></span><br><span class="line">                loss += (J - loss) / (i + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Store outputs</span></span><br><span class="line">                y_prob = F.softmax(z).cpu().numpy()</span><br><span class="line">                y_probs.extend(y_prob)</span><br><span class="line">                y_trues.extend(y_true.cpu().numpy())</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> loss, np.vstack(y_trues), np.vstack(y_probs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict_step</span>(<span class="params">self, dataloader</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Prediction step.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Set model to eval mode</span></span><br><span class="line">        self.model.<span class="built_in">eval</span>()</span><br><span class="line">        y_probs = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Iterate over val batches</span></span><br><span class="line">        <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">            <span class="keyword">for</span> i, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Forward pass w/ inputs</span></span><br><span class="line">                inputs, targets = batch[:-<span class="number">1</span>], batch[-<span class="number">1</span>]</span><br><span class="line">                z = self.model(inputs)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Store outputs</span></span><br><span class="line">                y_prob = F.softmax(z).cpu().numpy()</span><br><span class="line">                y_probs.extend(y_prob)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> np.vstack(y_probs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, num_epochs, patience, train_dataloader, val_dataloader</span>):</span><br><span class="line">        best_val_loss = np.inf</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">            <span class="comment"># Steps</span></span><br><span class="line">            train_loss = self.train_step(dataloader=train_dataloader)</span><br><span class="line">            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)</span><br><span class="line">            self.scheduler.step(val_loss)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Early stopping</span></span><br><span class="line">            <span class="keyword">if</span> val_loss &lt; best_val_loss:</span><br><span class="line">                best_val_loss = val_loss</span><br><span class="line">                best_model = self.model</span><br><span class="line">                _patience = patience  <span class="comment"># reset _patience</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                _patience -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> _patience:  <span class="comment"># 0</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Stopping early!&quot;</span>)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Logging</span></span><br><span class="line">            <span class="built_in">print</span>(</span><br><span class="line">                <span class="string">f&quot;Epoch: <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span> | &quot;</span></span><br><span class="line">                <span class="string">f&quot;train_loss: <span class="subst">&#123;train_loss:<span class="number">.5</span>f&#125;</span>, &quot;</span></span><br><span class="line">                <span class="string">f&quot;val_loss: <span class="subst">&#123;val_loss:<span class="number">.5</span>f&#125;</span>, &quot;</span></span><br><span class="line">                <span class="string">f&quot;lr: <span class="subst">&#123;self.optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>]:<span class="number">.2</span>E&#125;</span>, &quot;</span></span><br><span class="line">                <span class="string">f&quot;_patience: <span class="subst">&#123;_patience&#125;</span>&quot;</span></span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">return</span> best_model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_metrics</span>(<span class="params">y_true, y_pred, classes</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Per-class performance metrics.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Performance</span></span><br><span class="line">    performance = &#123;<span class="string">&quot;overall&quot;</span>: &#123;&#125;, <span class="string">&quot;class&quot;</span>: &#123;&#125;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Overall performance</span></span><br><span class="line">    metrics = precision_recall_fscore_support(y_true, y_pred, average=<span class="string">&quot;weighted&quot;</span>)</span><br><span class="line">    performance[<span class="string">&quot;overall&quot;</span>][<span class="string">&quot;precision&quot;</span>] = metrics[<span class="number">0</span>]</span><br><span class="line">    performance[<span class="string">&quot;overall&quot;</span>][<span class="string">&quot;recall&quot;</span>] = metrics[<span class="number">1</span>]</span><br><span class="line">    performance[<span class="string">&quot;overall&quot;</span>][<span class="string">&quot;f1&quot;</span>] = metrics[<span class="number">2</span>]</span><br><span class="line">    performance[<span class="string">&quot;overall&quot;</span>][<span class="string">&quot;num_samples&quot;</span>] = np.float64(<span class="built_in">len</span>(y_true))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Per-class performance</span></span><br><span class="line">    metrics = precision_recall_fscore_support(y_true, y_pred, average=<span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(classes)):</span><br><span class="line">        performance[<span class="string">&quot;class&quot;</span>][classes[i]] = &#123;</span><br><span class="line">            <span class="string">&quot;precision&quot;</span>: metrics[<span class="number">0</span>][i],</span><br><span class="line">            <span class="string">&quot;recall&quot;</span>: metrics[<span class="number">1</span>][i],</span><br><span class="line">            <span class="string">&quot;f1&quot;</span>: metrics[<span class="number">2</span>][i],</span><br><span class="line">            <span class="string">&quot;num_samples&quot;</span>: np.float64(metrics[<span class="number">3</span>][i]),</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> performance</span><br></pre></td></tr></table></figure><h3 id="Random-initialization">Random initialization</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">PRETRAINED_EMBEDDINGS = <span class="literal">None</span></span><br><span class="line">FREEZE_EMBEDDINGS = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize model</span></span><br><span class="line">model = CNN(</span><br><span class="line">    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,</span><br><span class="line">    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,</span><br><span class="line">    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,</span><br><span class="line">    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)</span><br><span class="line">model = model.to(device) <span class="comment"># set device</span></span><br><span class="line"><span class="built_in">print</span> (model.named_parameters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &lt;bound method Module.named_parameters of CNN(</span></span><br><span class="line"><span class="comment">#   (embeddings): Embedding(5000, 100, padding_idx=0)</span></span><br><span class="line"><span class="comment">#   (conv): ModuleList(</span></span><br><span class="line"><span class="comment">#     (0): Conv1d(100, 50, kernel_size=(2,), stride=(1,))</span></span><br><span class="line"><span class="comment">#     (1): Conv1d(100, 50, kernel_size=(3,), stride=(1,))</span></span><br><span class="line"><span class="comment">#     (2): Conv1d(100, 50, kernel_size=(4,), stride=(1,))</span></span><br><span class="line"><span class="comment">#   )</span></span><br><span class="line"><span class="comment">#   (dropout): Dropout(p=0.1, inplace=False)</span></span><br><span class="line"><span class="comment">#   (fc1): Linear(in_features=150, out_features=100, bias=True)</span></span><br><span class="line"><span class="comment">#   (fc2): Linear(in_features=100, out_features=4, bias=True)</span></span><br><span class="line"><span class="comment"># )&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define Loss</span></span><br><span class="line">class_weights_tensor = torch.Tensor(<span class="built_in">list</span>(class_weights.values())).to(device)</span><br><span class="line">loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define optimizer &amp; scheduler</span></span><br><span class="line">optimizer = Adam(model.parameters(), lr=LEARNING_RATE)</span><br><span class="line">scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(</span><br><span class="line">    optimizer, mode=<span class="string">&quot;min&quot;</span>, factor=<span class="number">0.1</span>, patience=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Trainer module</span></span><br><span class="line">trainer = Trainer(model=model, device=device, loss_fn=loss_fn,</span><br><span class="line">                  optimizer=optimizer, scheduler=scheduler)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train</span></span><br><span class="line">best_model = trainer.train(NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Epoch: 1 | train_loss: 0.78800, val_loss: 0.64168, lr: 1.00E-03, _patience: 5</span></span><br><span class="line"><span class="comment"># Epoch: 2 | train_loss: 0.49324, val_loss: 0.60757, lr: 1.00E-03, _patience: 5</span></span><br><span class="line"><span class="comment"># Epoch: 3 | train_loss: 0.38917, val_loss: 0.63572, lr: 1.00E-03, _patience: 4</span></span><br><span class="line"><span class="comment"># Epoch: 4 | train_loss: 0.31891, val_loss: 0.70638, lr: 1.00E-03, _patience: 3</span></span><br><span class="line"><span class="comment"># Epoch: 5 | train_loss: 0.26606, val_loss: 0.76403, lr: 1.00E-03, _patience: 2</span></span><br><span class="line"><span class="comment"># Epoch: 6 | train_loss: 0.22631, val_loss: 0.79747, lr: 1.00E-04, _patience: 1</span></span><br><span class="line"><span class="comment"># Stopping early!</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get predictions</span></span><br><span class="line">test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)</span><br><span class="line">y_pred = np.argmax(y_prob, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Determine performance</span></span><br><span class="line">performance = get_metrics(</span><br><span class="line">    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)</span><br><span class="line"><span class="built_in">print</span> (json.dumps(performance[<span class="string">&quot;overall&quot;</span>], indent=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &#123;</span></span><br><span class="line"><span class="comment">#   &quot;precision&quot;: 0.8065551302331581,</span></span><br><span class="line"><span class="comment">#   &quot;recall&quot;: 0.8066666666666666,</span></span><br><span class="line"><span class="comment">#   &quot;f1&quot;: 0.8062901077799052,</span></span><br><span class="line"><span class="comment">#   &quot;num_samples&quot;: 18000.0</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br></pre></td></tr></table></figure><h3 id="Glove-frozen">Glove (frozen)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">PRETRAINED_EMBEDDINGS = embedding_matrix</span><br><span class="line">FREEZE_EMBEDDINGS = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize model</span></span><br><span class="line">model = CNN(</span><br><span class="line">    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,</span><br><span class="line">    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,</span><br><span class="line">    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,</span><br><span class="line">    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)</span><br><span class="line">model = model.to(device) <span class="comment"># set device</span></span><br><span class="line"><span class="built_in">print</span> (model.named_parameters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &lt;bound method Module.named_parameters of CNN(</span></span><br><span class="line"><span class="comment">#   (embeddings): Embedding(5000, 100, padding_idx=0)</span></span><br><span class="line"><span class="comment">#   (conv): ModuleList(</span></span><br><span class="line"><span class="comment">#     (0): Conv1d(100, 50, kernel_size=(2,), stride=(1,))</span></span><br><span class="line"><span class="comment">#     (1): Conv1d(100, 50, kernel_size=(3,), stride=(1,))</span></span><br><span class="line"><span class="comment">#     (2): Conv1d(100, 50, kernel_size=(4,), stride=(1,))</span></span><br><span class="line"><span class="comment">#   )</span></span><br><span class="line"><span class="comment">#   (dropout): Dropout(p=0.1, inplace=False)</span></span><br><span class="line"><span class="comment">#   (fc1): Linear(in_features=150, out_features=100, bias=True)</span></span><br><span class="line"><span class="comment">#   (fc2): Linear(in_features=100, out_features=4, bias=True)</span></span><br><span class="line"><span class="comment"># )&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define Loss</span></span><br><span class="line">class_weights_tensor = torch.Tensor(<span class="built_in">list</span>(class_weights.values())).to(device)</span><br><span class="line">loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define optimizer &amp; scheduler</span></span><br><span class="line">optimizer = Adam(model.parameters(), lr=LEARNING_RATE)</span><br><span class="line">scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(</span><br><span class="line">    optimizer, mode=<span class="string">&quot;min&quot;</span>, factor=<span class="number">0.1</span>, patience=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Trainer module</span></span><br><span class="line">trainer = Trainer(model=model, device=device, loss_fn=loss_fn,</span><br><span class="line">                  optimizer=optimizer, scheduler=scheduler)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train</span></span><br><span class="line">best_model = trainer.train(NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Epoch: 1 | train_loss: 0.51462, val_loss: 0.49800, lr: 1.00E-03, _patience: 5</span></span><br><span class="line"><span class="comment"># Epoch: 2 | train_loss: 0.43604, val_loss: 0.49792, lr: 1.00E-03, _patience: 5</span></span><br><span class="line"><span class="comment"># Epoch: 3 | train_loss: 0.39698, val_loss: 0.50526, lr: 1.00E-03, _patience: 4</span></span><br><span class="line"><span class="comment"># Epoch: 4 | train_loss: 0.36507, val_loss: 0.51659, lr: 1.00E-03, _patience: 3</span></span><br><span class="line"><span class="comment"># Epoch: 5 | train_loss: 0.33745, val_loss: 0.53612, lr: 1.00E-03, _patience: 2</span></span><br><span class="line"><span class="comment"># Epoch: 6 | train_loss: 0.31418, val_loss: 0.56722, lr: 1.00E-04, _patience: 1</span></span><br><span class="line"><span class="comment"># Stopping early!</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get predictions</span></span><br><span class="line">test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)</span><br><span class="line">y_pred = np.argmax(y_prob, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Determine performance</span></span><br><span class="line">performance = get_metrics(</span><br><span class="line">    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)</span><br><span class="line"><span class="built_in">print</span> (json.dumps(performance[<span class="string">&quot;overall&quot;</span>], indent=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &#123;</span></span><br><span class="line"><span class="comment">#   &quot;precision&quot;: 0.8264024010717701,</span></span><br><span class="line"><span class="comment">#   &quot;recall&quot;: 0.8269444444444445,</span></span><br><span class="line"><span class="comment">#   &quot;f1&quot;: 0.8263287754212785,</span></span><br><span class="line"><span class="comment">#   &quot;num_samples&quot;: 18000.0</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br></pre></td></tr></table></figure><h3 id="GloVe-fine-tuned">GloVe (fine-tuned)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">PRETRAINED_EMBEDDINGS = embedding_matrix</span><br><span class="line">FREEZE_EMBEDDINGS = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize model</span></span><br><span class="line">model = CNN(</span><br><span class="line">    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,</span><br><span class="line">    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,</span><br><span class="line">    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,</span><br><span class="line">    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)</span><br><span class="line">model = model.to(device) <span class="comment"># set device</span></span><br><span class="line"><span class="built_in">print</span> (model.named_parameters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &lt;bound method Module.named_parameters of CNN(</span></span><br><span class="line"><span class="comment">#   (embeddings): Embedding(5000, 100, padding_idx=0)</span></span><br><span class="line"><span class="comment">#   (conv): ModuleList(</span></span><br><span class="line"><span class="comment">#     (0): Conv1d(100, 50, kernel_size=(2,), stride=(1,))</span></span><br><span class="line"><span class="comment">#     (1): Conv1d(100, 50, kernel_size=(3,), stride=(1,))</span></span><br><span class="line"><span class="comment">#     (2): Conv1d(100, 50, kernel_size=(4,), stride=(1,))</span></span><br><span class="line"><span class="comment">#   )</span></span><br><span class="line"><span class="comment">#   (dropout): Dropout(p=0.1, inplace=False)</span></span><br><span class="line"><span class="comment">#   (fc1): Linear(in_features=150, out_features=100, bias=True)</span></span><br><span class="line"><span class="comment">#   (fc2): Linear(in_features=100, out_features=4, bias=True)</span></span><br><span class="line"><span class="comment"># )&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define Lossclass_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define optimizer &amp; scheduler</span></span><br><span class="line">optimizer = Adam(model.parameters(), lr=LEARNING_RATE)</span><br><span class="line">scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(</span><br><span class="line">    optimizer, mode=<span class="string">&quot;min&quot;</span>, factor=<span class="number">0.1</span>, patience=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Trainer module</span></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model, device=device, loss_fn=loss_fn,</span><br><span class="line">    optimizer=optimizer, scheduler=scheduler)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train</span></span><br><span class="line">best_model = trainer.train(</span><br><span class="line">    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Epoch: 1 | train_loss: 0.48751, val_loss: 0.45729, lr: 1.00E-03, _patience: 5</span></span><br><span class="line"><span class="comment"># Epoch: 2 | train_loss: 0.38391, val_loss: 0.45669, lr: 1.00E-03, _patience: 5</span></span><br><span class="line"><span class="comment"># Epoch: 3 | train_loss: 0.33045, val_loss: 0.47826, lr: 1.00E-03, _patience: 4</span></span><br><span class="line"><span class="comment"># Epoch: 4 | train_loss: 0.27825, val_loss: 0.52608, lr: 1.00E-03, _patience: 3</span></span><br><span class="line"><span class="comment"># Epoch: 5 | train_loss: 0.22646, val_loss: 0.60470, lr: 1.00E-03, _patience: 2</span></span><br><span class="line"><span class="comment"># Epoch: 6 | train_loss: 0.18130, val_loss: 0.70291, lr: 1.00E-04, _patience: 1</span></span><br><span class="line"><span class="comment"># Stopping early!</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get predictions</span></span><br><span class="line">test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)</span><br><span class="line">y_pred = np.argmax(y_prob, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Determine performance</span></span><br><span class="line">performance = get_metrics(</span><br><span class="line">    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)</span><br><span class="line"><span class="built_in">print</span> (json.dumps(performance[<span class="string">&quot;overall&quot;</span>], indent=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &#123;</span></span><br><span class="line"><span class="comment">#   &quot;precision&quot;: 0.8246875013006352,</span></span><br><span class="line"><span class="comment">#   &quot;recall&quot;: 0.8251666666666667,</span></span><br><span class="line"><span class="comment">#   &quot;f1&quot;: 0.8248028697657125,</span></span><br><span class="line"><span class="comment">#   &quot;num_samples&quot;: 18000.0</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br></pre></td></tr></table></figure><p>Ok, 保存一些必要的模型数据，以供后续能够完整的加载和使用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Save artifacts</span></span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="built_in">dir</span> = Path(<span class="string">&quot;cnn&quot;</span>)</span><br><span class="line"><span class="built_in">dir</span>.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">label_encoder.save(fp=Path(<span class="built_in">dir</span>, <span class="string">&quot;label_encoder.json&quot;</span>))</span><br><span class="line">tokenizer.save(fp=Path(<span class="built_in">dir</span>, <span class="string">&quot;tokenizer.json&quot;</span>))</span><br><span class="line">torch.save(best_model.state_dict(), Path(<span class="built_in">dir</span>, <span class="string">&quot;model.pt&quot;</span>))</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(Path(<span class="built_in">dir</span>, <span class="string">&quot;performance.json&quot;</span>), <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    json.dump(performance, indent=<span class="number">2</span>, sort_keys=<span class="literal">False</span>, fp=fp)</span><br></pre></td></tr></table></figure><h2 id="Inference">Inference</h2><p>接下来看看如何利用模型进行推理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_probability_distribution</span>(<span class="params">y_prob, classes</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Create a dict of class probabilities from an array.&quot;&quot;&quot;</span></span><br><span class="line">    results = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i, class_ <span class="keyword">in</span> <span class="built_in">enumerate</span>(classes):</span><br><span class="line">        results[class_] = np.float64(y_prob[i])</span><br><span class="line">    sorted_results = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">sorted</span>(</span><br><span class="line">        results.items(), key=<span class="keyword">lambda</span> item: item[<span class="number">1</span>], reverse=<span class="literal">True</span>)&#125;</span><br><span class="line">    <span class="keyword">return</span> sorted_results</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load artifacts</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">label_encoder = LabelEncoder.load(fp=Path(<span class="built_in">dir</span>, <span class="string">&quot;label_encoder.json&quot;</span>))</span><br><span class="line">tokenizer = Tokenizer.load(fp=Path(<span class="built_in">dir</span>, <span class="string">&quot;tokenizer.json&quot;</span>))</span><br><span class="line">model = CNN(</span><br><span class="line">    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,</span><br><span class="line">    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,</span><br><span class="line">    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,</span><br><span class="line">    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)</span><br><span class="line">model.load_state_dict(torch.load(Path(<span class="built_in">dir</span>, <span class="string">&quot;model.pt&quot;</span>), map_location=device))</span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># CNN(</span></span><br><span class="line"><span class="comment">#   (embeddings): Embedding(5000, 100, padding_idx=0)</span></span><br><span class="line"><span class="comment">#   (conv): ModuleList(</span></span><br><span class="line"><span class="comment">#     (0): Conv1d(100, 50, kernel_size=(2,), stride=(1,))</span></span><br><span class="line"><span class="comment">#     (1): Conv1d(100, 50, kernel_size=(3,), stride=(1,))</span></span><br><span class="line"><span class="comment">#     (2): Conv1d(100, 50, kernel_size=(4,), stride=(1,))</span></span><br><span class="line"><span class="comment">#   )</span></span><br><span class="line"><span class="comment">#   (dropout): Dropout(p=0.1, inplace=False)</span></span><br><span class="line"><span class="comment">#   (fc1): Linear(in_features=150, out_features=100, bias=True)</span></span><br><span class="line"><span class="comment">#   (fc2): Linear(in_features=100, out_features=4, bias=True)</span></span><br><span class="line"><span class="comment"># )</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize trainer</span></span><br><span class="line">trainer = Trainer(model=model, device=device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Dataloader</span></span><br><span class="line">text = <span class="string">&quot;The final tennis tournament starts next week.&quot;</span></span><br><span class="line">X = tokenizer.texts_to_sequences([preprocess(text)])</span><br><span class="line"><span class="built_in">print</span> (tokenizer.sequences_to_texts(X))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># [&#x27;final tennis tournament starts next week&#x27;]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">y_filler = label_encoder.encode([label_encoder.classes[<span class="number">0</span>]]*<span class="built_in">len</span>(X))</span><br><span class="line">dataset = Dataset(X=X, y=y_filler, max_filter_size=max_filter_size)</span><br><span class="line">dataloader = dataset.create_dataloader(batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Inference</span></span><br><span class="line">y_prob = trainer.predict_step(dataloader)</span><br><span class="line">y_pred = np.argmax(y_prob, axis=<span class="number">1</span>)</span><br><span class="line">label_encoder.decode(y_pred)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Class distributions</span></span><br><span class="line">prob_dist = get_probability_distribution(y_prob=y_prob[<span class="number">0</span>], classes=label_encoder.classes)</span><br><span class="line"><span class="built_in">print</span> (json.dumps(prob_dist, indent=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &#123;</span></span><br><span class="line"><span class="comment">#   &quot;Sports&quot;: 1.0,</span></span><br><span class="line"><span class="comment">#   &quot;World&quot;: 7.881690092248483e-12,</span></span><br><span class="line"><span class="comment">#   &quot;Sci/Tech&quot;: 1.270132816196673e-13,</span></span><br><span class="line"><span class="comment">#   &quot;Business&quot;: 2.3282168800871726e-18</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br></pre></td></tr></table></figure><p>推理结果是 “The final tennis tournament starts next week.” 这篇文章属于 “Sports” 这个分类。</p><p>我们可以看看不同的n-gram提取器，在最大池化层里提取都是什么。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">sample_index = <span class="number">0</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;Original text:\n<span class="subst">&#123;text&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;\nPreprocessed text:\n<span class="subst">&#123;tokenizer.sequences_to_texts(X)[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;\nMost important n-grams:&quot;</span>)</span><br><span class="line"><span class="comment"># Process conv outputs for each unique filter size</span></span><br><span class="line"><span class="keyword">for</span> i, filter_size <span class="keyword">in</span> <span class="built_in">enumerate</span>(FILTER_SIZES):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Identify most important n-gram (excluding last token)</span></span><br><span class="line">    popular_indices = collections.Counter([np.argmax(conv_output) \</span><br><span class="line">            <span class="keyword">for</span> conv_output <span class="keyword">in</span> conv_outputs[i]])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get corresponding text</span></span><br><span class="line">    start = popular_indices.most_common(<span class="number">1</span>)[-<span class="number">1</span>][<span class="number">0</span>]</span><br><span class="line">    n_gram = <span class="string">&quot; &quot;</span>.join([token <span class="keyword">for</span> token <span class="keyword">in</span> tokens[start:start+filter_size]])</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">f&quot;[<span class="subst">&#123;filter_size&#125;</span>-gram]: <span class="subst">&#123;n_gram&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Original text:</span></span><br><span class="line"><span class="comment"># The final tennis tournament starts next week.</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># Preprocessed text:</span></span><br><span class="line"><span class="comment"># final tennis tournament starts next week</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># Most important n-grams:</span></span><br><span class="line"><span class="comment"># [2-gram]: tennis tournament</span></span><br><span class="line"><span class="comment"># [3-gram]: final tennis tournament</span></span><br><span class="line"><span class="comment"># [4-gram]: final tennis tournament starts</span></span><br></pre></td></tr></table></figure><h2 id="Ending">Ending</h2><p>如你所见，加入Embedding层的卷积神经网络模型的表现，相较于只有one-hot编码的模型，性能上有了很大的提升。</p>]]></content>
    
    <summary type="html">
    
      Explore and motivate the need for representation via embeddings.
    
    </summary>
    
    
      <category term="Way2AI" scheme="https://neo1989.net/categories/Way2AI/"/>
    
    
      <category term="Coder" scheme="https://neo1989.net/tags/Coder/"/>
    
      <category term="AI" scheme="https://neo1989.net/tags/AI/"/>
    
      <category term="PyTorch" scheme="https://neo1989.net/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>Way2AI · Embeddings （上）</title>
    <link href="https://neo1989.net/Way2AI/Way2AI-Embeddings-1/"/>
    <id>https://neo1989.net/Way2AI/Way2AI-Embeddings-1/</id>
    <published>2023-07-04T07:28:36.000Z</published>
    <updated>2023-07-04T15:35:49.798Z</updated>
    
    <content type="html"><![CDATA[<h2 id="TL-DR">TL;DR</h2><p>虽然One-Hot编码能够将离散变量表示为二进制向量，且能保留结构化信息，但它有两个主要的缺点：</p><ul><li>线性依赖词表的大小。这在语料库很大的情况下会带来问题如维数巨大且稀疏</li><li>单个token的表示，不保留其相对于其它token的关系</li></ul><p>本文将简单介绍embeddings，及它是如何解决one-hot编码的所有缺点。</p><h2 id="Learning-embeddings">Learning embeddings</h2><p>我们将通过使用PyTorch建模来学习embeddings，不过首先，我们学习一下专门用于嵌入和主题建模的库<a href="https://radimrehurek.com/gensim/" title="Gensim">Gensim</a>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line">nltk.download(<span class="string">&quot;punkt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">1024</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split text into sentence</span></span><br><span class="line">tokenizer = nltk.data.load(<span class="string">&quot;tokenizers/punkt/english.pickle&quot;</span>)</span><br><span class="line">book = requests.get(<span class="string">&quot;https://s3.mindex.xyz/datasets/harrypotter.txt&quot;</span>).content</span><br><span class="line">sentences = tokenizer.tokenize(<span class="built_in">str</span>(book))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;<span class="subst">&#123;<span class="built_in">len</span>(sentences)&#125;</span> sentences&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># 12449 sentences</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Conditional preprocessing on our text.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Lower</span></span><br><span class="line">    text = text.lower()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Spacing and filters</span></span><br><span class="line">    text = re.sub(<span class="string">r&quot;([-;;.,!?&lt;=&gt;])&quot;</span>, <span class="string">r&quot; \1 &quot;</span>, text)  <span class="comment"># separate punctuation tied to words</span></span><br><span class="line">    text = re.sub(<span class="string">&quot;[^A-Za-z0-9]+&quot;</span>, <span class="string">&quot; &quot;</span>, text)  <span class="comment"># remove non alphanumeric chars</span></span><br><span class="line">    text = re.sub(<span class="string">&quot; +&quot;</span>, <span class="string">&quot; &quot;</span>, text)  <span class="comment"># remove multiple spaces</span></span><br><span class="line">    text = text.strip()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Separate into word tokens</span></span><br><span class="line">    text = text.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Preprocess sentences</span></span><br><span class="line"><span class="built_in">print</span> (sentences[<span class="number">11</span>])</span><br><span class="line">sentences = [preprocess(s) <span class="keyword">for</span> s <span class="keyword">in</span> sentences]</span><br><span class="line"><span class="built_in">print</span> (sentences[<span class="number">11</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Snape nodded, but did not elaborate.</span></span><br><span class="line"><span class="comment"># [&#x27;snape&#x27;, &#x27;nodded&#x27;, &#x27;but&#x27;, &#x27;did&#x27;, &#x27;not&#x27;, &#x27;elaborate&#x27;]</span></span><br></pre></td></tr></table></figure><p>embeddings的核心就是单词表示，且这种表示不只是依赖单词本身，而且依赖它的上下文。我们有几种不同的方法可以实现这一目标：</p><ul><li>给定上下文中的单词，预测目标单词（CBOW )</li><li>给定目标词，预测上下文词（skip-gram)</li><li>给定一个文本序列，预测下一个单词（ LM ）</li></ul><p>上面这些方法都涉及到创建数据来训练模型。句子中的每个单词都成为目标单词，上下文由窗口决定。</p><p>如下图（skip-gram），窗口大小为2。我们对语料库中的每个句子重复此操作，以产生用于无监督任务的训练数据。这个任务的核心逻辑是，相似的词会出现在相似的上下文中，我们可以通过反复的使用这种(target, context)文本对来学习这种关系。</p><p><img src="//s3.mindex.xyz/tmp/7bf17eefb4ff89642692d20685c9cb1a.webp" alt=""></p><p>我们可以使用上述任何一种方法来应用Embeddings。在任务中到底选择哪种方案，可能更多的需要依靠在监督任务上的表现来做选择。</p><h3 id="Word2Vec">Word2Vec</h3><p>当我们有大量的词汇表需要应用Embeddings时，事情会变得复杂。回想一下在反向传播中使用softmax更新正确的和不正确的分类权重，这种情况下每一次反向传播都意味着一个巨大的计算。因此解决方案是使用<a href="http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/" title="Word2Vec Negative Sampling">负采样</a>，它只更新正确的类和随机一部分不正确的类（NEGATIVE_SAMPLING = 20）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gensim</span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> KeyedVectors</span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</span><br><span class="line"></span><br><span class="line">EMBEDDING_DIM = <span class="number">100</span></span><br><span class="line">WINDOW = <span class="number">5</span></span><br><span class="line">MIN_COUNT = <span class="number">3</span></span><br><span class="line">SKIP_GRAM = <span class="number">1</span></span><br><span class="line">NEGATIVE_SAMPLING = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">w2v = Word2Vec(</span><br><span class="line">    sentences=sentences, vector_size=EMBEDDING_DIM,</span><br><span class="line">    window=WINDOW, min_count=MIN_COUNT,</span><br><span class="line">    sg=SKIP_GRAM, negative=NEGATIVE_SAMPLING)</span><br><span class="line"><span class="built_in">print</span> (w2v)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Word2Vec&lt;vocab=4937, vector_size=100, alpha=0.025&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Vector for each word</span></span><br><span class="line">w2v.wv.get_vector(<span class="string">&quot;potter&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># array([ 0.04592679,  0.26393083, -0.29759625, -0.51007414,  0.02860732,</span></span><br><span class="line"><span class="comment">#        -0.01302573,  0.3703193 ,  0.14425582, -0.4187037 ,  0.04296769,</span></span><br><span class="line"><span class="comment">#        -0.13030362, -0.30441925, -0.14958233,  0.04964258,  0.14798391,</span></span><br><span class="line"><span class="comment">#        -0.18539314,  0.51730794,  0.01598365, -0.11325987, -0.6307836 ,</span></span><br><span class="line"><span class="comment">#         0.39244524,  0.25232184,  0.29555508, -0.22162063, -0.29100868,</span></span><br><span class="line"><span class="comment">#        -0.22083738, -0.52918744, -0.68654346, -0.09764519,  0.05514489,</span></span><br><span class="line"><span class="comment">#         0.06108054,  0.3587375 , -0.01166064, -0.42530054, -0.05000629,</span></span><br><span class="line"><span class="comment">#         0.45623606, -0.29811206, -0.09037815, -0.0024387 , -0.41930553,</span></span><br><span class="line"><span class="comment">#         0.12495753, -0.1773121 ,  0.19551197,  0.02754493,  0.25369856,</span></span><br><span class="line"><span class="comment">#         0.10022393, -0.38912103, -0.10274333, -0.24544689,  0.00851442,</span></span><br><span class="line"><span class="comment">#         0.26698554, -0.03026148,  0.12343717, -0.07433262,  0.0162609 ,</span></span><br><span class="line"><span class="comment">#         0.15033086,  0.09943663,  0.28371716, -0.26024884, -0.05571229,</span></span><br><span class="line"><span class="comment">#         0.0938114 , -0.00562614, -0.11472147,  0.21217017,  0.12490374,</span></span><br><span class="line"><span class="comment">#         0.34131378,  0.10346038,  0.38650215, -0.44265935, -0.02233333,</span></span><br><span class="line"><span class="comment">#        -0.47005087, -0.28585035,  0.06968105,  0.08989634,  0.22004889,</span></span><br><span class="line"><span class="comment">#        -0.22940454, -0.06248426,  0.089827  , -0.35011858,  0.11977731,</span></span><br><span class="line"><span class="comment">#        -0.06323916,  0.0940324 , -0.31842625,  0.53730965,  0.17043817,</span></span><br><span class="line"><span class="comment">#         0.15869781,  0.40275395,  0.04705542,  0.35397893,  0.00738561,</span></span><br><span class="line"><span class="comment">#         0.21539825,  0.14310665,  0.13341616, -0.0660746 ,  0.42496106,</span></span><br><span class="line"><span class="comment">#         0.09145384,  0.47487733, -0.23636843,  0.00715503,  0.05220298],</span></span><br><span class="line"><span class="comment">#       dtype=float32)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get nearest neighbors (excluding itself)</span></span><br><span class="line">w2v.wv.most_similar(positive=<span class="string">&quot;scar&quot;</span>, topn=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># [(&#x27;forehead&#x27;, 0.9045635461807251),</span></span><br><span class="line"><span class="comment">#  (&#x27;pain&#x27;, 0.9014869928359985),</span></span><br><span class="line"><span class="comment">#  (&#x27;mouth&#x27;, 0.8918080925941467),</span></span><br><span class="line"><span class="comment">#  (&#x27;prickling&#x27;, 0.890386164188385),</span></span><br><span class="line"><span class="comment">#  (&#x27;throat&#x27;, 0.8795480728149414)]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Saving and loading</span></span><br><span class="line">w2v.wv.save_word2vec_format(<span class="string">&quot;w2v.bin&quot;</span>, binary=<span class="literal">True</span>)</span><br><span class="line">wv = KeyedVectors.load_word2vec_format(<span class="string">&quot;w2v.bin&quot;</span>, binary=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="FastText">FastText</h3><p>当一个词在我们的词汇表中不存在时会发生什么？我们可以分配一个 UNK 标识来表示为未登录词，或者使用<a href="https://radimrehurek.com/gensim/models/fasttext.html" title="FastText">FastText</a>，它使用字符级的n-grams算法来embed单词，这样有助于处理罕见词,拼错的词，以及语料库中不存在但相似的词。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> FastText</span><br><span class="line"></span><br><span class="line"><span class="comment"># Super fast because of optimized C code under the hood</span></span><br><span class="line">ft = FastText(sentences=sentences, vector_size=EMBEDDING_DIM,</span><br><span class="line">              window=WINDOW, min_count=MIN_COUNT,</span><br><span class="line">              sg=SKIP_GRAM, negative=NEGATIVE_SAMPLING)</span><br><span class="line"><span class="built_in">print</span> (ft)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># FastText&lt;vocab=4937, vector_size=100, alpha=0.025&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># This word doesn&#x27;t exist so the word2vec model will error out</span></span><br><span class="line">wv.most_similar(positive=<span class="string">&#x27;scarring&#x27;</span>, topn=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># KeyError: &quot;Key &#x27;scarring&#x27; not present in vocabulary&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># FastText will use n-grams to embed an OOV word</span></span><br><span class="line">ft.wv.most_similar(positive=<span class="string">&#x27;scarring&#x27;</span>, topn=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># [(&#x27;swimming&#x27;, 0.9938331246376038),</span></span><br><span class="line"><span class="comment">#  (&#x27;howling&#x27;, 0.9927006959915161),</span></span><br><span class="line"><span class="comment">#  (&#x27;dabbing&#x27;, 0.9923058748245239),</span></span><br><span class="line"><span class="comment">#  (&#x27;wriggling&#x27;, 0.9921060800552368),</span></span><br><span class="line"><span class="comment">#  (&#x27;bulging&#x27;, 0.9919766783714294)]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Save and loading</span></span><br><span class="line">ft.wv.save(<span class="string">&quot;ft.bin&quot;</span>)</span><br><span class="line">ftwv = KeyedVectors.load(<span class="string">&quot;ft.bin&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="Pretrained-embeddings">Pretrained embeddings</h2><p>我们可以利用上述方法从头开始应用embeddings，也可以利用已经在百万文档上训练过的预训练embeddings。流行的包括<a href="https://www.tensorflow.org/tutorials/text/word2vec" title="Word2Vec">Word2Vec</a>、<a href="https://nlp.stanford.edu/projects/glove/" title="GloVe">GloVe</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Preview of the GloVe embeddings file</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;glove.6B.100d.txt&quot;</span>, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    line = <span class="built_in">next</span>(fp)</span><br><span class="line">    values = line.split()</span><br><span class="line">    word = values[<span class="number">0</span>]</span><br><span class="line">    embedding = np.asarray(values[<span class="number">1</span>:], dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">f&quot;word: <span class="subst">&#123;word&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">f&quot;embedding:\n<span class="subst">&#123;embedding&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">f&quot;embedding dim: <span class="subst">&#123;<span class="built_in">len</span>(embedding)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># word: the</span></span><br><span class="line"><span class="comment"># embedding:</span></span><br><span class="line"><span class="comment"># [-0.038194 -0.24487   0.72812  -0.39961   0.083172  0.043953 -0.39141</span></span><br><span class="line"><span class="comment">#   0.3344   -0.57545   0.087459  0.28787  -0.06731   0.30906  -0.26384</span></span><br><span class="line"><span class="comment">#  -0.13231  -0.20757   0.33395  -0.33848  -0.31743  -0.48336   0.1464</span></span><br><span class="line"><span class="comment">#  -0.37304   0.34577   0.052041  0.44946  -0.46971   0.02628  -0.54155</span></span><br><span class="line"><span class="comment">#  -0.15518  -0.14107  -0.039722  0.28277   0.14393   0.23464  -0.31021</span></span><br><span class="line"><span class="comment">#   0.086173  0.20397   0.52624   0.17164  -0.082378 -0.71787  -0.41531</span></span><br><span class="line"><span class="comment">#   0.20335  -0.12763   0.41367   0.55187   0.57908  -0.33477  -0.36559</span></span><br><span class="line"><span class="comment">#  -0.54857  -0.062892  0.26584   0.30205   0.99775  -0.80481  -3.0243</span></span><br><span class="line"><span class="comment">#   0.01254  -0.36942   2.2167    0.72201  -0.24978   0.92136   0.034514</span></span><br><span class="line"><span class="comment">#   0.46745   1.1079   -0.19358  -0.074575  0.23353  -0.052062 -0.22044</span></span><br><span class="line"><span class="comment">#   0.057162 -0.15806  -0.30798  -0.41625   0.37972   0.15006  -0.53212</span></span><br><span class="line"><span class="comment">#  -0.2055   -1.2526    0.071624  0.70565   0.49744  -0.42063   0.26148</span></span><br><span class="line"><span class="comment">#  -1.538    -0.30223  -0.073438 -0.28312   0.37104  -0.25217   0.016215</span></span><br><span class="line"><span class="comment">#  -0.017099 -0.38984   0.87424  -0.72569  -0.51058  -0.52028  -0.1459</span></span><br><span class="line"><span class="comment">#   0.8278    0.27062 ]</span></span><br><span class="line"><span class="comment"># embedding dim: 100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load embeddings (may take a minute)</span></span><br><span class="line">glove = KeyedVectors.load_word2vec_format(<span class="string">&quot;glove.6B.100d.txt&quot;</span>, binary=<span class="literal">False</span>, no_header=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># (king - man) + woman = ?</span></span><br><span class="line"><span class="comment"># king - man = ? -  woman</span></span><br><span class="line">glove.most_similar(positive=[<span class="string">&quot;woman&quot;</span>, <span class="string">&quot;king&quot;</span>], negative=[<span class="string">&quot;man&quot;</span>], topn=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># [(&#x27;queen&#x27;, 0.7698540687561035),</span></span><br><span class="line"><span class="comment">#  (&#x27;monarch&#x27;, 0.6843381524085999),</span></span><br><span class="line"><span class="comment">#  (&#x27;throne&#x27;, 0.6755736470222473),</span></span><br><span class="line"><span class="comment">#  (&#x27;daughter&#x27;, 0.6594556570053101),</span></span><br><span class="line"><span class="comment">#  (&#x27;princess&#x27;, 0.6520534157752991)]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get nearest neighbors (excluding itself)</span></span><br><span class="line">glove.most_similar(positive=<span class="string">&quot;goku&quot;</span>, topn=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># [(&#x27;gohan&#x27;, 0.7246542572975159),</span></span><br><span class="line"><span class="comment">#  (&#x27;bulma&#x27;, 0.6497020125389099),</span></span><br><span class="line"><span class="comment">#  (&#x27;raistlin&#x27;, 0.644360363483429),</span></span><br><span class="line"><span class="comment">#  (&#x27;skaar&#x27;, 0.6316742897033691),</span></span><br><span class="line"><span class="comment">#  (&#x27;guybrush&#x27;, 0.6231325268745422)]</span></span><br></pre></td></tr></table></figure><p>我们可视化一下 king, queen, man, woman 这四个单词的位置关系。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Reduce dimensionality for plotting</span></span><br><span class="line">X = glove[glove.index_to_key]</span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">pca_results = pca.fit_transform(X)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_embeddings</span>(<span class="params">words, embeddings, pca_results</span>):</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        idx = embeddings.key_to_index[word]</span><br><span class="line">        plt.scatter(pca_results[idx, <span class="number">0</span>], pca_results[idx, <span class="number">1</span>])</span><br><span class="line">        plt.annotate(word, xy=(pca_results[idx, <span class="number">0</span>], pca_results[idx, <span class="number">1</span>]))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Visualize</span></span><br><span class="line">plot_embeddings(</span><br><span class="line">    words=[<span class="string">&quot;king&quot;</span>, <span class="string">&quot;queen&quot;</span>, <span class="string">&quot;man&quot;</span>, <span class="string">&quot;woman&quot;</span>], embeddings=glove,</span><br><span class="line">    pca_results=pca_results)</span><br></pre></td></tr></table></figure><p><img src="//s3.mindex.xyz/tmp/6c1b85445e28b27bfed73fc0d1f7d3ec.png" alt=""></p><p>再看一下，离woman和doctor近，但离man远的词有哪些</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Bias in embeddings</span></span><br><span class="line">glove.most_similar(positive=[<span class="string">&quot;woman&quot;</span>, <span class="string">&quot;doctor&quot;</span>], negative=[<span class="string">&quot;man&quot;</span>], topn=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># [(&#x27;nurse&#x27;, 0.7735227942466736),</span></span><br><span class="line"><span class="comment">#  (&#x27;physician&#x27;, 0.7189430594444275),</span></span><br><span class="line"><span class="comment">#  (&#x27;doctors&#x27;, 0.6824328303337097),</span></span><br><span class="line"><span class="comment">#  (&#x27;patient&#x27;, 0.6750683188438416),</span></span><br><span class="line"><span class="comment">#  (&#x27;dentist&#x27;, 0.6726033091545105)]</span></span><br></pre></td></tr></table></figure><h2 id="Ending">Ending</h2><p>下一篇，我们将进一步介绍Embeddings如何提升我们前篇介绍的CNN分类模型。</p>]]></content>
    
    <summary type="html">
    
      Explore and motivate the need for representation via embeddings.
    
    </summary>
    
    
      <category term="Way2AI" scheme="https://neo1989.net/categories/Way2AI/"/>
    
    
      <category term="Coder" scheme="https://neo1989.net/tags/Coder/"/>
    
      <category term="AI" scheme="https://neo1989.net/tags/AI/"/>
    
      <category term="PyTorch" scheme="https://neo1989.net/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>Way2AI · 卷积神经网络</title>
    <link href="https://neo1989.net/Way2AI/Way2AI-CNN/"/>
    <id>https://neo1989.net/Way2AI/Way2AI-CNN/</id>
    <published>2023-06-27T09:30:43.000Z</published>
    <updated>2023-07-04T15:10:06.945Z</updated>
    
    <content type="html"><![CDATA[<h2 id="TL-DR">TL;DR</h2><p>本文简单示范了如何利用CNN处理NLP任务。</p><p>CNNs的核心就是利用卷积（滑动）操作来提取数据特征的卷积核（aka kernels, filters,weights, etc.)。它们随机初始化但通过参数共享来提取特征。</p><p><img src="//s3.mindex.xyz/tmp/1a58a0c1e58cd3f543995ecee0eb71d4.gif" alt=""></p><h2 id="Set-up">Set up</h2><p>复用<a href="http://neo1989.net/Way2AI/Way2AI-utilities/" title="PyTorch实现神经网络的基本套路">《PyTorch实现神经网络的基本套路》</a> 里介绍的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_seeds</span>(<span class="params">seed=<span class="number">1024</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Set seeds for reproducibility.&quot;&quot;&quot;</span></span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    random.seed(seed)</span><br><span class="line">    touch.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed_all(seed)  <span class="comment"># multi-GPU</span></span><br><span class="line"></span><br><span class="line">set_seeds(seed=<span class="number">1024</span>)</span><br><span class="line"></span><br><span class="line">cuda = <span class="literal">True</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span>(torch.cuda.is_available() <span class="keyword">and</span> cuda) <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">torch.set_default_tensor_type(&#123;<span class="string">&quot;cuda&quot;</span>: <span class="string">&quot;torch.cuda.FloatTensor&quot;</span>, <span class="string">&quot;cpu&quot;</span>: <span class="string">&quot;torch.FloatTensor&quot;</span>&#125;.get(<span class="built_in">str</span>(device)))</span><br></pre></td></tr></table></figure><h3 id="Load-data">Load data</h3><p>我们将在<a href="https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset" title="AG News Classification Dataset">AGNews dataset</a> 这个数据集上完成本次学习任务。这是一份来自4个不同新闻分类120k条新闻标题样本。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load data</span></span><br><span class="line">url = <span class="string">&quot;https://s3.mindex.xyz/datasets/news.csv&quot;</span></span><br><span class="line">df = pd.read_csv(url, header=<span class="number">0</span>)</span><br><span class="line">df = df.sample(frac=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure><p><img src="//s3.mindex.xyz/tmp/5820e01cf3a5f9f93ce85ba8d488647e.png" alt=""></p><h3 id="Preprocessing">Preprocessing</h3><p>首先要做的，是对这些数据进行预处理，手段包括删除停用词、字母小写（英文）、词形还原词干提取、中文分词、正则处理等。</p><p>由于我们的任务是纯英文数据，这里使用英文的通用处理方法。中文任务以后再表。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> PorterStemmer</span><br><span class="line"></span><br><span class="line">nltk.download(<span class="string">&quot;stopwords&quot;</span>)</span><br><span class="line">STOPWORDS = stopwords.words(<span class="string">&quot;english&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (STOPWORDS[:<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># [&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;]</span></span><br><span class="line"></span><br><span class="line">porter = PorterStemmer()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">text, stopwords=STOPWORDS</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Conditional preprocessing on our text unique to our task.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Lower</span></span><br><span class="line">    text = text.lower()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Remove stopwords</span></span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">r&quot;\b(&quot;</span> + <span class="string">r&quot;|&quot;</span>.join(stopwords) + <span class="string">r&quot;)\b\s*&quot;</span>)</span><br><span class="line">    text = pattern.sub(<span class="string">&quot;&quot;</span>, text)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Remove words in parenthesis</span></span><br><span class="line">    text = re.sub(<span class="string">r&quot;\([^)]*\)&quot;</span>, <span class="string">&quot;&quot;</span>, text)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Spacing and filters</span></span><br><span class="line">    text = re.sub(<span class="string">r&quot;([-;;.,!?&lt;=&gt;])&quot;</span>, <span class="string">r&quot; \1 &quot;</span>, text)  <span class="comment"># separate punctuation tied to words</span></span><br><span class="line">    text = re.sub(<span class="string">&quot;[^A-Za-z0-9]+&quot;</span>, <span class="string">&quot; &quot;</span>, text)  <span class="comment"># remove non alphanumeric chars</span></span><br><span class="line">    text = re.sub(<span class="string">&quot; +&quot;</span>, <span class="string">&quot; &quot;</span>, text)  <span class="comment"># remove multiple spaces</span></span><br><span class="line">    text = text.strip()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Apply to dataframe</span></span><br><span class="line">preprocessed_df = df.copy()</span><br><span class="line">preprocessed_df.title = preprocessed_df.title.apply(preprocess)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;<span class="subst">&#123;df.title.values[-<span class="number">1</span>]&#125;</span>\n\n<span class="subst">&#123;preprocessed_df.title.values[-<span class="number">1</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Oil Slips Under \$55 a Barrel</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># oil slips 55 barrel</span></span><br></pre></td></tr></table></figure><h3 id="Split-data">Split data</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">TRAIN_SIZE = <span class="number">0.7</span></span><br><span class="line">VAL_SIZE = <span class="number">0.15</span></span><br><span class="line">TEST_SIZE = <span class="number">0.15</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_val_test_split</span>(<span class="params">X, y, train_size</span>):</span><br><span class="line">    X_train, X_, y_train,y_ = train_test_split(X, y, train_size=train_size, stratify=y)</span><br><span class="line">    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=<span class="number">0.5</span>, stratify=y_)</span><br><span class="line">    <span class="keyword">return</span> X_train, X_val, X_test, y_train, y_val, y_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Data</span></span><br><span class="line">X = preprocessed_df[<span class="string">&quot;title&quot;</span>].values</span><br><span class="line">y = preprocessed_df[<span class="string">&quot;category&quot;</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create data splits</span></span><br><span class="line">X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X=X, y=y, train_size=TRAIN_SIZE)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_train: <span class="subst">&#123;X_train.shape&#125;</span>, y_train: <span class="subst">&#123;y_train.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_val: <span class="subst">&#123;X_val.shape&#125;</span>, y_val: <span class="subst">&#123;y_val.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_test: <span class="subst">&#123;X_test.shape&#125;</span>, y_test: <span class="subst">&#123;y_test.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;Sample point: <span class="subst">&#123;X_train[<span class="number">0</span>]&#125;</span> → <span class="subst">&#123;y_train[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># X_train: (84000,), y_train: (84000,)</span></span><br><span class="line"><span class="comment"># X_val: (18000,), y_val: (18000,)</span></span><br><span class="line"><span class="comment"># X_test: (18000,), y_test: (18000,)</span></span><br><span class="line"><span class="comment"># Sample point: wenger plans buy new keeper → Sports</span></span><br></pre></td></tr></table></figure><h2 id="Label-encoding">Label encoding</h2><p>复用<a href="http://neo1989.net/Way2AI/Way2AI-utilities/" title="PyTorch实现神经网络的基本套路">《PyTorch实现神经网络的基本套路》</a> 里介绍的 LabelEncoder</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Encode</span></span><br><span class="line">label_encoder = LabelEncoder()</span><br><span class="line">label_encoder.fit(y_train)</span><br><span class="line">NUM_CLASSES = <span class="built_in">len</span>(label_encoder)</span><br><span class="line"><span class="built_in">print</span> (label_encoder.class_to_index)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &#123;&#x27;Business&#x27;: 0, &#x27;Sci/Tech&#x27;: 1, &#x27;Sports&#x27;: 2, &#x27;World&#x27;: 3&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert labels to tokens</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;y_train[0]: <span class="subst">&#123;y_train[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line">y_train = label_encoder.encode(y_train)</span><br><span class="line">y_val = label_encoder.encode(y_val)</span><br><span class="line">y_test = label_encoder.encode(y_test)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;y_train[0]: <span class="subst">&#123;y_train[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># y_train[0]: Sports</span></span><br><span class="line"><span class="comment"># y_train[0]: 2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Class weights</span></span><br><span class="line">counts = np.bincount(y_train)</span><br><span class="line">class_weights = &#123;i: <span class="number">1.0</span>/count <span class="keyword">for</span> i, count <span class="keyword">in</span> <span class="built_in">enumerate</span>(counts)&#125;</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;counts: <span class="subst">&#123;counts&#125;</span>\nweights: <span class="subst">&#123;class_weights&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># counts: [21000 21000 21000 21000]</span></span><br><span class="line"><span class="comment"># weights: &#123;0: 4.761904761904762e-05, 1: 4.761904761904762e-05, 2: 4.761904761904762e-05, 3: 4.761904761904762e-05&#125;</span></span><br></pre></td></tr></table></figure><h2 id="Tokenizer">Tokenizer</h2><p>由于任务要处理的是文本，无法直接送给模型。因此我们定义一个Tokenizer来处理文本数据，目的是将文本序列转化成离散的标记（tokens)，以便后续的处理和分析。这意味着每个token可以映射到一个唯一的索引，这样我们就可以用一个索引数组（向量）来表示文本序列。而一个token可以是一个字符、一个单词、一个词组等等。</p><p>下面是一个示例实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">from</span> more_itertools <span class="keyword">import</span> take</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Tokenizer</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, char_level, num_tokens=<span class="literal">None</span>, pad_token=<span class="string">&quot;&lt;PAD&gt;&quot;</span>, oov_token=<span class="string">&quot;&lt;UNK&gt;&quot;</span>, token_to_index=<span class="literal">None</span></span>):</span><br><span class="line">        self.char_level = char_level</span><br><span class="line">        self.separator = <span class="string">&quot;&quot;</span> <span class="keyword">if</span> self.char_level <span class="keyword">else</span> <span class="string">&quot; &quot;</span></span><br><span class="line">        <span class="keyword">if</span> num_tokens:</span><br><span class="line">            num_tokens -= <span class="number">2</span> <span class="comment"># pad + unk tokens</span></span><br><span class="line">        self.num_tokens = num_tokens</span><br><span class="line">        self.pad_token = pad_token</span><br><span class="line">        self.oov_token = oov_token</span><br><span class="line">        self.token_to_index = token_to_index <span class="keyword">if</span> token_to_index <span class="keyword">else</span> &#123;pad_token: <span class="number">0</span>, oov_token: <span class="number">1</span>&#125;</span><br><span class="line">        self.index_to_token = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> self.token_to_index.items()&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.token_to_index)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;&lt;Tokenizer(num_tokens=<span class="subst">&#123;<span class="built_in">len</span>(self)&#125;</span>)&gt;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit_on_texts</span>(<span class="params">self, texts</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.char_level:</span><br><span class="line">            texts = [text.split(<span class="string">&quot; &quot;</span>) <span class="keyword">for</span> text <span class="keyword">in</span> texts]</span><br><span class="line">        all_tokens = [token <span class="keyword">for</span> text <span class="keyword">in</span> texts <span class="keyword">for</span> token <span class="keyword">in</span> text]</span><br><span class="line">        counts = Counter(all_tokens).most_common(self.num_tokens)</span><br><span class="line">        self.min_token_freq = counts[-<span class="number">1</span>][<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> token, count <span class="keyword">in</span> counts:</span><br><span class="line">            index = <span class="built_in">len</span>(self)</span><br><span class="line">            self.token_to_index[token] = index</span><br><span class="line">            self.index_to_token[index] = token</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">texts_to_sequences</span>(<span class="params">self, texts</span>):</span><br><span class="line">        sequences = []</span><br><span class="line">        <span class="keyword">for</span> text <span class="keyword">in</span> texts:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> self.char_level:</span><br><span class="line">                text = text.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">            sequence = []</span><br><span class="line">            <span class="keyword">for</span> token <span class="keyword">in</span> text:</span><br><span class="line">                sequence.append(self.token_to_index.get(</span><br><span class="line">                    token, self.token_to_index[self.oov_token]))</span><br><span class="line">            sequences.append(np.asarray(sequence))</span><br><span class="line">        <span class="keyword">return</span> sequences</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sequences_to_texts</span>(<span class="params">self, sequences</span>):</span><br><span class="line">        texts = []</span><br><span class="line">        <span class="keyword">for</span> sequence <span class="keyword">in</span> sequences:</span><br><span class="line">            text = []</span><br><span class="line">            <span class="keyword">for</span> index <span class="keyword">in</span> sequence:</span><br><span class="line">                text.append(self.index_to_token.get(index, self.oov_token))</span><br><span class="line">            texts.append(self.separator.join([token <span class="keyword">for</span> token <span class="keyword">in</span> text]))</span><br><span class="line">        <span class="keyword">return</span> texts</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save</span>(<span class="params">self, fp</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(fp, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            contents = &#123;</span><br><span class="line">                <span class="string">&quot;char_level&quot;</span>: self.char_level,</span><br><span class="line">                <span class="string">&quot;oov_token&quot;</span>: self.oov_token,</span><br><span class="line">                <span class="string">&quot;token_to_index&quot;</span>: self.token_to_index</span><br><span class="line">            &#125;</span><br><span class="line">            json.dump(contents, fp, indent=<span class="number">4</span>, sort_keys=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load</span>(<span class="params">cls, fp</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(fp, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            kwargs = json.load(fp=fp)</span><br><span class="line">        <span class="keyword">return</span> cls(**kwargs)</span><br></pre></td></tr></table></figure><p>本次实验我们限制tokens的数量为500个(停用词已删除)，其中包括两个占位的。如果您的计算资源足够，可以使用更大的tokens数量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Tokenize</span></span><br><span class="line">tokenizer = Tokenizer(char_level=<span class="literal">False</span>, num_tokens=<span class="number">500</span>)</span><br><span class="line">tokenizer.fit_on_texts(texts=X_train)</span><br><span class="line">VOCAB_SIZE = <span class="built_in">len</span>(tokenizer)</span><br><span class="line"><span class="built_in">print</span> (tokenizer)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &lt;Tokenizer(num_tokens=500)&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Sample of tokens</span></span><br><span class="line"><span class="built_in">print</span> (take(<span class="number">10</span>, tokenizer.token_to_index.items()))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;least freq token&#x27;s freq: <span class="subst">&#123;tokenizer.min_token_freq&#125;</span>&quot;</span>) <span class="comment"># use this to adjust num_tokens</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># [(&#x27;&lt;PAD&gt;&#x27;, 0), (&#x27;&lt;UNK&gt;&#x27;, 1), (&#x27;39&#x27;, 2), (&#x27;b&#x27;, 3), (&#x27;gt&#x27;, 4), (&#x27;lt&#x27;, 5), (&#x27;us&#x27;, 6), (&#x27;new&#x27;, 7), (&#x27;oil&#x27;, 8), (&#x27;microsoft&#x27;, 9)]</span></span><br><span class="line"><span class="comment"># least freq token&#x27;s freq: 166</span></span><br></pre></td></tr></table></figure><p>Ok，接下来将我们文本数据全部token化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Convert texts to sequences of indices</span></span><br><span class="line">X_train = tokenizer.texts_to_sequences(X_train)</span><br><span class="line">X_val = tokenizer.texts_to_sequences(X_val)</span><br><span class="line">X_test = tokenizer.texts_to_sequences(X_test)</span><br><span class="line">preprocessed_text = tokenizer.sequences_to_texts([X_train[<span class="number">0</span>]])[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;Text to indices:\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  (preprocessed) → <span class="subst">&#123;preprocessed_text&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  (tokenized) → <span class="subst">&#123;X_train[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Text to indices:</span></span><br><span class="line"><span class="comment">#   (preprocessed) → ibm wins time talks &lt;UNK&gt; case</span></span><br><span class="line"><span class="comment">#   (tokenized) → [ 31  32  69  26   1 100]</span></span><br></pre></td></tr></table></figure><h2 id="One-hot-encoding">One-hot encoding</h2><p>One-hot编码是一种将离散变量表示为二进制向量的技术。它允许我们以一种模型可以理解的方式来表示数据，并且不受token的实际值的影响。</p><p>举个例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设我们有个只含5个字符的词表：</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;a&quot;</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="string">&quot;e&quot;</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">&quot;i&quot;</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="string">&quot;o&quot;</span>: <span class="number">3</span>,</span><br><span class="line">    <span class="string">&quot;u&quot;</span>: <span class="number">4</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 那么文本 aou 就会表示成一个二维矩阵：</span></span><br><span class="line"><span class="comment"># 列对应着词表，而每一行表示单个token的二进制向量（只在词表对应位置置为1，其他位置为0）</span></span><br><span class="line">[[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]]</span><br></pre></td></tr></table></figure><p>我们手动实现一下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">to_categorical</span>(<span class="params">seq, num_classes</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;One-hot encode a sequence of tokens.&quot;&quot;&quot;</span></span><br><span class="line">    one_hot = np.zeros((<span class="built_in">len</span>(seq), num_classes))</span><br><span class="line">    <span class="keyword">for</span> i, item <span class="keyword">in</span> <span class="built_in">enumerate</span>(seq):</span><br><span class="line">        one_hot[i, item] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> one_hot</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># One-hot encoding</span></span><br><span class="line"><span class="built_in">print</span> (X_train[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span> (<span class="built_in">len</span>(X_train[<span class="number">0</span>]))</span><br><span class="line">cat = to_categorical(seq=X_train[<span class="number">0</span>], num_classes=<span class="built_in">len</span>(tokenizer))</span><br><span class="line"><span class="built_in">print</span> (cat)</span><br><span class="line"><span class="built_in">print</span> (cat.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># [ 31  32  69  26   1 100]</span></span><br><span class="line"><span class="comment"># 6</span></span><br><span class="line"><span class="comment"># [[0. 0. 0. ... 0. 0. 0.]</span></span><br><span class="line"><span class="comment">#  [0. 0. 0. ... 0. 0. 0.]</span></span><br><span class="line"><span class="comment">#  [0. 0. 0. ... 0. 0. 0.]</span></span><br><span class="line"><span class="comment">#  [0. 0. 0. ... 0. 0. 0.]</span></span><br><span class="line"><span class="comment">#  [0. 1. 0. ... 0. 0. 0.]</span></span><br><span class="line"><span class="comment">#  [0. 0. 0. ... 0. 0. 0.]]</span></span><br><span class="line"><span class="comment"># (6, 500)</span></span><br></pre></td></tr></table></figure><p>接下来需要将我们的数据进行one-hot编码处理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Convert tokens to one-hot</span></span><br><span class="line">vocab_size = <span class="built_in">len</span>(tokenizer)</span><br><span class="line">X_train = [to_categorical(seq, num_classes=vocab_size) <span class="keyword">for</span> seq <span class="keyword">in</span> X_train]</span><br><span class="line">X_val = [to_categorical(seq, num_classes=vocab_size) <span class="keyword">for</span> seq <span class="keyword">in</span> X_val]</span><br><span class="line">X_test = [to_categorical(seq, num_classes=vocab_size) <span class="keyword">for</span> seq <span class="keyword">in</span> X_test]</span><br></pre></td></tr></table></figure><h2 id="Padding">Padding</h2><p>由于我们的数据是不定长的新闻标题，而模型能够处理的是相同形状的数据，所以引入padding来预处理数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pad_sequences</span>(<span class="params">sequences, max_seq_len=<span class="number">0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Pad sequences to max length in sequence.&quot;&quot;&quot;</span></span><br><span class="line">    max_seq_len = <span class="built_in">max</span>(max_seq_len, <span class="built_in">max</span>(<span class="built_in">len</span>(sequence) <span class="keyword">for</span> sequence <span class="keyword">in</span> sequences))</span><br><span class="line">    num_classes = sequences[<span class="number">0</span>].shape[-<span class="number">1</span>]</span><br><span class="line">    padded_sequences = np.zeros((<span class="built_in">len</span>(sequences), max_seq_len, num_classes))</span><br><span class="line">    <span class="keyword">for</span> i, sequence <span class="keyword">in</span> <span class="built_in">enumerate</span>(sequences):</span><br><span class="line">        padded_sequences[i][:<span class="built_in">len</span>(sequence)] = sequence</span><br><span class="line">    <span class="keyword">return</span> padded_sequences</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3D sequences</span></span><br><span class="line"><span class="built_in">print</span> (X_train[<span class="number">0</span>].shape, X_train[<span class="number">1</span>].shape, X_train[<span class="number">2</span>].shape)</span><br><span class="line">padded = pad_sequences(X_train[<span class="number">0</span>:<span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span> (padded.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># (6, 500) (8, 500) (6, 500)</span></span><br><span class="line"><span class="comment"># (3, 8, 500)</span></span><br></pre></td></tr></table></figure><h2 id="Dataset">Dataset</h2><p>一如上篇文章里介绍的，我们需要把数据放在 Dataset 中，并使用 DataLoader 来有效地创建用于训练和验证的批次。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line">FILTER_SIZE = <span class="number">1</span> <span class="comment"># unigram</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Dataset</span>(torch.utils.data.Dataset):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, X, y, max_filter_size</span>):</span><br><span class="line">        self.X = X</span><br><span class="line">        self.y = y</span><br><span class="line">        self.max_filter_size = max_filter_size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;&lt;Dataset(N=<span class="subst">&#123;<span class="built_in">len</span>(self)&#125;</span>)&gt;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        X = self.X[index]</span><br><span class="line">        y = self.y[index]</span><br><span class="line">        <span class="keyword">return</span> [X, y]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">self, batch</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Processing on a batch.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Get inputs</span></span><br><span class="line">        batch = np.array(batch)</span><br><span class="line">        X = batch[:, <span class="number">0</span>]</span><br><span class="line">        y = batch[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Pad sequences</span></span><br><span class="line">        X = pad_sequences(X, max_seq_len=self.max_filter_size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Cast</span></span><br><span class="line">        X = torch.FloatTensor(X.astype(np.int32))</span><br><span class="line">        y = torch.LongTensor(y.astype(np.int32))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> X, y</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_dataloader</span>(<span class="params">self, batch_size, shuffle=<span class="literal">False</span>, drop_last=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="keyword">return</span> torch.utils.data.DataLoader(</span><br><span class="line">            dataset=self, batch_size=batch_size, collate_fn=self.collate_fn,</span><br><span class="line">            shuffle=shuffle, drop_last=drop_last, pin_memory=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create datasets for embedding</span></span><br><span class="line">train_dataset = Dataset(X=X_train, y=y_train, max_filter_size=FILTER_SIZE)</span><br><span class="line">val_dataset = Dataset(X=X_val, y=y_val, max_filter_size=FILTER_SIZE)</span><br><span class="line">test_dataset = Dataset(X=X_test, y=y_test, max_filter_size=FILTER_SIZE)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;Datasets:\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  Train dataset:<span class="subst">&#123;train_dataset.__str__()&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  Val dataset: <span class="subst">&#123;val_dataset.__str__()&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  Test dataset: <span class="subst">&#123;test_dataset.__str__()&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">&quot;Sample point:\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  X: <span class="subst">&#123;test_dataset[<span class="number">0</span>][<span class="number">0</span>]&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  y: <span class="subst">&#123;test_dataset[<span class="number">0</span>][<span class="number">1</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Datasets:</span></span><br><span class="line"><span class="comment">#   Train dataset:&lt;Dataset(N=84000)&gt;</span></span><br><span class="line"><span class="comment">#   Val dataset: &lt;Dataset(N=18000)&gt;</span></span><br><span class="line"><span class="comment">#   Test dataset: &lt;Dataset(N=18000)&gt;</span></span><br><span class="line"><span class="comment"># Sample point:</span></span><br><span class="line"><span class="comment">#   X: [[0. 1. 0. ... 0. 0. 0.]</span></span><br><span class="line"><span class="comment">#  [0. 1. 0. ... 0. 0. 0.]</span></span><br><span class="line"><span class="comment">#  [0. 0. 0. ... 0. 0. 0.]]</span></span><br><span class="line"><span class="comment">#   y: 1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create dataloaders</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">train_dataloader = train_dataset.create_dataloader(batch_size=batch_size)</span><br><span class="line">val_dataloader = val_dataset.create_dataloader(batch_size=batch_size)</span><br><span class="line">test_dataloader = test_dataset.create_dataloader(batch_size=batch_size)</span><br><span class="line">batch_X, batch_y = <span class="built_in">next</span>(<span class="built_in">iter</span>(test_dataloader))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;Sample batch:\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  X: <span class="subst">&#123;<span class="built_in">list</span>(batch_X.size())&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  y: <span class="subst">&#123;<span class="built_in">list</span>(batch_y.size())&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">&quot;Sample point:\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  X: <span class="subst">&#123;batch_X[<span class="number">0</span>]&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  y: <span class="subst">&#123;batch_y[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Sample batch:</span></span><br><span class="line"><span class="comment">#   X: [64, 15, 500]</span></span><br><span class="line"><span class="comment">#   y: [64]</span></span><br><span class="line"><span class="comment"># Sample point:</span></span><br><span class="line"><span class="comment">#   X: tensor([[0., 1., 0.,  ..., 0., 0., 0.],</span></span><br><span class="line"><span class="comment">#         [0., 1., 0.,  ..., 0., 0., 0.],</span></span><br><span class="line"><span class="comment">#         [0., 0., 0.,  ..., 0., 0., 0.],</span></span><br><span class="line"><span class="comment">#         ...,</span></span><br><span class="line"><span class="comment">#         [0., 0., 0.,  ..., 0., 0., 0.],</span></span><br><span class="line"><span class="comment">#         [0., 0., 0.,  ..., 0., 0., 0.],</span></span><br><span class="line"><span class="comment">#         [0., 0., 0.,  ..., 0., 0., 0.]])</span></span><br><span class="line"><span class="comment">#   y: 1</span></span><br><span class="line"><span class="comment"># </span></span><br></pre></td></tr></table></figure><h2 id="CNN">CNN</h2><p>接下来呢要进入本篇的重点，CNN了。</p><h3 id="Inputs">Inputs</h3><p>下面这个简单的示例里，我们随机给出了N个样本，每个样本有8个token，而我们的词表大小是10个。</p><p>也就意味着，我们inputs的形状是 (N, 8, 10)</p><p>但需要注意的是，当我使用PyTorch处理CNN时，通道数需要在第二个维度，也就意味着，在这个例子里，我们的inputs的形状得是 (N, 10, 8)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Assume all our inputs are padded to have the same num of tokens.</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">max_seq_len = <span class="number">8</span>  <span class="comment"># tokens per input</span></span><br><span class="line">vocab_size = <span class="number">10</span>  <span class="comment"># one-hot size</span></span><br><span class="line">x = torch.randn(batch_size, max_seq_len, vocab_size)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;X: <span class="subst">&#123;x.shape&#125;</span>&quot;</span>)</span><br><span class="line">x = x.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;X: <span class="subst">&#123;x.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># X: torch.Size([64, 8, 10])</span></span><br><span class="line"><span class="comment"># X: torch.Size([64, 10, 8])</span></span><br></pre></td></tr></table></figure><p><img src="//s3.mindex.xyz/tmp/fea49de2fb514aafde1b3545c5163058.png" alt=""></p><h3 id="Filters">Filters</h3><p>在下面的动画中，我们将卷积核和输入简化成2D，以便于可视化，而且实际上值并不总是是0或1，而是任意的浮点数。</p><p><img src="//s3.mindex.xyz/tmp/1a58a0c1e58cd3f543995ecee0eb71d4.gif" alt=""></p><p>现在回到我们的示例数据，单个样本的形状是(8, 10) [max_seq_len, vocab_size]，然后我们考虑用50个形状是(1, 3)的一维卷积来提取数据的特征，由于我们的数据的通道数是10 （num_channels = vocab_size = one_hot_size = 10）, 这边意味着这个卷积核的形状便是 (3, 10, 50) [kernel_size, vocab_size, num_filters]</p><p><img src="//s3.mindex.xyz/tmp/18c83d441855deaf7671fea9f9f26bdc.png" alt=""></p><p>这里有两个关键的概念，步长(stride) 和 填充(padding). 详见下图</p><p><img src="//s3.mindex.xyz/tmp/49dc51e7b89f5215577c01e74a17ce73.png" alt=""></p><p>这里采用一维卷积<a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d" title="Conv1d">Conv1D</a>来处理示例数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Convolutional filters (VALID padding)</span></span><br><span class="line">num_filters = <span class="number">50</span> <span class="comment"># num filters</span></span><br><span class="line">filter_size = <span class="number">3</span></span><br><span class="line">stride = <span class="number">1</span></span><br><span class="line">padding = <span class="number">0</span>  <span class="comment"># valid padding (no padding)</span></span><br><span class="line">conv1 = nn.Conv1d(in_channels=vocab_size, out_channels=num_filters,</span><br><span class="line">                  kernel_size=filter_size, stride=stride,</span><br><span class="line">                  padding=padding, padding_mode=<span class="string">&quot;zeros&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;conv: <span class="subst">&#123;conv1.weight.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># conv: torch.Size([50, 10, 3])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Forward pass</span></span><br><span class="line">z = conv1(x)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;z: <span class="subst">&#123;z.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># z: torch.Size([64, 50, 6])</span></span><br></pre></td></tr></table></figure><p><img src="//s3.mindex.xyz/tmp/0fcb44386fcdfdd5c7e56e79be18515a.png" alt=""></p><p>如你所见，我们输入数据max_seq_len=8，而经过卷积后的output的长度却是6。如果需要保证长度一致，那么就需要引入padding了。<br>$$<br>\begin{split}<br>W = \frac{W - F + 2P}{S} + 1 \\<br>P = \frac{S(W - 1) - W + F}{2}<br>\end{split}<br>$$</p><p>如果P不是一个整数，考虑向上取整(math.ceil)在右侧填充。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Convolutional filters (SAME padding)</span></span><br><span class="line">num_filters = <span class="number">50</span> <span class="comment"># num filters</span></span><br><span class="line">filter_size = <span class="number">3</span></span><br><span class="line">stride = <span class="number">1</span></span><br><span class="line">padding = <span class="number">0</span>  <span class="comment"># valid padding (no padding)</span></span><br><span class="line">conv = nn.Conv1d(in_channels=vocab_size, out_channels=num_filters,</span><br><span class="line">                 kernel_size=filter_size, stride=stride,</span><br><span class="line">                 padding=padding, padding_mode=<span class="string">&quot;zeros&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;conv: <span class="subst">&#123;conv.weight.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># conv: torch.Size([50, 10, 3])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># `SAME` padding</span></span><br><span class="line">padding_left = <span class="built_in">int</span>((conv.stride[<span class="number">0</span>]*(max_seq_len-<span class="number">1</span>) - max_seq_len + filter_size) / <span class="number">2</span>)</span><br><span class="line">padding_right =<span class="built_in">int</span>(math.ceil((conv.stride[<span class="number">0</span>]*(max_seq_len-<span class="number">1</span>) - max_seq_len + filter_size) / <span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;padding: <span class="subst">&#123;(padding_left, padding_right)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># padding: (1, 1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Forward pass</span></span><br><span class="line">z = conv(F.pad(x, (padding_left, padding_right)))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;z: <span class="subst">&#123;z.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># z: torch.Size([64, 50, 8])</span></span><br></pre></td></tr></table></figure><p>未来我们会探索更高维度的卷积层。包括使用Conv2D来处理3D数据（图像、字符级别文本等），使用Conv3D来处理4D数据（视频、时间序列数据等）</p><h3 id="Pooling">Pooling</h3><p>池化是一种用于简化下游计算的方法，通过将高维特征图总结为较低维特征图来减少冗余信息。在卷积滤波器对输入进行处理后产生的特征映射中，由于卷积和重叠的性质，会存在大量的冗余信息。池化操作可以采用最大值或平均值等方式。下面是一个池化的示例：假设来自卷积层的输出是4x4的特征图，我们使用2x2的最大池化过滤器进行处理。</p><p><img src="//s3.mindex.xyz/tmp/16910ad2e084e2b567c1cfadffcabab4.png" alt=""></p><p>在这个例子里，我们使用<a href="https://pytorch.org/docs/stable/generated/torch.nn.MaxPool1d.html#torch.nn.MaxPool1d" title="MaxPool1d">MaxPool1D</a>取一个max值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Max pooling</span></span><br><span class="line">pool_output = F.max_pool1d(z, z.size(<span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;Size: <span class="subst">&#123;pool_output.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Size: torch.Size([64, 50, 1])</span></span><br></pre></td></tr></table></figure><h3 id="Batch-normalization">Batch normalization</h3><p>在构建模型前，需要讨论的最后一个主题便是<a href="https://arxiv.org/abs/1502.03167" title="batch normalization">batch normalization</a>.  它是一种对来自前一层激活的标准化操作，使其均值为0，标准差为1。</p><p>在以前的笔记本中，我们对输入进行标准化，以便模型能够更快地进行优化，并提高学习率。这里采用相同的概念，但我们在重复的前向传递过程中保持标准化的值，以进一步帮助优化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Batch normalization</span></span><br><span class="line">batch_norm = nn.BatchNorm1d(num_features=num_filters)</span><br><span class="line">z = batch_norm(conv(x)) <span class="comment"># applied to activations (after conv layer &amp; before pooling)</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;z: <span class="subst">&#123;z.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># z: torch.Size([64, 50, 6])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Mean and std before batchnorm</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;mean: <span class="subst">&#123;torch.mean(conv(x)):<span class="number">.2</span>f&#125;</span>, std: <span class="subst">&#123;torch.std(conv(x)):<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># mean: -0.00, std: 0.59</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Mean and std after batchnorm</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;mean: <span class="subst">&#123;torch.mean(z):<span class="number">.2</span>f&#125;</span>, std: <span class="subst">&#123;torch.std(z):<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># mean: -0.00, std: 1.00</span></span><br></pre></td></tr></table></figure><h2 id="Modling">Modling</h2><h3 id="Model">Model</h3><p>可视化一下模型的前向传播.</p><ul><li>首先对输入tokenizer化 (batch_size, max_seq_len)</li><li>然后，one-hot编码 (batch_size, max_seq_len, vocab_size)</li><li>接下来，使用filters（filter_size, vocab_size, num_filter)进行卷积，然后批归一化。这里我们的filters相当于一个n-gram检测器。</li><li>紧跟着，应用max polling，从特征图中提取最相关信息</li><li>再接一个含dropout的全连接层</li><li>最后再一个softmax全连接层以输出最终的类别概率</li></ul><p><img src="//s3.mindex.xyz/tmp/3984d8e8ac31581c8b9525fd221e275c.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">NUM_FILTERS = <span class="number">50</span></span><br><span class="line">HIDDEN_DIM = <span class="number">100</span></span><br><span class="line">DROPOUT_P = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, num_filters, filter_size,</span></span><br><span class="line"><span class="params">                 hidden_dim, dropout_p, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(CNN, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># COnvolutional filters</span></span><br><span class="line">        self.filter_size = filter_size</span><br><span class="line">        self.conv = nn.Conv1d(</span><br><span class="line">            in_channels=vocab_size, out_channels=num_filters,</span><br><span class="line">            kernel_size=filter_size, stride=<span class="number">1</span>, padding=<span class="number">0</span>, padding_mode=<span class="string">&#x27;zeros&#x27;</span>)</span><br><span class="line">        self.batch_norm = nn.BatchNorm1d(num_features=num_filters)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># FC layers</span></span><br><span class="line">        self.fc1 = nn.Linear(num_filters, hidden_dim)</span><br><span class="line">        self.dropout = nn.Dropout(dropout_p)</span><br><span class="line">        self.fc2 = nn.Linear(hidden_dim, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs, channel_first=<span class="literal">False</span>,</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Rearrange input so num_channels is in dim 1 (N, C, L)</span></span><br><span class="line">        x_in, = inputs</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> channel_first:</span><br><span class="line">            x_in = x_in.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Padding for `SAME` padding</span></span><br><span class="line">        max_seq_len = x_in.shape[<span class="number">2</span>]</span><br><span class="line">        padding_left = <span class="built_in">int</span>((self.conv.stride[<span class="number">0</span>]*(max_seq_len-<span class="number">1</span>) - max_seq_len + self.filter_size)/<span class="number">2</span>)</span><br><span class="line">        padding_right = <span class="built_in">int</span>(math.ceil((self.conv.stride[<span class="number">0</span>]*(max_seq_len-<span class="number">1</span>) - max_seq_len + self.filter_size)/<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Conv outputs</span></span><br><span class="line">        z = self.conv(F.pad(x_in, (padding_left, padding_right)))</span><br><span class="line">        z = F.max_pool1d(z, z.size(<span class="number">2</span>)).squeeze(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># FC layer</span></span><br><span class="line">        z = self.fc1(z)</span><br><span class="line">        z = self.dropout(z)</span><br><span class="line">        z = self.fc2(z)</span><br><span class="line">        <span class="keyword">return</span> z</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize model</span></span><br><span class="line">model = CNN(vocab_size=VOCAB_SIZE, num_filters=NUM_FILTERS, filter_size=FILTER_SIZE,</span><br><span class="line">            hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)</span><br><span class="line">model = model.to(device)</span><br><span class="line"><span class="built_in">print</span> (model.named_parameters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &lt;bound method Module.named_parameters of CNN(</span></span><br><span class="line"><span class="comment">#   (conv): Conv1d(500, 50, kernel_size=(1,), stride=(1,))</span></span><br><span class="line"><span class="comment">#   (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span></span><br><span class="line"><span class="comment">#   (fc1): Linear(in_features=50, out_features=100, bias=True)</span></span><br><span class="line"><span class="comment">#   (dropout): Dropout(p=0.1, inplace=False)</span></span><br><span class="line"><span class="comment">#   (fc2): Linear(in_features=100, out_features=4, bias=True)</span></span><br><span class="line"><span class="comment"># )&gt;</span></span><br></pre></td></tr></table></figure><h3 id="Training">Training</h3><p>接下来，利用到<a href="http://neo1989.net/Way2AI/Way2AI-utilities/" title="PyTorch实现神经网络的基本套路">《PyTorch实现神经网络的基本套路》</a> 里介绍到Trainer类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> Adam</span><br><span class="line"></span><br><span class="line">LEARNING_RATE = <span class="number">1e-3</span></span><br><span class="line">PATIENCE = <span class="number">5</span></span><br><span class="line">NUM_EPOCHS = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Trainer</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model, device, loss_fn=<span class="literal">None</span>, optimizer=<span class="literal">None</span>, scheduler=<span class="literal">None</span></span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Set params</span></span><br><span class="line">        self.model = model</span><br><span class="line">        self.device = device</span><br><span class="line">        self.loss_fn = loss_fn</span><br><span class="line">        self.optimizer = optimizer</span><br><span class="line">        self.scheduler = scheduler</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">self, dataloader</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Train step.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Set model to train mode</span></span><br><span class="line">        self.model.train()</span><br><span class="line">        loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Iterate over train batches</span></span><br><span class="line">        <span class="keyword">for</span> i, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Step</span></span><br><span class="line">            batch = [item.to(self.device) <span class="keyword">for</span> item <span class="keyword">in</span> batch]  <span class="comment"># Set device</span></span><br><span class="line">            inputs, targets = batch[:-<span class="number">1</span>], batch[-<span class="number">1</span>]</span><br><span class="line">            self.optimizer.zero_grad()  <span class="comment"># Reset gradients</span></span><br><span class="line">            z = self.model(inputs)  <span class="comment"># Forward pass</span></span><br><span class="line">            J = self.loss_fn(z, targets)  <span class="comment"># Define loss</span></span><br><span class="line">            J.backward()  <span class="comment"># Backward pass</span></span><br><span class="line">            self.optimizer.step()  <span class="comment"># Update weights</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Cumulative Metrics</span></span><br><span class="line">            loss += (J.detach().item() - loss) / (i + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">eval_step</span>(<span class="params">self, dataloader</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Validation or test step.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Set model to eval mode</span></span><br><span class="line">        self.model.<span class="built_in">eval</span>()</span><br><span class="line">        loss = <span class="number">0.0</span></span><br><span class="line">        y_trues, y_probs = [], []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Iterate over val batches</span></span><br><span class="line">        <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">            <span class="keyword">for</span> i, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Step</span></span><br><span class="line">                batch = [item.to(self.device) <span class="keyword">for</span> item <span class="keyword">in</span> batch]  <span class="comment"># Set device</span></span><br><span class="line">                inputs, y_true = batch[:-<span class="number">1</span>], batch[-<span class="number">1</span>]</span><br><span class="line">                z = self.model(inputs)  <span class="comment"># Forward pass</span></span><br><span class="line">                J = self.loss_fn(z, y_true).item()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Cumulative Metrics</span></span><br><span class="line">                loss += (J - loss) / (i + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Store outputs</span></span><br><span class="line">                y_prob = F.softmax(z).cpu().numpy()</span><br><span class="line">                y_probs.extend(y_prob)</span><br><span class="line">                y_trues.extend(y_true.cpu().numpy())</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> loss, np.vstack(y_trues), np.vstack(y_probs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict_step</span>(<span class="params">self, dataloader</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Prediction step.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Set model to eval mode</span></span><br><span class="line">        self.model.<span class="built_in">eval</span>()</span><br><span class="line">        y_probs = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Iterate over val batches</span></span><br><span class="line">        <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">            <span class="keyword">for</span> i, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Forward pass w/ inputs</span></span><br><span class="line">                inputs, targets = batch[:-<span class="number">1</span>], batch[-<span class="number">1</span>]</span><br><span class="line">                z = self.model(inputs)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Store outputs</span></span><br><span class="line">                y_prob = F.softmax(z).cpu().numpy()</span><br><span class="line">                y_probs.extend(y_prob)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> np.vstack(y_probs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, num_epochs, patience, train_dataloader, val_dataloader</span>):</span><br><span class="line">        best_val_loss = np.inf</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">            <span class="comment"># Steps</span></span><br><span class="line">            train_loss = self.train_step(dataloader=train_dataloader)</span><br><span class="line">            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)</span><br><span class="line">            self.scheduler.step(val_loss)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Early stopping</span></span><br><span class="line">            <span class="keyword">if</span> val_loss &lt; best_val_loss:</span><br><span class="line">                best_val_loss = val_loss</span><br><span class="line">                best_model = self.model</span><br><span class="line">                _patience = patience  <span class="comment"># reset _patience</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                _patience -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> _patience:  <span class="comment"># 0</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Stopping early!&quot;</span>)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Logging</span></span><br><span class="line">            <span class="built_in">print</span>(</span><br><span class="line">                <span class="string">f&quot;Epoch: <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span> | &quot;</span></span><br><span class="line">                <span class="string">f&quot;train_loss: <span class="subst">&#123;train_loss:<span class="number">.5</span>f&#125;</span>, &quot;</span></span><br><span class="line">                <span class="string">f&quot;val_loss: <span class="subst">&#123;val_loss:<span class="number">.5</span>f&#125;</span>, &quot;</span></span><br><span class="line">                <span class="string">f&quot;lr: <span class="subst">&#123;self.optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>]:<span class="number">.2</span>E&#125;</span>, &quot;</span></span><br><span class="line">                <span class="string">f&quot;_patience: <span class="subst">&#123;_patience&#125;</span>&quot;</span></span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">return</span> best_model</span><br></pre></td></tr></table></figure><p>定义必要的组件，然后开始训练</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Defince Loss</span></span><br><span class="line">class_weights_tensor = torch.Tensor(<span class="built_in">list</span>(class_weights.values())).to(device)</span><br><span class="line">loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define optimizer &amp; scheduler</span></span><br><span class="line">optimizer = Adam(model.parameters(), lr=LEARNING_RATE)</span><br><span class="line">scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(</span><br><span class="line">    optimizer, mode=<span class="string">&quot;min&quot;</span>, factor=<span class="number">0.1</span>, patience=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train module</span></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model, device=device, loss_fn=loss_fn,</span><br><span class="line">    optimizer=optimizer, scheduler=scheduler)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train</span></span><br><span class="line">best_model = trainer.train(</span><br><span class="line">    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Epoch: 1 | train_loss: 0.86713, val_loss: 0.79795, lr: 1.00E-03, _patience: 5</span></span><br><span class="line"><span class="comment"># Epoch: 2 | train_loss: 0.77799, val_loss: 0.79238, lr: 1.00E-03, _patience: 5</span></span><br><span class="line"><span class="comment"># Epoch: 3 | train_loss: 0.77053, val_loss: 0.78976, lr: 1.00E-03, _patience: 5</span></span><br><span class="line"><span class="comment"># Epoch: 4 | train_loss: 0.76625, val_loss: 0.78882, lr: 1.00E-03, _patience: 5</span></span><br><span class="line"><span class="comment"># Epoch: 5 | train_loss: 0.76305, val_loss: 0.78799, lr: 1.00E-03, _patience: 5</span></span><br><span class="line"><span class="comment"># Epoch: 6 | train_loss: 0.76027, val_loss: 0.78786, lr: 1.00E-03, _patience: 5</span></span><br><span class="line"><span class="comment"># Epoch: 7 | train_loss: 0.75813, val_loss: 0.78810, lr: 1.00E-03, _patience: 4</span></span><br><span class="line"><span class="comment"># Epoch: 8 | train_loss: 0.75588, val_loss: 0.78725, lr: 1.00E-03, _patience: 5</span></span><br><span class="line"><span class="comment"># Epoch: 9 | train_loss: 0.75429, val_loss: 0.78740, lr: 1.00E-03, _patience: 4</span></span><br><span class="line"><span class="comment"># Epoch: 10 | train_loss: 0.75270, val_loss: 0.78747, lr: 1.00E-03, _patience: 3</span></span><br></pre></td></tr></table></figure><h3 id="Evaluaton">Evaluaton</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_fscore_support</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_metrics</span>(<span class="params">y_true, y_pred, classes</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Per-class performance metrics.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Performance</span></span><br><span class="line">    performance = &#123;<span class="string">&quot;overall&quot;</span>: &#123;&#125;, <span class="string">&quot;class&quot;</span>: &#123;&#125;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Overall performance</span></span><br><span class="line">    metrics = precision_recall_fscore_support(y_true, y_pred, average=<span class="string">&quot;weighted&quot;</span>)</span><br><span class="line">    performance[<span class="string">&quot;overall&quot;</span>][<span class="string">&quot;precision&quot;</span>] = metrics[<span class="number">0</span>]</span><br><span class="line">    performance[<span class="string">&quot;overall&quot;</span>][<span class="string">&quot;recall&quot;</span>] = metrics[<span class="number">1</span>]</span><br><span class="line">    performance[<span class="string">&quot;overall&quot;</span>][<span class="string">&quot;f1&quot;</span>] = metrics[<span class="number">2</span>]</span><br><span class="line">    performance[<span class="string">&quot;overall&quot;</span>][<span class="string">&quot;num_samples&quot;</span>] = np.float64(<span class="built_in">len</span>(y_true))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Per-class performance</span></span><br><span class="line">    metrics = precision_recall_fscore_support(y_true, y_pred, average=<span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(classes)):</span><br><span class="line">        performance[<span class="string">&quot;class&quot;</span>][classes[i]] = &#123;</span><br><span class="line">            <span class="string">&quot;precision&quot;</span>: metrics[<span class="number">0</span>][i],</span><br><span class="line">            <span class="string">&quot;recall&quot;</span>: metrics[<span class="number">1</span>][i],</span><br><span class="line">            <span class="string">&quot;f1&quot;</span>: metrics[<span class="number">2</span>][i],</span><br><span class="line">            <span class="string">&quot;num_samples&quot;</span>: np.float64(metrics[<span class="number">3</span>][i]),</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> performance</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get predictions</span></span><br><span class="line">test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)</span><br><span class="line">y_pred = np.argmax(y_prob, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Determine performance</span></span><br><span class="line">performance = get_metrics(</span><br><span class="line">    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)</span><br><span class="line"><span class="built_in">print</span> (json.dumps(performance[<span class="string">&quot;overall&quot;</span>], indent=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &#123;</span></span><br><span class="line"><span class="comment">#   &quot;precision&quot;: 0.7074944756886696,</span></span><br><span class="line"><span class="comment">#   &quot;recall&quot;: 0.6868333333333333,</span></span><br><span class="line"><span class="comment">#   &quot;f1&quot;: 0.6866617275444412,</span></span><br><span class="line"><span class="comment">#   &quot;num_samples&quot;: 18000.0</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br></pre></td></tr></table></figure><p>保存一些必要的模型数据，以供后续能够完整的加载和使用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Save artifacts</span></span><br><span class="line"><span class="built_in">dir</span> = Path(<span class="string">&quot;cnn&quot;</span>)</span><br><span class="line"><span class="built_in">dir</span>.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">label_encoder.save(fp=Path(<span class="built_in">dir</span>, <span class="string">&quot;label_encoder.json&quot;</span>))</span><br><span class="line">tokenizer.save(fp=Path(<span class="built_in">dir</span>, <span class="string">&#x27;tokenizer.json&#x27;</span>))</span><br><span class="line">torch.save(best_model.state_dict(), Path(<span class="built_in">dir</span>, <span class="string">&quot;model.pt&quot;</span>))</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(Path(<span class="built_in">dir</span>, <span class="string">&#x27;performance.json&#x27;</span>), <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    json.dump(performance, indent=<span class="number">2</span>, sort_keys=<span class="literal">False</span>, fp=fp)</span><br></pre></td></tr></table></figure><h3 id="Inference">Inference</h3><p>接下来看看如何利用模型进行新的推理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load artifacts</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">label_encoder = LabelEncoder.load(fp=Path(<span class="built_in">dir</span>, <span class="string">&quot;label_encoder.json&quot;</span>))</span><br><span class="line">tokenizer = Tokenizer.load(fp=Path(<span class="built_in">dir</span>, <span class="string">&#x27;tokenizer.json&#x27;</span>))</span><br><span class="line">model = CNN(</span><br><span class="line">    vocab_size=VOCAB_SIZE, num_filters=NUM_FILTERS, filter_size=FILTER_SIZE,</span><br><span class="line">    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)</span><br><span class="line">model.load_state_dict(torch.load(Path(<span class="built_in">dir</span>, <span class="string">&quot;model.pt&quot;</span>), map_location=device))</span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># CNN(</span></span><br><span class="line"><span class="comment">#   (conv): Conv1d(500, 50, kernel_size=(1,), stride=(1,))</span></span><br><span class="line"><span class="comment">#   (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span></span><br><span class="line"><span class="comment">#   (fc1): Linear(in_features=50, out_features=100, bias=True)</span></span><br><span class="line"><span class="comment">#   (dropout): Dropout(p=0.1, inplace=False)</span></span><br><span class="line"><span class="comment">#   (fc2): Linear(in_features=100, out_features=4, bias=True)</span></span><br><span class="line"><span class="comment"># )</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize trainer</span></span><br><span class="line">trainer = Trainer(model=model, device=device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Dataloader</span></span><br><span class="line">text = <span class="string">&quot;China’s economic recovery fades as services, factory activity show weakness&quot;</span></span><br><span class="line">sequences = tokenizer.texts_to_sequences([preprocess(text)])</span><br><span class="line"><span class="built_in">print</span> (tokenizer.sequences_to_texts(sequences))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># [&#x27;china economic &lt;UNK&gt; &lt;UNK&gt; services &lt;UNK&gt; &lt;UNK&gt; show &lt;UNK&gt;&#x27;]</span></span><br><span class="line"></span><br><span class="line">X = [to_categorical(seq, num_classes=<span class="built_in">len</span>(tokenizer)) <span class="keyword">for</span> seq <span class="keyword">in</span> sequences]</span><br><span class="line">y_filler = label_encoder.encode([label_encoder.classes[<span class="number">0</span>]]*<span class="built_in">len</span>(X))</span><br><span class="line">dataset = Dataset(X=X, y=y_filler, max_filter_size=FILTER_SIZE)</span><br><span class="line">dataloader = dataset.create_dataloader(batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Inference</span></span><br><span class="line">y_prob = trainer.predict_step(dataloader)</span><br><span class="line">y_pred = np.argmax(y_prob, axis=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span> (label_encoder.decode(y_pred))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># [&#x27;Business&#x27;]</span></span><br></pre></td></tr></table></figure><p>推理结果是 “China’s economic recovery fades as services, factory activity show weakness” 这篇文章属于 “Business” 这个分类，符合预期。</p><p>我们来看一下这个case的具体概率分布</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_probability_distribution</span>(<span class="params">y_prob, classes</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Create a dict of class probabilities from an array.&quot;&quot;&quot;</span></span><br><span class="line">    results = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i, class_ <span class="keyword">in</span> <span class="built_in">enumerate</span>(classes):</span><br><span class="line">        results[class_] = np.float64(y_prob[i])</span><br><span class="line">    sorted_results = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">sorted</span>(</span><br><span class="line">        results.items(), key=<span class="keyword">lambda</span> item: item[<span class="number">1</span>], reverse=<span class="literal">True</span>)&#125;</span><br><span class="line">    <span class="keyword">return</span> sorted_results</span><br><span class="line"></span><br><span class="line"><span class="comment"># Class distributions</span></span><br><span class="line">prob_dist = get_probability_distribution(y_prob=y_prob[<span class="number">0</span>], classes=label_encoder.classes)</span><br><span class="line"><span class="built_in">print</span> (json.dumps(prob_dist, indent=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &#123;</span></span><br><span class="line"><span class="comment">#   &quot;Business&quot;: 0.7551461458206177,</span></span><br><span class="line"><span class="comment">#   &quot;World&quot;: 0.23087970912456512,</span></span><br><span class="line"><span class="comment">#   &quot;Sci/Tech&quot;: 0.01362547930330038,</span></span><br><span class="line"><span class="comment">#   &quot;Sports&quot;: 0.0003486045461613685</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br></pre></td></tr></table></figure><h2 id="Ending">Ending</h2><p>本篇给出了一个使用CNN对文本进行分类的完整示例，有很多细节需要深入学习。</p><p>但无论如何，先跑起来再说，在战斗中学习战斗。</p>]]></content>
    
    <summary type="html">
    
      先上手再说。
    
    </summary>
    
    
      <category term="Way2AI" scheme="https://neo1989.net/categories/Way2AI/"/>
    
    
      <category term="Coder" scheme="https://neo1989.net/tags/Coder/"/>
    
      <category term="AI" scheme="https://neo1989.net/tags/AI/"/>
    
      <category term="PyTorch" scheme="https://neo1989.net/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>ChatGPT开放函数调用能力 · 好用到震惊！</title>
    <link href="https://neo1989.net/Notes/NOTE-openai-function-calling/"/>
    <id>https://neo1989.net/Notes/NOTE-openai-function-calling/</id>
    <published>2023-06-16T04:06:39.000Z</published>
    <updated>2023-06-16T05:41:43.132Z</updated>
    
    <content type="html"><![CDATA[<h2 id="TL-DR">TL;DR</h2><p>ChatGPT已经自带函数调用能力了，本文给了一个简单的示例。</p><h2 id="回顾">回顾</h2><p>笔者曾经在<a href="http://neo1989.net/Notes/NOTE-langchain-3/" title="LangChain | 快速释放LLMs的能力">LangChain</a>系列文章里交代利用LangChain赋予ChatGPT上网的能力。</p><p>然而OpenAI官方在<a href="https://openai.com/blog/function-calling-and-other-api-updates" title="function-calling-and-other-api-updates">June 13, 2023</a>的更新里提出了function calling的能力，可以说在这个方向上直接灭掉了LangChain。</p><p>先看一下官方有哪些更新。<br><img src="//s3.mindex.xyz/blog/Courses/68e512444d547a4c6727d27d049050f4.png" alt=""></p><ul><li>在Chat Completions API中提供了新的函数调用能力</li><li><code>gpt-4</code> 和 <code>gpt-3.5-turbo</code> 模型的小版本迭代</li><li><code>gpt-3.5-turbo</code> 扩展到了4倍（16k）的上下文的能力</li><li>SOTA embeddings 模型降价 75%</li><li><code>gpt-3.5-turbo</code> 降价25%</li><li><code>gpt-3.5-turbo-0301</code> 和 <code>gpt-4-0314</code> 的退役时间</li></ul><p>而最令人激动的，实属 <code>function calling</code></p><h2 id="一个示范">一个示范</h2><p>如下图，依然是用人话要股票信息，能够直接给出df数据（完成函数调用）。<br><img src="//s3.mindex.xyz/blog/Courses/ec1319f72a0c54c58a3d8080a9231041.png" alt=""></p><h2 id="如何实现">如何实现</h2><p>简单到令人发指。</p><p>首先，只需定义functions manifest，如下示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">functions = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;name&quot;</span>: <span class="string">&quot;get_stock_a&quot;</span>,</span><br><span class="line">        <span class="string">&quot;description&quot;</span>: <span class="string">&quot;获取指定A股股票一段时间内的量价信息&quot;</span>,</span><br><span class="line">        <span class="string">&quot;parameters&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>,</span><br><span class="line">            <span class="string">&quot;properties&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;stock_name&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;description&quot;</span>: <span class="string">&quot;具体的股票名称或代号，如贵州茅台、中国移动&quot;</span>,</span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="string">&quot;start_date&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;description&quot;</span>: <span class="string">&quot;开始日期，格式为2023-01-01&quot;</span>,</span><br><span class="line">                &#125;,</span><br><span class="line">                 <span class="string">&quot;end_date&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;description&quot;</span>: <span class="string">&quot;结束日期，格式为2023-01-01&quot;</span>,</span><br><span class="line">                &#125;,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;required&quot;</span>: [<span class="string">&quot;stock_name&quot;</span>, <span class="string">&quot;start_date&quot;</span>, <span class="string">&quot;end_date&quot;</span>],</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>当然这个是不能乱来的，需要遵循一定的规则，具体需要参考官方<a href="https://swagger.io/specification/" title="OpenAPI Specification">specification</a></p><p>然后，实现你的自定义方法，这个示例就是实现 <code>get_stock_a</code> 方法，以获取指定A股股票的量价数据。这里我不给出具体实现，有兴趣私聊。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_stock_a</span>(<span class="params">stock_name, start_date, end_date</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; 获取指定A股股票的量价数据 &quot;&quot;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;stock_name: <span class="subst">&#123;stock_name&#125;</span>, start_date: <span class="subst">&#123;start_date&#125;</span>, end_date: <span class="subst">&#123;end_date&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>接着，只需在调用Chat Completions API时候，把functions带上。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">requests.post(<span class="string">f&quot;<span class="subst">&#123;openai.api_base&#125;</span>/chat/completions&quot;</span>, headers=headers,</span><br><span class="line">    json=&#123;</span><br><span class="line">        <span class="string">&quot;model&quot;</span>: GPT_MODEL,  <span class="comment"># &#x27;gpt-3.5-turbo-0613&#x27; or &#x27;gpt-4-0613&#x27;</span></span><br><span class="line">        <span class="string">&quot;messages&quot;</span>: messages,</span><br><span class="line">        <span class="string">&quot;functions&quot;</span>: functions</span><br><span class="line">    &#125;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>最后，你会看到类似下面这样的返回，完成一点解析和调用的动作，这个事就成了。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">null</span></span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;function_call&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;get_stock_a&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;arguments&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&#123;\n  \&quot;stock_name\&quot;: \&quot;招商银行\&quot;,\n  \&quot;start_date\&quot;: \&quot;2023-05-01\&quot;,\n  \&quot;end_date\&quot;: \&quot;2023-06-01\&quot;\n&#125;&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h2 id="完整示例">完整示例</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> openai</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">GPT_MODEL = <span class="string">&quot;gpt-3.5-turbo-0613&quot;</span></span><br><span class="line"></span><br><span class="line">openai.api_key = <span class="string">&quot;&quot;</span>  <span class="comment"># 你的密钥</span></span><br><span class="line">openai.api_base = <span class="string">&quot;https://api.openai.com/v1&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">messages, functions</span>):</span><br><span class="line">    headers = &#123;<span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/json&quot;</span>, <span class="string">&quot;Authorization&quot;</span>: <span class="string">f&quot;Bearer <span class="subst">&#123;openai.api_key&#125;</span>&quot;</span>&#125;</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.post(<span class="string">f&quot;<span class="subst">&#123;openai.api_base&#125;</span>/chat/completions&quot;</span>, headers=headers,</span><br><span class="line">            json=&#123;</span><br><span class="line">                <span class="string">&quot;model&quot;</span>: GPT_MODEL,</span><br><span class="line">                <span class="string">&quot;messages&quot;</span>: messages,</span><br><span class="line">                <span class="string">&quot;functions&quot;</span>: functions</span><br><span class="line">            &#125;,</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> response.json()[<span class="string">&quot;choices&quot;</span>][<span class="number">0</span>][<span class="string">&quot;message&quot;</span>]</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Unable to generate ChatCompletion response&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Exception: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">functions = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;name&quot;</span>: <span class="string">&quot;get_stock_a&quot;</span>,</span><br><span class="line">        <span class="string">&quot;description&quot;</span>: <span class="string">&quot;获取指定A股股票一段时间内的量价信息&quot;</span>,</span><br><span class="line">        <span class="string">&quot;parameters&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>,</span><br><span class="line">            <span class="string">&quot;properties&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;stock_name&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;description&quot;</span>: <span class="string">&quot;具体的股票名称或代号，如贵州茅台、中国移动&quot;</span>,</span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="string">&quot;start_date&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;description&quot;</span>: <span class="string">&quot;开始日期，格式为2023-01-01&quot;</span>,</span><br><span class="line">                &#125;,</span><br><span class="line">                 <span class="string">&quot;end_date&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;description&quot;</span>: <span class="string">&quot;结束日期，格式为2023-01-01&quot;</span>,</span><br><span class="line">                &#125;,</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;required&quot;</span>: [<span class="string">&quot;stock_name&quot;</span>, <span class="string">&quot;start_date&quot;</span>, <span class="string">&quot;end_date&quot;</span>],</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_stock_a</span>(<span class="params">stock_name, start_date, end_date</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;stock_name: <span class="subst">&#123;stock_name&#125;</span>, start_date: <span class="subst">&#123;start_date&#125;</span>, end_date: <span class="subst">&#123;end_date&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chat_call</span>(<span class="params">message</span>):</span><br><span class="line">    messages = [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;不要对函数中应该填入的数值作出自作主张的假设。如果用户的要求不够明确，要求澄清。&quot;</span>&#125;]</span><br><span class="line">    messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: message&#125;)</span><br><span class="line">    r = call(messages, functions)</span><br><span class="line"></span><br><span class="line">    fcall = r[<span class="string">&quot;function_call&quot;</span>]</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">eval</span>(fcall[<span class="string">&quot;name&quot;</span>])(**json.loads(fcall[<span class="string">&quot;arguments&quot;</span>]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">chat_call(<span class="string">&quot;2023年5月1日到6月1日，招商银行的A股量价给我一份&quot;</span>)</span><br></pre></td></tr></table></figure><p>如果你足够幸运，你将看到这样一串文本: “stock_name: 招商银行, start_date: 2023-05-01, end_date: 2023-06-01”</p><h2 id="Ending">Ending</h2><p>不多说了，黄老板已经说过了，“跑起来掠食，或是努力奔跑免得成为掠食者的食物”。</p>]]></content>
    
    <summary type="html">
    
      Function calling capability in the Chat Completions API.
    
    </summary>
    
    
      <category term="Notes" scheme="https://neo1989.net/categories/Notes/"/>
    
    
      <category term="Coder" scheme="https://neo1989.net/tags/Coder/"/>
    
      <category term="AI" scheme="https://neo1989.net/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>Way2AI · PyTorch实现神经网络的基本套路</title>
    <link href="https://neo1989.net/Way2AI/Way2AI-utilities/"/>
    <id>https://neo1989.net/Way2AI/Way2AI-utilities/</id>
    <published>2023-06-15T05:53:07.000Z</published>
    <updated>2023-06-27T11:03:55.252Z</updated>
    
    <content type="html"><![CDATA[<h2 id="TL-DR">TL;DR</h2><p>本文简单交代了神经网络的基本套路以及部分实用组件，以简化开发过程。</p><h2 id="Set-up">Set up</h2><p>通常我们需要为重复实验设置很多seed，所以我们可以将其打包到一个函数里。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_seeds</span>(<span class="params">seed=<span class="number">1024</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Set seeds for reproducibility.&quot;&quot;&quot;</span></span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    random.seed(seed)</span><br><span class="line">    touch.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed_all(seed)  <span class="comment"># multi-GPU</span></span><br><span class="line"></span><br><span class="line">set_seeds(seed=<span class="number">1024</span>)</span><br></pre></td></tr></table></figure><h2 id="Device">Device</h2><p>当我们有大型数据集和更大的模型要训练时，我们可以通过在 GPU 上并行化张量操作来加速。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cuda = <span class="literal">True</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span>(torch.cuda.is_available() <span class="keyword">and</span> cuda) <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">torch.set_default_tensor_type(&#123;<span class="string">&quot;cuda&quot;</span>: <span class="string">&quot;torch.cuda.FloatTensor&quot;</span>, <span class="string">&quot;cpu&quot;</span>: <span class="string">&quot;torch.FloatTensor&quot;</span>&#125;.get(<span class="built_in">str</span>(device)))</span><br></pre></td></tr></table></figure><h2 id="Load-data">Load data</h2><p>这里依然使用前文引入的螺旋数据作为演示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load data</span></span><br><span class="line">url = <span class="string">&quot;http://s3.mindex.xyz/datasets/9378f64fc8dd2817e4c92be0a3bae8e7.csv&quot;</span></span><br><span class="line">df = pd.read_csv(url, header=<span class="number">0</span>) <span class="comment"># load</span></span><br><span class="line">df = df.sample(frac=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>) <span class="comment"># shuffle</span></span><br><span class="line">df.head()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data shapes</span></span><br><span class="line">X = df[[<span class="string">&quot;X1&quot;</span>, <span class="string">&quot;X2&quot;</span>]].values</span><br><span class="line">y = df[<span class="string">&quot;color&quot;</span>].values</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;X: &quot;</span>, np.shape(X))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;y: &quot;</span>, np.shape(y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># X:  (1500, 2)</span></span><br><span class="line"><span class="comment"># y:  (1500,)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Visualize data</span></span><br><span class="line">plt.title(<span class="string">&quot;Generated non-linear data&quot;</span>)</span><br><span class="line">colors = &#123;<span class="string">&quot;c1&quot;</span>: <span class="string">&quot;red&quot;</span>, <span class="string">&quot;c2&quot;</span>: <span class="string">&quot;yellow&quot;</span>, <span class="string">&quot;c3&quot;</span>: <span class="string">&quot;blue&quot;</span>&#125;</span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=[colors[_y] <span class="keyword">for</span> _y <span class="keyword">in</span> y], edgecolors=<span class="string">&quot;k&quot;</span>, s=<span class="number">25</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="//s3.mindex.xyz/blog/Courses/147e784e6ecae3fd226abce4f3905550.png" alt=""></p><h2 id="Split-data">Split data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">TRAIN_SIZE = <span class="number">0.7</span></span><br><span class="line">VAL_SIZE = <span class="number">0.15</span></span><br><span class="line">TEST_SIZE = <span class="number">0.15</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_val_test_split</span>(<span class="params">X, y, train_size</span>):</span><br><span class="line">    X_train, X_, y_train, y_ = train_test_split(X, y, train_size=TRAIN_SIZE, stratify=y)</span><br><span class="line">    X_test, X_val, y_test, y_val = train_test_split(X_, y_, train_size=<span class="number">0.5</span>, stratify=y_)</span><br><span class="line">    <span class="keyword">return</span> X_train, X_val, X_test, y_train, y_val, y_test</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create data splits</span></span><br><span class="line">X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(</span><br><span class="line">    X=X, y=y, train_size=TRAIN_SIZE)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_train: <span class="subst">&#123;X_train.shape&#125;</span>, y_train: <span class="subst">&#123;y_train.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_val: <span class="subst">&#123;X_val.shape&#125;</span>, y_val: <span class="subst">&#123;y_val.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_test: <span class="subst">&#123;X_test.shape&#125;</span>, y_test: <span class="subst">&#123;y_test.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;Sample point: <span class="subst">&#123;X_train[<span class="number">0</span>]&#125;</span> → <span class="subst">&#123;y_train[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># X_train: (1050, 2), y_train: (1050,)</span></span><br><span class="line"><span class="comment"># X_val: (225, 2), y_val: (225,)</span></span><br><span class="line"><span class="comment"># X_test: (225, 2), y_test: (225,)</span></span><br><span class="line"><span class="comment"># Sample point: [0.17003003 0.63079261] → c3</span></span><br></pre></td></tr></table></figure><h2 id="Label-encoding">Label encoding</h2><p>接下来定义一个 LabelEncoder 来将文本标签编码成唯一的索引。</p><p>这里不再使用 scikit-learn 的 LabelEncoder，因为我们希望能够以我们想要的方式保存和加载我们的实例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LabelEncoder</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Label encoder for tag labels.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, class_to_index=<span class="literal">None</span></span>):</span><br><span class="line">        self.class_to_index = class_to_index <span class="keyword">or</span> &#123;&#125;</span><br><span class="line">        self.index_to_class = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> self.class_to_index.items()&#125;</span><br><span class="line">        self.classes = <span class="built_in">list</span>(self.class_to_index.keys())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.class_to_index)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;&lt;LabelEncoder(num_classes=<span class="subst">&#123;<span class="built_in">len</span>(self)&#125;</span>&gt;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, y</span>):</span><br><span class="line">        classes = np.unique(y)</span><br><span class="line">        <span class="keyword">for</span> i, class_ <span class="keyword">in</span> <span class="built_in">enumerate</span>(classes):</span><br><span class="line">            self.class_to_index[class_] = i</span><br><span class="line">        self.index_to_class = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> self.class_to_index.items()&#125;</span><br><span class="line">        self.classes = <span class="built_in">list</span>(self.class_to_index.keys())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">self, y</span>):</span><br><span class="line">        encoded = np.zeros((<span class="built_in">len</span>(y)), dtype=<span class="built_in">int</span>)</span><br><span class="line">        <span class="keyword">for</span> i, item <span class="keyword">in</span> <span class="built_in">enumerate</span>(y):</span><br><span class="line">            encoded[i] = self.class_to_index[item]</span><br><span class="line">        <span class="keyword">return</span> encoded</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decode</span>(<span class="params">self, y</span>):</span><br><span class="line">        classes = []</span><br><span class="line">        <span class="keyword">for</span> i, item <span class="keyword">in</span> <span class="built_in">enumerate</span>(y):</span><br><span class="line">            classes.append(self.index_to_class[item])</span><br><span class="line">        <span class="keyword">return</span> classes</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save</span>(<span class="params">self, fp</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(fp, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            contents = &#123;<span class="string">&#x27;class_to_index&#x27;</span>: self.class_to_index&#125;</span><br><span class="line">            json.dump(contents, fp, indent=<span class="number">4</span>, sort_keys=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load</span>(<span class="params">cls, fp</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(fp, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            kwargs = json.load(fp=fp)</span><br><span class="line">        <span class="keyword">return</span> cls(**kwargs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Encode</span></span><br><span class="line">label_encoder = LabelEncoder()</span><br><span class="line">label_encoder.fit(y_train)</span><br><span class="line">label_encoder.class_to_index</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert labels to tokens</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;y_train[0]: <span class="subst">&#123;y_train[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line">y_train = label_encoder.encode(y_train)</span><br><span class="line">y_val = label_encoder.encode(y_val)</span><br><span class="line">y_test = label_encoder.encode(y_test)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;y_train[0]: <span class="subst">&#123;y_train[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Class weights</span></span><br><span class="line">counts = np.bincount(y_train)</span><br><span class="line">class_weights = &#123;i: <span class="number">1.0</span>/count <span class="keyword">for</span> i, count <span class="keyword">in</span> <span class="built_in">enumerate</span>(counts)&#125;</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;counts: <span class="subst">&#123;counts&#125;</span>\nweights: <span class="subst">&#123;class_weights&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># y_train[0]: c3</span></span><br><span class="line"><span class="comment"># y_train[0]: 2</span></span><br><span class="line"><span class="comment"># counts: [350 350 350]</span></span><br><span class="line"><span class="comment"># weights: &#123;0: 0.002857142857142857, 1: 0.002857142857142857, 2: 0.002857142857142857&#125;</span></span><br></pre></td></tr></table></figure><h2 id="Standardize-data">Standardize data</h2><p>我们需要标准化我们的数据（零均值和单位方差），这样特定特征的大小就不会影响模型学习其权重的方式。</p><p>我们只对输入X进行标准化，因为我们的输出y是类值。</p><p>我们将编写自己的 StandardScaler 类，以便在推理过程中轻松保存和加载它。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">StandardScaler</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, mean=<span class="literal">None</span>, std=<span class="literal">None</span></span>):</span><br><span class="line">        self.mean = np.array(mean)</span><br><span class="line">        self.std = np.array(std)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X</span>):</span><br><span class="line">        self.mean = np.mean(X_train, axis=<span class="number">0</span>)</span><br><span class="line">        self.std = np.std(X_train, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">scale</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="keyword">return</span> (X - self.mean) / self.std</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">unscale</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="keyword">return</span> (X * self.std) + self.mean</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save</span>(<span class="params">self, fp</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(fp, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            contents = &#123;<span class="string">&quot;mean&quot;</span>: self.mean.tolist(), <span class="string">&quot;std&quot;</span>: self.std.tolist()&#125;</span><br><span class="line">            json.dump(contents, fp, indent=<span class="number">4</span>, sort_keys=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load</span>(<span class="params">cls, fp</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(fp, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            kwargs = json.load(fp=fp)</span><br><span class="line">        <span class="keyword">return</span> cls(**kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Standardize the data (mean=0, std=1) using training data</span></span><br><span class="line">X_scaler = StandardScaler()</span><br><span class="line">X_scaler.fit(X_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check (means should be ~0 and std should be ~1)</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_test[0]: mean: <span class="subst">&#123;np.mean(X_test[:, <span class="number">0</span>], axis=<span class="number">0</span>):<span class="number">.1</span>f&#125;</span>, std: <span class="subst">&#123;np.std(X_test[:, <span class="number">0</span>], axis=<span class="number">0</span>):<span class="number">.1</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_test[1]: mean: <span class="subst">&#123;np.mean(X_test[:, <span class="number">1</span>], axis=<span class="number">0</span>):<span class="number">.1</span>f&#125;</span>, std: <span class="subst">&#123;np.std(X_test[:, <span class="number">1</span>], axis=<span class="number">0</span>):<span class="number">.1</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># X_test[0]: mean: 0.0, std: 1.0</span></span><br><span class="line"><span class="comment"># X_test[1]: mean: -0.0, std: 1.0</span></span><br></pre></td></tr></table></figure><h2 id="DataLoader">DataLoader</h2><p>我们将把数据放在 Dataset 中，并使用 DataLoader 来有效地创建用于训练和验证的批次。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Dataset</span>(torch.utils.data.Dataset):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, X, y</span>):</span><br><span class="line">        self.X = X</span><br><span class="line">        self.y = y</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;&lt;Dataset(N=<span class="subst">&#123;<span class="built_in">len</span>(self)&#125;</span>)&gt;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        X = self.X[index]</span><br><span class="line">        y = self.y[index]</span><br><span class="line">        <span class="keyword">return</span> [X, y]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">self, batch</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Processing on a batch.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Get inputs</span></span><br><span class="line">        batch = np.array(batch)</span><br><span class="line">        X = np.stack(batch[:, <span class="number">0</span>], axis=<span class="number">0</span>)</span><br><span class="line">        y = batch[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Cast</span></span><br><span class="line">        X = torch.FloatTensor(X.astype(np.float32))</span><br><span class="line">        y = torch.LongTensor(y.astype(np.int32))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> X, y</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_dataloader</span>(<span class="params">self, batch_size, shuffle=<span class="literal">False</span>, drop_last=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="keyword">return</span> torch.utils.data.DataLoader(</span><br><span class="line">            dataset=self, batch_size=batch_size, collate_fn=self.collate_fn,</span><br><span class="line">            shuffle=shuffle, drop_last=drop_last, pin_memory=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>事实上我们并不需要 collate_fn ，但我们可以让它透明（无副作用），因为当我想要对批处理做一些处理的时候，需要用到这个方法。(如：数据padding）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create datasets</span></span><br><span class="line">train_dataset = Dataset(X=X_train, y=y_train)</span><br><span class="line">val_dataset = Dataset(X=X_val, y=y_val)</span><br><span class="line">test_dataset = Dataset(X=X_test, y=y_test)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;Datasets:\n&quot;</span></span><br><span class="line">       <span class="string">f&quot;  Train dataset:<span class="subst">&#123;train_dataset.__str__()&#125;</span>\n&quot;</span></span><br><span class="line">       <span class="string">f&quot;  Val dataset: <span class="subst">&#123;val_dataset.__str__()&#125;</span>\n&quot;</span></span><br><span class="line">       <span class="string">f&quot;  Test dataset: <span class="subst">&#123;test_dataset.__str__()&#125;</span>\n&quot;</span></span><br><span class="line">       <span class="string">&quot;Sample point:\n&quot;</span></span><br><span class="line">       <span class="string">f&quot;  X: <span class="subst">&#123;train_dataset[<span class="number">0</span>][<span class="number">0</span>]&#125;</span>\n&quot;</span></span><br><span class="line">       <span class="string">f&quot;  y: <span class="subst">&#123;train_dataset[<span class="number">0</span>][<span class="number">1</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Datasets:</span></span><br><span class="line"><span class="comment">#   Train dataset: &lt;Dataset(N=1050)&gt;</span></span><br><span class="line"><span class="comment">#   Val dataset: &lt;Dataset(N=225)&gt;</span></span><br><span class="line"><span class="comment">#   Test dataset: &lt;Dataset(N=225)&gt;</span></span><br><span class="line"><span class="comment"># Sample point:</span></span><br><span class="line"><span class="comment">#   X: [-1.47355106 -1.67417243]</span></span><br><span class="line"><span class="comment">#   y: 0</span></span><br></pre></td></tr></table></figure><p>之前的文章中都是利用全部的数据进行梯度计算，然而更标准的做法是 <strong>mini-batch</strong> 随机梯度下降，也就是将样本分成多个只有 n(BATCH_SIZE) 个样本的 mini-batch。这就是 Dataloader 派上用场的地方。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create dataloaders</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">train_dataloader = train_dataset.create_dataloader(batch_size=batch_size)</span><br><span class="line">val_dataloader = val_dataset.create_dataloader(batch_size=batch_size)</span><br><span class="line">test_dataloader = test_dataset.create_dataloader(batch_size=batch_size)</span><br><span class="line">batch_X, batch_y = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_dataloader))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;Sample batch:\n&quot;</span></span><br><span class="line">       <span class="string">f&quot;  X: <span class="subst">&#123;<span class="built_in">list</span>(batch_X.size())&#125;</span>\n&quot;</span></span><br><span class="line">       <span class="string">f&quot;  y: <span class="subst">&#123;<span class="built_in">list</span>(batch_y.size())&#125;</span>\n&quot;</span></span><br><span class="line">       <span class="string">&quot;Sample point:\n&quot;</span></span><br><span class="line">       <span class="string">f&quot;  X: <span class="subst">&#123;batch_X[<span class="number">0</span>]&#125;</span>\n&quot;</span></span><br><span class="line">       <span class="string">f&quot;  y: <span class="subst">&#123;batch_y[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Sample batch:</span></span><br><span class="line"><span class="comment">#   X: [64, 2]</span></span><br><span class="line"><span class="comment">#   y: [64]</span></span><br><span class="line"><span class="comment"># Sample point:</span></span><br><span class="line"><span class="comment">#   X: tensor([ 0.4535, -0.3570], dtype=torch.float64)</span></span><br><span class="line"><span class="comment">#   y: 0</span></span><br></pre></td></tr></table></figure><h2 id="Model">Model</h2><p>我们需要定义一个模型，以便继续给出训练阶段的实用组件。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">INPUT_DIM = X_train.shape[<span class="number">1</span>]  <span class="comment"># 2D</span></span><br><span class="line">HIDDEN_DIM = <span class="number">100</span></span><br><span class="line">DROPOUT_P = <span class="number">.01</span></span><br><span class="line">NUM_CLASSES = <span class="built_in">len</span>(label_encoder.classes)</span><br><span class="line">NUM_EPOCHS = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim, hidden_dim, dropout_p, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(MLP, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(input_dim, hidden_dim)</span><br><span class="line">        self.dropout = nn.Dropout(dropout_p)</span><br><span class="line">        self.fc2 = nn.Linear(hidden_dim, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x_in</span>):</span><br><span class="line">        z = F.relu(self.fc1(x_in))</span><br><span class="line">        z = self.dropout(z)</span><br><span class="line">        z = self.fc2(z)</span><br><span class="line">        <span class="keyword">return</span> z</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize model</span></span><br><span class="line">model = MLP(input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM,</span><br><span class="line">            dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)</span><br><span class="line">model = model.to(device)</span><br><span class="line"><span class="built_in">print</span> (model.named_parameters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &lt;bound method Module.named_parameters of MLP(</span></span><br><span class="line"><span class="comment">#   (fc1): Linear(in_features=2, out_features=100, bias=True)</span></span><br><span class="line"><span class="comment">#   (droput): Dropout(p=0.01, inplace=False)</span></span><br><span class="line"><span class="comment">#   (fc2): Linear(in_features=100, out_features=3, bias=True)</span></span><br><span class="line"><span class="comment"># )&gt;</span></span><br></pre></td></tr></table></figure><h2 id="Trainer">Trainer</h2><p>之前的文章，我们一直在编写只使用循环来训练分割后的训练数据，然后在测试集上评估。</p><p>但实际工作中，我们会遵循下面这个过程：</p><ul><li>使用mini-batches进行训练</li><li>在验证集上评估损失，并更新超参</li><li>训练结束后，在测试集上评估模型</li></ul><p>所以我们需要创建 Trainer 类来组织这些过程。</p><p>首先，train_step 用来执行小批量数据训练</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">self, dataloader</span>):</span><br><span class="line">    self.model.train()</span><br><span class="line">    loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        batch = [item.to(self.device) <span class="keyword">for</span> item <span class="keyword">in</span> batch]</span><br><span class="line">        inputs, targets = batch[:-<span class="number">1</span>], batch[-<span class="number">1</span>]</span><br><span class="line">        self.optimizer.zero_grad()  <span class="comment"># reset gradients</span></span><br><span class="line">        z = self.model(inputs)  <span class="comment"># forward pass</span></span><br><span class="line">        J = self.loss_fn(z, targets)</span><br><span class="line">        J.backward()  <span class="comment"># backward pass</span></span><br><span class="line">        self.optimizer.step()  <span class="comment"># Update weights</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Cumulative Metrics</span></span><br><span class="line">        loss += (j.detach().item() - loss) / (i + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><p>然后 eval_step，用于验证</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">eval_step</span>(<span class="params">self, dataloader</span>):</span><br><span class="line">    self.model.<span class="built_in">eval</span>()</span><br><span class="line">    loss = <span class="number">0.0</span></span><br><span class="line">    y_trues, x_probs = [], []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.inference_model():</span><br><span class="line">        <span class="keyword">for</span> i, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">            batch = [item.to(self.device) <span class="keyword">for</span> item <span class="keyword">in</span> batch]</span><br><span class="line">            inputs, y_trye = batch[:-<span class="number">1</span>], batch[-<span class="number">1</span>]</span><br><span class="line">            z = self.model(inputs)</span><br><span class="line">            J = self.loss_fn(z, y_true).item()</span><br><span class="line"></span><br><span class="line">            loss += (J - loss) / (i + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Store outputs</span></span><br><span class="line">            y_prob = F.softmax(z).cpu().numpy()</span><br><span class="line">            y_probs.extend(y_prob)</span><br><span class="line">            y_trues.extend(y_true.cpu().numpy())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss, np.vstack(y_trues), np.vstack(y_probs)</span><br></pre></td></tr></table></figure><p>最后 predict_step, 只是用来对数据进行预测</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict_step</span>(<span class="params">self, dataloader</span>):</span><br><span class="line">    self.model.<span class="built_in">eval</span>()</span><br><span class="line">    y_prods = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.inference_model():</span><br><span class="line">        <span class="keyword">for</span> i, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line"></span><br><span class="line">            inputs, y_trye = batch[:-<span class="number">1</span>], batch[-<span class="number">1</span>]</span><br><span class="line">            z = self.model(inputs)</span><br><span class="line">            y_prob = F.softmax(z).cpu().numpy()</span><br><span class="line">            y_probs.extend(y_prob)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.vstack(y_probs)</span><br></pre></td></tr></table></figure><h2 id="LR-scheduler">LR scheduler</h2><p>我们将向优化器添加一个学习率调度器，以在训练期间调整我们的学习率。</p><p>有许多<a href="%22https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate%22" title="How to adjust learning rate">调度器</a>可供选择，但最受欢迎的是 ReduceLROnPlateau ，它在指标（例如：验证损失）停止改进的时候，减少学习率。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Initialize the LR scheduler</span></span><br><span class="line">scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=<span class="string">&quot;min&quot;</span>, factor=<span class="number">0.1</span>, patience=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(NUM_EPOCHS * <span class="number">10</span>):</span><br><span class="line">    ...</span><br><span class="line">    train_loss = trainer.train_step(dataloader=train_dataloader)</span><br><span class="line">    val_loss, _, _ = trainer.eval_step(dataloader=val_dataloader)</span><br><span class="line">    scheduler.step(val_loss)</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><h2 id="Early-stopping">Early stopping</h2><p>我们不应该拍脑袋训练足够多的epoch，而是应该有个明确的停止标准。</p><p>常见的停止标准，是模型达到一个期望的性能时，即停止训练。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Early stopping</span></span><br><span class="line"><span class="keyword">if</span> val_loss &lt; best_val_loss:</span><br><span class="line">    best_val_loss = val_loss</span><br><span class="line">    best_model = trainer.model</span><br><span class="line">    _patience = patience  <span class="comment"># reset _patience</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    _patience -= <span class="number">1</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> _patience:  <span class="comment"># 0</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Stopping early!&quot;</span>)</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Training">Training</h2><p>现在把上面这些放到一起</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">LEARNING_RATE = <span class="number">1e-2</span></span><br><span class="line">NUM_EPOCHS = <span class="number">100</span></span><br><span class="line">PATIENCE = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define Loss</span></span><br><span class="line">class_weights_tensor = torch.Tensor(<span class="built_in">list</span>(class_weights.values())).to(device)</span><br><span class="line">loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define optimizer &amp; scheduler</span></span><br><span class="line">optimizer = Adam(model.parameters(), lr=LEARNING_RATE)</span><br><span class="line">scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(</span><br><span class="line">    optimizer, mode=<span class="string">&quot;min&quot;</span>, factor=<span class="number">0.1</span>, patience=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Trainer</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model, device, loss_fn=<span class="literal">None</span>, optimizer=<span class="literal">None</span>, scheduler=<span class="literal">None</span></span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Set params</span></span><br><span class="line">        self.model = model</span><br><span class="line">        self.device = device</span><br><span class="line">        self.loss_fn = loss_fn</span><br><span class="line">        self.optimizer = optimizer</span><br><span class="line">        self.scheduler = scheduler</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">self, dataloader</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Train step.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Set model to train mode</span></span><br><span class="line">        self.model.train()</span><br><span class="line">        loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Iterate over train batches</span></span><br><span class="line">        <span class="keyword">for</span> i, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Step</span></span><br><span class="line">            batch = [item.to(self.device) <span class="keyword">for</span> item <span class="keyword">in</span> batch]  <span class="comment"># Set device</span></span><br><span class="line">            inputs, targets = batch[:-<span class="number">1</span>], batch[-<span class="number">1</span>]</span><br><span class="line">            self.optimizer.zero_grad()  <span class="comment"># Reset gradients</span></span><br><span class="line">            z = self.model(inputs)  <span class="comment"># Forward pass</span></span><br><span class="line">            J = self.loss_fn(z, targets)  <span class="comment"># Define loss</span></span><br><span class="line">            J.backward()  <span class="comment"># Backward pass</span></span><br><span class="line">            self.optimizer.step()  <span class="comment"># Update weights</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Cumulative Metrics</span></span><br><span class="line">            loss += (J.detach().item() - loss) / (i + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">eval_step</span>(<span class="params">self, dataloader</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Validation or test step.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Set model to eval mode</span></span><br><span class="line">        self.model.<span class="built_in">eval</span>()</span><br><span class="line">        loss = <span class="number">0.0</span></span><br><span class="line">        y_trues, y_probs = [], []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Iterate over val batches</span></span><br><span class="line">        <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">            <span class="keyword">for</span> i, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Step</span></span><br><span class="line">                batch = [item.to(self.device) <span class="keyword">for</span> item <span class="keyword">in</span> batch]  <span class="comment"># Set device</span></span><br><span class="line">                inputs, y_true = batch[:-<span class="number">1</span>], batch[-<span class="number">1</span>]</span><br><span class="line">                z = self.model(inputs)  <span class="comment"># Forward pass</span></span><br><span class="line">                J = self.loss_fn(z, y_true).item()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Cumulative Metrics</span></span><br><span class="line">                loss += (J - loss) / (i + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Store outputs</span></span><br><span class="line">                y_prob = F.softmax(z).cpu().numpy()</span><br><span class="line">                y_probs.extend(y_prob)</span><br><span class="line">                y_trues.extend(y_true.cpu().numpy())</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> loss, np.vstack(y_trues), np.vstack(y_probs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict_step</span>(<span class="params">self, dataloader</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Prediction step.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Set model to eval mode</span></span><br><span class="line">        self.model.<span class="built_in">eval</span>()</span><br><span class="line">        y_probs = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Iterate over val batches</span></span><br><span class="line">        <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">            <span class="keyword">for</span> i, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Forward pass w/ inputs</span></span><br><span class="line">                inputs, targets = batch[:-<span class="number">1</span>], batch[-<span class="number">1</span>]</span><br><span class="line">                z = self.model(inputs)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Store outputs</span></span><br><span class="line">                y_prob = F.softmax(z).cpu().numpy()</span><br><span class="line">                y_probs.extend(y_prob)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> np.vstack(y_probs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, num_epochs, patience, train_dataloader, val_dataloader</span>):</span><br><span class="line">        best_val_loss = np.inf</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">            <span class="comment"># Steps</span></span><br><span class="line">            train_loss = self.train_step(dataloader=train_dataloader)</span><br><span class="line">            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)</span><br><span class="line">            self.scheduler.step(val_loss)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Early stopping</span></span><br><span class="line">            <span class="keyword">if</span> val_loss &lt; best_val_loss:</span><br><span class="line">                best_val_loss = val_loss</span><br><span class="line">                best_model = self.model</span><br><span class="line">                _patience = patience  <span class="comment"># reset _patience</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                _patience -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> _patience:  <span class="comment"># 0</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Stopping early!&quot;</span>)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Logging</span></span><br><span class="line">            <span class="built_in">print</span>(</span><br><span class="line">                <span class="string">f&quot;Epoch: <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span> | &quot;</span></span><br><span class="line">                <span class="string">f&quot;train_loss: <span class="subst">&#123;train_loss:<span class="number">.5</span>f&#125;</span>, &quot;</span></span><br><span class="line">                <span class="string">f&quot;val_loss: <span class="subst">&#123;val_loss:<span class="number">.5</span>f&#125;</span>, &quot;</span></span><br><span class="line">                <span class="string">f&quot;lr: <span class="subst">&#123;self.optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>]:<span class="number">.2</span>E&#125;</span>, &quot;</span></span><br><span class="line">                <span class="string">f&quot;_patience: <span class="subst">&#123;_patience&#125;</span>&quot;</span></span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">return</span> best_model</span><br><span class="line"></span><br><span class="line"><span class="comment"># Trainer module</span></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model, device=device, loss_fn=loss_fn,</span><br><span class="line">    optimizer=optimizer, scheduler=scheduler)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train</span></span><br><span class="line">best_model = trainer.train(</span><br><span class="line">    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Epoch: 1 | train_loss: 0.87488, val_loss: 0.66353, lr: 1.00E-02, _patience: 3</span></span><br><span class="line"><span class="comment"># Epoch: 2 | train_loss: 0.66368, val_loss: 0.55748, lr: 1.00E-02, _patience: 3</span></span><br><span class="line"><span class="comment"># ...</span></span><br><span class="line"><span class="comment"># Epoch: 67 | train_loss: 0.03002, val_loss: 0.02305, lr: 1.00E-02, _patience: 3</span></span><br><span class="line"><span class="comment"># Epoch: 68 | train_loss: 0.03011, val_loss: 0.02309, lr: 1.00E-02, _patience: 2</span></span><br><span class="line"><span class="comment"># Epoch: 69 | train_loss: 0.02544, val_loss: 0.02227, lr: 1.00E-02, _patience: 3</span></span><br><span class="line"><span class="comment"># Epoch: 70 | train_loss: 0.02680, val_loss: 0.02154, lr: 1.00E-02, _patience: 3</span></span><br><span class="line"><span class="comment"># Epoch: 71 | train_loss: 0.02897, val_loss: 0.02162, lr: 1.00E-02, _patience: 2</span></span><br><span class="line"><span class="comment"># Epoch: 72 | train_loss: 0.02737, val_loss: 0.02190, lr: 1.00E-02, _patience: 1</span></span><br><span class="line"><span class="comment"># Stopping early!</span></span><br></pre></td></tr></table></figure><h2 id="Evaluation">Evaluation</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_fscore_support</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_metrics</span>(<span class="params">y_true, y_pred, classes</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Per-class performance metrics.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Performance</span></span><br><span class="line">    performance = &#123;<span class="string">&quot;overall&quot;</span>: &#123;&#125;, <span class="string">&quot;class&quot;</span>: &#123;&#125;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Overall performance</span></span><br><span class="line">    metrics = precision_recall_fscore_support(y_true, y_pred, average=<span class="string">&quot;weighted&quot;</span>)</span><br><span class="line">    performance[<span class="string">&quot;overall&quot;</span>][<span class="string">&quot;precision&quot;</span>] = metrics[<span class="number">0</span>]</span><br><span class="line">    performance[<span class="string">&quot;overall&quot;</span>][<span class="string">&quot;recall&quot;</span>] = metrics[<span class="number">1</span>]</span><br><span class="line">    performance[<span class="string">&quot;overall&quot;</span>][<span class="string">&quot;f1&quot;</span>] = metrics[<span class="number">2</span>]</span><br><span class="line">    performance[<span class="string">&quot;overall&quot;</span>][<span class="string">&quot;num_samples&quot;</span>] = np.float64(<span class="built_in">len</span>(y_true))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Per-class performance</span></span><br><span class="line">    metrics = precision_recall_fscore_support(y_true, y_pred, average=<span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(classes)):</span><br><span class="line">        performance[<span class="string">&quot;class&quot;</span>][classes[i]] = &#123;</span><br><span class="line">            <span class="string">&quot;precision&quot;</span>: metrics[<span class="number">0</span>][i],</span><br><span class="line">            <span class="string">&quot;recall&quot;</span>: metrics[<span class="number">1</span>][i],</span><br><span class="line">            <span class="string">&quot;f1&quot;</span>: metrics[<span class="number">2</span>][i],</span><br><span class="line">            <span class="string">&quot;num_samples&quot;</span>: np.float64(metrics[<span class="number">3</span>][i]),</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> performance</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get predictions</span></span><br><span class="line">test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)</span><br><span class="line">y_pred = np.argmax(y_prob, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Determine performance</span></span><br><span class="line">performance = get_metrics(</span><br><span class="line">    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)</span><br><span class="line"><span class="built_in">print</span> (json.dumps(performance[<span class="string">&quot;overall&quot;</span>], indent=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &#123;</span></span><br><span class="line"><span class="comment">#   &quot;precision&quot;: 0.9956140350877192,</span></span><br><span class="line"><span class="comment">#   &quot;recall&quot;: 0.9955555555555555,</span></span><br><span class="line"><span class="comment">#   &quot;f1&quot;: 0.9955553580159118,</span></span><br><span class="line"><span class="comment">#   &quot;num_samples&quot;: 225.0</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br></pre></td></tr></table></figure><h2 id="Saving-loading">Saving &amp; loading</h2><p>我们需要保存一些必要的模型数据，以供后续能够完整的加载和使用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Save artifacts</span></span><br><span class="line"><span class="built_in">dir</span> = Path(<span class="string">&quot;mlp&quot;</span>)</span><br><span class="line"><span class="built_in">dir</span>.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">label_encoder.save(fp=Path(<span class="built_in">dir</span>, <span class="string">&quot;label_encoder.json&quot;</span>))</span><br><span class="line">X_scaler.save(fp=Path(<span class="built_in">dir</span>, <span class="string">&quot;X_scaler.json&quot;</span>))</span><br><span class="line">torch.save(best_model.state_dict(), Path(<span class="built_in">dir</span>, <span class="string">&quot;model.pt&quot;</span>))</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(Path(<span class="built_in">dir</span>, <span class="string">&#x27;performance.json&#x27;</span>), <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    json.dump(performance, indent=<span class="number">2</span>, sort_keys=<span class="literal">False</span>, fp=fp)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load artifacts</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">label_encoder = LabelEncoder.load(fp=Path(<span class="built_in">dir</span>, <span class="string">&quot;label_encoder.json&quot;</span>))</span><br><span class="line">X_scaler = StandardScaler.load(fp=Path(<span class="built_in">dir</span>, <span class="string">&quot;X_scaler.json&quot;</span>))</span><br><span class="line">model = MLP(</span><br><span class="line">    input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM,</span><br><span class="line">    dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)</span><br><span class="line">model.load_state_dict(torch.load(Path(<span class="built_in">dir</span>, <span class="string">&quot;model.pt&quot;</span>), map_location=device))</span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize trainer</span></span><br><span class="line">trainer = Trainer(model=model, device=device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Dataloader</span></span><br><span class="line">sample = [[<span class="number">0.106737</span>, <span class="number">0.114197</span>]] <span class="comment"># c1</span></span><br><span class="line">X = X_scaler.scale(sample)</span><br><span class="line">y_filler = label_encoder.encode([label_encoder.classes[<span class="number">0</span>]]*<span class="built_in">len</span>(X))</span><br><span class="line">dataset = Dataset(X=X, y=y_filler)</span><br><span class="line">dataloader = dataset.create_dataloader(batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Inference</span></span><br><span class="line">y_prob = trainer.predict_step(dataloader)</span><br><span class="line">y_pred = np.argmax(y_prob, axis=<span class="number">1</span>)</span><br><span class="line">label_encoder.decode(y_pred)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Ending">Ending</h2><p>本文给出了一个机器学习项目的基本组件， 事实上，还有一些其他的重要组成没有覆盖到。比如：</p><ul><li>文本序列化的Tokenizers</li><li>表征数据的Encoders</li><li>数据padding</li><li>实验跟踪及可视化结果</li><li>超惨优化</li><li>等等</li></ul><p>后续我们会继续学习，至少到这里，我们有了入门深度学习的基础了。</p>]]></content>
    
    <summary type="html">
    
      先上手再说。
    
    </summary>
    
    
      <category term="Way2AI" scheme="https://neo1989.net/categories/Way2AI/"/>
    
    
      <category term="Coder" scheme="https://neo1989.net/tags/Coder/"/>
    
      <category term="AI" scheme="https://neo1989.net/tags/AI/"/>
    
      <category term="PyTorch" scheme="https://neo1989.net/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>Way2AI · 神经网络 (二)</title>
    <link href="https://neo1989.net/Way2AI/Way2AI-neural-networks-2/"/>
    <id>https://neo1989.net/Way2AI/Way2AI-neural-networks-2/</id>
    <published>2023-06-12T14:56:13.000Z</published>
    <updated>2023-06-14T05:21:05.688Z</updated>
    
    <content type="html"><![CDATA[<h2 id="TL-DR">TL;DR</h2><p>接上篇，本文使用PyTorch实现一个相同的神经网络模型。</p><h2 id="Model">Model</h2><p>我们将使用两个线性连接层，并在前向传播中添加ReLU激活函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim, hidden_dim, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(MLP, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(input_dim, hidden_dim)</span><br><span class="line">        self.fc2 = nn.Linear(hidden_dim, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x_in</span>):</span><br><span class="line">        z = F.relu(self.fc1(x_in))</span><br><span class="line">        z = self.fc2(z)</span><br><span class="line">        <span class="keyword">return</span> z</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initalize model</span></span><br><span class="line">model = MLP(input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM, num_classes=NUM_CLASSES)</span><br><span class="line"><span class="built_in">print</span>(model.named_parameters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &lt;bound method Module.named_parameters of MLP(</span></span><br><span class="line"><span class="comment">#   (fc1): Linear(in_features=2, out_features=100, bias=True)</span></span><br><span class="line"><span class="comment">#   (fc2): Linear(in_features=100, out_features=3, bias=True)</span></span><br><span class="line"><span class="comment"># )&gt;</span></span><br></pre></td></tr></table></figure><h2 id="Training">Training</h2><p>训练模型的代码跟之前学到的逻辑回归几乎没有区别。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">LEARNING_RATE = <span class="number">1e-2</span></span><br><span class="line">NUM_EPOCHS = <span class="number">10</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define Loss</span></span><br><span class="line">class_weights_tensor = torch.Tensor(<span class="built_in">list</span>(class_weights.values()))</span><br><span class="line">loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy_fn</span>(<span class="params">y_pred, y_true</span>):</span><br><span class="line">    n_correct = torch.eq(y_pred, y_true).<span class="built_in">sum</span>().item()</span><br><span class="line">    accuarcy = (n_correct / <span class="built_in">len</span>(y_pred)) * <span class="number">100</span></span><br><span class="line">    <span class="keyword">return</span> accuarcy</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optimizer</span></span><br><span class="line">optimizer = Adam(model.parameters(), lr=LEARNING_RATE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert data to tensors</span></span><br><span class="line">X_train = torch.Tensor(X_train)</span><br><span class="line">y_train = torch.LongTensor(y_train)</span><br><span class="line">X_val = torch.Tensor(X_val)</span><br><span class="line">y_val = torch.LongTensor(y_val)</span><br><span class="line">X_test = torch.Tensor(X_test)</span><br><span class="line">y_test = torch.LongTensor(y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(NUM_EPOCHS * <span class="number">10</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    y_pred = model(X_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Loss</span></span><br><span class="line">    loss = loss_fn(y_pred, y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Zero all gradients</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        predictions = y_pred.<span class="built_in">max</span>(dim=<span class="number">1</span>)[<span class="number">1</span>]  <span class="comment"># class</span></span><br><span class="line">        accuracy = accuracy_fn(y_pred=predictions, y_true=y_train)</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch&#125;</span> | loss: <span class="subst">&#123;loss:<span class="number">.2</span>f&#125;</span>, accuracy: <span class="subst">&#123;accuracy:<span class="number">.1</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Epoch: 0 | loss: 0.09, accuracy: 98.6</span></span><br><span class="line"><span class="comment"># Epoch: 10 | loss: 0.06, accuracy: 99.0</span></span><br><span class="line"><span class="comment"># Epoch: 20 | loss: 0.05, accuracy: 99.2</span></span><br><span class="line"><span class="comment"># Epoch: 30 | loss: 0.04, accuracy: 99.6</span></span><br><span class="line"><span class="comment"># Epoch: 40 | loss: 0.03, accuracy: 99.7</span></span><br><span class="line"><span class="comment"># Epoch: 50 | loss: 0.03, accuracy: 99.7</span></span><br><span class="line"><span class="comment"># Epoch: 60 | loss: 0.03, accuracy: 99.7</span></span><br><span class="line"><span class="comment"># Epoch: 70 | loss: 0.02, accuracy: 99.7</span></span><br><span class="line"><span class="comment"># Epoch: 80 | loss: 0.02, accuracy: 99.7</span></span><br><span class="line"><span class="comment"># Epoch: 90 | loss: 0.02, accuracy: 99.7</span></span><br></pre></td></tr></table></figure><h2 id="Evaluation">Evaluation</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Predictiions</span></span><br><span class="line">y_prob = F.softmax(model(X_test), dim=<span class="number">1</span>)</span><br><span class="line">y_pred = y_prob.<span class="built_in">max</span>(dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Performance</span></span><br><span class="line">performance = get_metrics(y_true=y_test, y_pred=y_pred, classes=classes)</span><br><span class="line"><span class="built_in">print</span> (json.dumps(performance, indent=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &#123;</span></span><br><span class="line"><span class="comment">#   &quot;overall&quot;: &#123;</span></span><br><span class="line"><span class="comment">#     &quot;precision&quot;: 1.0,</span></span><br><span class="line"><span class="comment">#     &quot;recall&quot;: 1.0,</span></span><br><span class="line"><span class="comment">#     &quot;f1&quot;: 1.0,</span></span><br><span class="line"><span class="comment">#     &quot;num_samples&quot;: 225.0</span></span><br><span class="line"><span class="comment">#   &#125;,</span></span><br><span class="line"><span class="comment">#   &quot;class&quot;: &#123;</span></span><br><span class="line"><span class="comment">#     &quot;c1&quot;: &#123;</span></span><br><span class="line"><span class="comment">#       &quot;precision&quot;: 1.0,</span></span><br><span class="line"><span class="comment">#       &quot;recall&quot;: 1.0,</span></span><br><span class="line"><span class="comment">#       &quot;f1&quot;: 1.0,</span></span><br><span class="line"><span class="comment">#       &quot;num_samples&quot;: 75.0</span></span><br><span class="line"><span class="comment">#     &#125;,</span></span><br><span class="line"><span class="comment">#     &quot;c2&quot;: &#123;</span></span><br><span class="line"><span class="comment">#       &quot;precision&quot;: 1.0,</span></span><br><span class="line"><span class="comment">#       &quot;recall&quot;: 1.0,</span></span><br><span class="line"><span class="comment">#       &quot;f1&quot;: 1.0,</span></span><br><span class="line"><span class="comment">#       &quot;num_samples&quot;: 75.0</span></span><br><span class="line"><span class="comment">#     &#125;,</span></span><br><span class="line"><span class="comment">#     &quot;c3&quot;: &#123;</span></span><br><span class="line"><span class="comment">#       &quot;precision&quot;: 1.0,</span></span><br><span class="line"><span class="comment">#       &quot;recall&quot;: 1.0,</span></span><br><span class="line"><span class="comment">#       &quot;f1&quot;: 1.0,</span></span><br><span class="line"><span class="comment">#       &quot;num_samples&quot;: 75.0</span></span><br><span class="line"><span class="comment">#     &#125;</span></span><br><span class="line"><span class="comment">#   &#125;</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Visualize the decision boundary</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">5</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Train&quot;</span>)</span><br><span class="line">plot_multiclass_decision_boundary(model=model, X=X_train, y=y_train)</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Test&quot;</span>)</span><br><span class="line">plot_multiclass_decision_boundary(model=model, X=X_test, y=y_test)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="//s3.mindex.xyz/blog/Courses/3ac0940bf9a117acde72a4d36241c2b8.png" alt=""></p><p>如你所见，PyTorch的直观和易用性能让我的学习曲线相对平缓。</p><p>需要我们编写的核心代码，只集中在定义模型、定义损失函数和优化器、定义训练循环、验证和测试这个四个部分。</p><p>当然，还有许多细节需要考虑，比如说数据预处理、模型的保存和加载、使用GPU等。</p><h2 id="Initializing-weights">Initializing weights</h2><p>到目前为止，我们都是使用了一个很小的随机值初始化权重，这其实不是让模型在训练阶段能够收敛的最佳方式。</p><p>我们的目标是初始化一个合适的权重，使得我们激活的输出不会消失或者爆炸，因为这两种情况都会阻碍模型收敛。事实上我们可以<a href="https://pytorch.org/docs/stable/nn.init.html" title="nn.init">自定义权重初始化</a>方法。目前比较常用的是<a href="https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.xavier_normal_" title="nn.init.xavier_normal_">Xavier初始化方法</a>和<a href="https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_normal_" title="nn.init.kaiming_normal_">He初始化方法</a>。</p><p>事实上PyTorch的Linear类默认使用了kaiming_uniform_初始化方法，相关源代码看<a href="https://github.com/pytorch/pytorch/blob/af7dc23124a6e3e7b8af0637e3b027f3a8b3fb76/torch/nn/modules/linear.py#L101" title="Linear源码">这里</a>，后续我们会学习到更高级的优化收敛的策略如batch normalization。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim, hidden_dim, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(MLP, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(input_dim, hidden_dim)</span><br><span class="line">        self.fc2 = nn.Linear(hidden_dim, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_weights</span>(<span class="params">self</span>):</span><br><span class="line">        init.xavier_normal_(self.fc1.weight, gain=init.calculate_gain(<span class="string">&quot;relu&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x_in</span>):</span><br><span class="line">        z = F.relu(self.fc1(x_in))</span><br><span class="line">        z = self.fc2(z)</span><br><span class="line">        <span class="keyword">return</span> z</span><br></pre></td></tr></table></figure><h2 id="Dropout">Dropout</h2><p>能够让我们的模型表现的好的最好的技术是增加数据，但这并不总是一个可选项。幸运的是，还有有一些帮助模型更健壮的其他办法，如正则化、dropout等。</p><p>Dropout是在训练过程中允许我们将神经元的输出置0的技术。由于我们每批次都会丢弃一组不同的神经元，所以Dropout可以作为一种采样策略，防止过拟合。</p><p><img src="//s3.mindex.xyz/blog/Courses/2c301aaf51dcbdc7fb1556b1cf547228.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">DROPOUT_P = <span class="number">0.1</span> <span class="comment"># percentage of weights that are dropped each pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim, hidden_dim, dropout_p, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(MLP, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(input_dim, hidden_dim)</span><br><span class="line">        self.dropout = nn.Dropout(dropout_p) <span class="comment"># dropout</span></span><br><span class="line">        self.fc2 = nn.Linear(hidden_dim, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_weights</span>(<span class="params">self</span>):</span><br><span class="line">        init.xavier_normal(self.fc1.weight, gain=init.calculate_gain(<span class="string">&quot;relu&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x_in</span>):</span><br><span class="line">        z = F.relu(self.fc1(x_in))</span><br><span class="line">        z = self.dropout(z) <span class="comment"># dropout</span></span><br><span class="line">        z = self.fc2(z)</span><br><span class="line">        <span class="keyword">return</span> z</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize model</span></span><br><span class="line">model = MLP(input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM,</span><br><span class="line">            dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)</span><br><span class="line"><span class="built_in">print</span> (model.named_parameters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &lt;bound method Module.named_parameters of MLP(</span></span><br><span class="line"><span class="comment">#   (fc1): Linear(in_features=2, out_features=100, bias=True)</span></span><br><span class="line"><span class="comment">#   (dropout): Dropout(p=0.1, inplace=False)</span></span><br><span class="line"><span class="comment">#   (fc2): Linear(in_features=100, out_features=3, bias=True)</span></span><br><span class="line"><span class="comment"># )&gt;</span></span><br></pre></td></tr></table></figure><h2 id="Overfitting">Overfitting</h2><p>虽然神经网络很擅长捕捉非线性关系，但它们非常容易对训练数据进行过度拟合，且无法对测试数据进行归纳。</p><p>看看下面的例子，我们使用完全随机的数据，并试图拟合含 $2 * N * C + D $ (其中N=样本数，C=标签，D表示输入纬度) 隐藏神经元的模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br></pre></td><td class="code"><pre><span class="line">NUM_EPOCHS = <span class="number">500</span></span><br><span class="line">NUM_SAMPLES_PER_CLASS = <span class="number">50</span></span><br><span class="line">LEARNING_RATE = <span class="number">1e-1</span></span><br><span class="line">HIDDEN_DIM = <span class="number">2</span> * NUM_SAMPLES_PER_CLASS * NUM_CLASSES + INPUT_DIM <span class="comment"># 2*N*C + D</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate random data</span></span><br><span class="line">X = np.random.rand(NUM_SAMPLES_PER_CLASS * NUM_CLASSES, INPUT_DIM)</span><br><span class="line">y = np.array([[i] * NUM_SAMPLES_PER_CLASS <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(NUM_CLASSES)]).reshape(-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;X: &quot;</span>, <span class="built_in">format</span>(np.shape(X)))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;y: &quot;</span>, <span class="built_in">format</span>(np.shape(y)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># X:  (150, 2)</span></span><br><span class="line"><span class="comment"># y:  (150,)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create data splits</span></span><br><span class="line">X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(</span><br><span class="line">    X=X, y=y, train_size=TRAIN_SIZE)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_train: <span class="subst">&#123;X_train.shape&#125;</span>, y_train: <span class="subst">&#123;y_train.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_val: <span class="subst">&#123;X_val.shape&#125;</span>, y_val: <span class="subst">&#123;y_val.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_test: <span class="subst">&#123;X_test.shape&#125;</span>, y_test: <span class="subst">&#123;y_test.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;Sample point: <span class="subst">&#123;X_train[<span class="number">0</span>]&#125;</span> → <span class="subst">&#123;y_train[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># X_train: (105, 2), y_train: (105,)</span></span><br><span class="line"><span class="comment"># X_val: (23, 2), y_val: (23,)</span></span><br><span class="line"><span class="comment"># X_test: (22, 2), y_test: (22,)</span></span><br><span class="line"><span class="comment"># Sample point: [0.51102894 0.55377194] → 2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Standardize the inputs (mean=0, std=1) using training data</span></span><br><span class="line">X_scaler = StandardScaler().fit(X_train)</span><br><span class="line">X_train = X_scaler.transform(X_train)</span><br><span class="line">X_val = X_scaler.transform(X_val)</span><br><span class="line">X_test = X_scaler.transform(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert data to tensors</span></span><br><span class="line">X_train = torch.Tensor(X_train)</span><br><span class="line">y_train = torch.LongTensor(y_train)</span><br><span class="line">X_val = torch.Tensor(X_val)</span><br><span class="line">y_val = torch.LongTensor(y_val)</span><br><span class="line">X_test = torch.Tensor(X_test)</span><br><span class="line">y_test = torch.LongTensor(y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize model</span></span><br><span class="line">model = MLP(input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM,</span><br><span class="line">            dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)</span><br><span class="line"><span class="built_in">print</span> (model.named_parameters)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &lt;bound method Module.named_parameters of MLP(</span></span><br><span class="line"><span class="comment">#   (fc1): Linear(in_features=2, out_features=302, bias=True)</span></span><br><span class="line"><span class="comment">#   (dropout): Dropout(p=0.1, inplace=False)</span></span><br><span class="line"><span class="comment">#   (fc2): Linear(in_features=302, out_features=3, bias=True)</span></span><br><span class="line"><span class="comment"># )&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Optimizer</span></span><br><span class="line">optimizer = Adam(model.parameters(), lr=LEARNING_RATE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(NUM_EPOCHS):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    y_pred = model(X_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Loss</span></span><br><span class="line">    loss = loss_fn(y_pred, y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Zero all gradients</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">50</span>==<span class="number">0</span>:</span><br><span class="line">        predictions = y_pred.<span class="built_in">max</span>(dim=<span class="number">1</span>)[<span class="number">1</span>] <span class="comment"># class</span></span><br><span class="line">        accuracy = accuracy_fn(y_pred=predictions, y_true=y_train)</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch&#125;</span> | loss: <span class="subst">&#123;loss:<span class="number">.2</span>f&#125;</span>, accuracy: <span class="subst">&#123;accuracy:<span class="number">.1</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Epoch: 0 | loss: 1.07, accuracy: 43.8</span></span><br><span class="line"><span class="comment"># Epoch: 20 | loss: 0.94, accuracy: 52.4</span></span><br><span class="line"><span class="comment"># Epoch: 40 | loss: 0.89, accuracy: 55.2</span></span><br><span class="line"><span class="comment"># Epoch: 60 | loss: 0.87, accuracy: 49.5</span></span><br><span class="line"><span class="comment"># Epoch: 80 | loss: 0.82, accuracy: 63.8</span></span><br><span class="line"><span class="comment"># Epoch: 100 | loss: 0.84, accuracy: 62.9</span></span><br><span class="line"><span class="comment"># Epoch: 120 | loss: 0.75, accuracy: 63.8</span></span><br><span class="line"><span class="comment"># Epoch: 140 | loss: 0.77, accuracy: 60.0</span></span><br><span class="line"><span class="comment"># Epoch: 160 | loss: 0.75, accuracy: 60.0</span></span><br><span class="line"><span class="comment"># Epoch: 180 | loss: 0.75, accuracy: 66.7</span></span><br><span class="line"><span class="comment"># Epoch: 200 | loss: 0.75, accuracy: 67.6</span></span><br><span class="line"><span class="comment"># Epoch: 220 | loss: 0.69, accuracy: 68.6</span></span><br><span class="line"><span class="comment"># Epoch: 240 | loss: 0.75, accuracy: 65.7</span></span><br><span class="line"><span class="comment"># Epoch: 260 | loss: 0.73, accuracy: 71.4</span></span><br><span class="line"><span class="comment"># Epoch: 280 | loss: 0.73, accuracy: 69.5</span></span><br><span class="line"><span class="comment"># Epoch: 300 | loss: 0.71, accuracy: 62.9</span></span><br><span class="line"><span class="comment"># Epoch: 320 | loss: 0.68, accuracy: 69.5</span></span><br><span class="line"><span class="comment"># Epoch: 340 | loss: 0.74, accuracy: 65.7</span></span><br><span class="line"><span class="comment"># Epoch: 360 | loss: 0.68, accuracy: 71.4</span></span><br><span class="line"><span class="comment"># Epoch: 380 | loss: 0.78, accuracy: 63.8</span></span><br><span class="line"><span class="comment"># Epoch: 400 | loss: 0.69, accuracy: 66.7</span></span><br><span class="line"><span class="comment"># Epoch: 420 | loss: 0.75, accuracy: 67.6</span></span><br><span class="line"><span class="comment"># Epoch: 440 | loss: 0.76, accuracy: 69.5</span></span><br><span class="line"><span class="comment"># Epoch: 460 | loss: 0.71, accuracy: 67.6</span></span><br><span class="line"><span class="comment"># Epoch: 480 | loss: 0.66, accuracy: 66.7</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Predictions</span></span><br><span class="line">y_prob = F.softmax(model(X_test), dim=<span class="number">1</span>)</span><br><span class="line">y_pred = y_prob.<span class="built_in">max</span>(dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Performance</span></span><br><span class="line">performance = get_metrics(y_true=y_test, y_pred=y_pred, classes=classes)</span><br><span class="line"><span class="built_in">print</span> (json.dumps(performance, indent=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &#123;</span></span><br><span class="line"><span class="comment">#   &quot;overall&quot;: &#123;</span></span><br><span class="line"><span class="comment">#     &quot;precision&quot;: 0.45959595959595956,</span></span><br><span class="line"><span class="comment">#     &quot;recall&quot;: 0.45454545454545453,</span></span><br><span class="line"><span class="comment">#     &quot;f1&quot;: 0.4512987012987013,</span></span><br><span class="line"><span class="comment">#     &quot;num_samples&quot;: 22.0</span></span><br><span class="line"><span class="comment">#   &#125;,</span></span><br><span class="line"><span class="comment">#   &quot;class&quot;: &#123;</span></span><br><span class="line"><span class="comment">#     &quot;c1&quot;: &#123;</span></span><br><span class="line"><span class="comment">#       &quot;precision&quot;: 0.5,</span></span><br><span class="line"><span class="comment">#       &quot;recall&quot;: 0.375,</span></span><br><span class="line"><span class="comment">#       &quot;f1&quot;: 0.42857142857142855,</span></span><br><span class="line"><span class="comment">#       &quot;num_samples&quot;: 8.0</span></span><br><span class="line"><span class="comment">#     &#125;,</span></span><br><span class="line"><span class="comment">#     &quot;c2&quot;: &#123;</span></span><br><span class="line"><span class="comment">#       &quot;precision&quot;: 0.4444444444444444,</span></span><br><span class="line"><span class="comment">#       &quot;recall&quot;: 0.5714285714285714,</span></span><br><span class="line"><span class="comment">#       &quot;f1&quot;: 0.5,</span></span><br><span class="line"><span class="comment">#       &quot;num_samples&quot;: 7.0</span></span><br><span class="line"><span class="comment">#     &#125;,</span></span><br><span class="line"><span class="comment">#     &quot;c3&quot;: &#123;</span></span><br><span class="line"><span class="comment">#       &quot;precision&quot;: 0.42857142857142855,</span></span><br><span class="line"><span class="comment">#       &quot;recall&quot;: 0.42857142857142855,</span></span><br><span class="line"><span class="comment">#       &quot;f1&quot;: 0.42857142857142855,</span></span><br><span class="line"><span class="comment">#       &quot;num_samples&quot;: 7.0</span></span><br><span class="line"><span class="comment">#     &#125;</span></span><br><span class="line"><span class="comment">#   &#125;</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Visualize the decision boundary</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">5</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Train&quot;</span>)</span><br><span class="line">plot_multiclass_decision_boundary(model=model, X=X_train, y=y_train)</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Test&quot;</span>)</span><br><span class="line">plot_multiclass_decision_boundary(model=model, X=X_test, y=y_test)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="//s3.mindex.xyz/blog/Courses/8b43366da170668bdeaee171c279362d.png" alt=""></p><p>正如你所见，虽然模型在训练集上做到了接近70%的准确率，但模型在测试集上的表现并不能令人满意。</p><p>重要的是我们需要进行实验，从不合适（高偏差）的简单模型开始，并试图改进到良好的拟合，以及避免过拟合。</p><p><img src="//s3.mindex.xyz/blog/Courses/9a3b5a8d871020ccda41430ca7958bc1.png" alt=""></p><h2 id="Citation">Citation</h2><figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="language-xml">@article</span><span class="template-variable">&#123;madewithml,</span></span><br><span class="line"><span class="template-variable">    author       = &#123;Goku Mohandas&#125;</span><span class="language-xml">,</span></span><br><span class="line"><span class="language-xml">    title        = </span><span class="template-variable">&#123; Neural networks - Made With ML &#125;</span><span class="language-xml">,</span></span><br><span class="line"><span class="language-xml">    howpublished = </span><span class="template-variable">&#123;\url&#123;https://madewithml.com/&#125;</span><span class="language-xml">&#125;,</span></span><br><span class="line"><span class="language-xml">    year         = </span><span class="template-variable">&#123;2022&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">&#125;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      PyTorch实现一个神经网络。
    
    </summary>
    
    
      <category term="Way2AI" scheme="https://neo1989.net/categories/Way2AI/"/>
    
    
      <category term="Coder" scheme="https://neo1989.net/tags/Coder/"/>
    
      <category term="AI" scheme="https://neo1989.net/tags/AI/"/>
    
      <category term="PyTorch" scheme="https://neo1989.net/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>Way2AI · 神经网络 (一)</title>
    <link href="https://neo1989.net/Way2AI/Way2AI-neural-networks-1/"/>
    <id>https://neo1989.net/Way2AI/Way2AI-neural-networks-1/</id>
    <published>2023-06-01T08:16:24.000Z</published>
    <updated>2023-06-08T15:33:37.054Z</updated>
    
    <content type="html"><![CDATA[<h2 id="TL-DR">TL;DR</h2><p>本章的目标依然是学习一种模型 $\hat{y}$，能准确对输入 $X$ 及对应的输出 $y$ 进行建模。</p><p>你会注意到神经网络只是我们迄今为止看到的广义线性方法的扩展，但具有非线性激活函数，因为我们的数据是高度非线性的。</p><p><img src="//s3.mindex.xyz/blog/Courses/908c174b73d8c8bb1c1ec3ba9e4cf885.png" alt=""></p><p>$$<br>z_1 = XW_1<br>$$</p><p>$$<br>a_1 = f(z_1)<br>$$</p><p>$$<br>z_2 = a_1W_2<br>$$</p><p>$$<br>\hat{y} = softmax(x)<br>$$</p><table><thead><tr><th style="text-align:center">参数</th><th style="text-align:center">解释</th></tr></thead><tbody><tr><td style="text-align:center">$N$</td><td style="text-align:center">样本数</td></tr><tr><td style="text-align:center">$D$</td><td style="text-align:center">特征数</td></tr><tr><td style="text-align:center">$H$</td><td style="text-align:center">隐藏神经元</td></tr><tr><td style="text-align:center">$C$</td><td style="text-align:center">标签数</td></tr><tr><td style="text-align:center">$W_1$</td><td style="text-align:center">第一层的权重</td></tr><tr><td style="text-align:center">$z_1$</td><td style="text-align:center">第一层的输出</td></tr><tr><td style="text-align:center">$f$</td><td style="text-align:center">非线性激活函数</td></tr><tr><td style="text-align:center">$a_1$</td><td style="text-align:center">第一层的激活值</td></tr><tr><td style="text-align:center">$W_2$</td><td style="text-align:center">第二层的权重</td></tr><tr><td style="text-align:center">$z_2$</td><td style="text-align:center">第二层的输出</td></tr></tbody></table><h2 id="Set-up">Set up</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">SEED = <span class="number">1024</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set seed for reproducibility</span></span><br><span class="line">np.random.seed(SEED)</span><br><span class="line">random.seed(SEED)</span><br></pre></td></tr></table></figure><h3 id="Load-data">Load data</h3><p>这里准备了一份非线性可分的螺旋数据来学习。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load data</span></span><br><span class="line">url = <span class="string">&quot;http://s3.mindex.xyz/datasets/9378f64fc8dd2817e4c92be0a3bae8e7.csv&quot;</span></span><br><span class="line">df = pd.read_csv(url, header=<span class="number">0</span>) <span class="comment"># load</span></span><br><span class="line">df = df.sample(frac=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>) <span class="comment"># shuffle</span></span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure><p><img src="//s3.mindex.xyz/blog/Courses/4022744de8e63b11599cdd95aab6ac62.png" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Data shapes</span></span><br><span class="line">X = df[[<span class="string">&quot;X1&quot;</span>, <span class="string">&quot;X2&quot;</span>]].values</span><br><span class="line">y = df[<span class="string">&quot;color&quot;</span>].values</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;X: &quot;</span>, np.shape(X))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;y: &quot;</span>, np.shape(y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># X:  (1500, 2)</span></span><br><span class="line"><span class="comment"># y:  (1500,)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Visualize data</span></span><br><span class="line">plt.title(<span class="string">&quot;Generated non-linear data&quot;</span>)</span><br><span class="line">colors = &#123;<span class="string">&quot;c1&quot;</span>: <span class="string">&quot;red&quot;</span>, <span class="string">&quot;c2&quot;</span>: <span class="string">&quot;yellow&quot;</span>, <span class="string">&quot;c3&quot;</span>: <span class="string">&quot;blue&quot;</span>&#125;</span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=[colors[_y] <span class="keyword">for</span> _y <span class="keyword">in</span> y], edgecolors=<span class="string">&quot;k&quot;</span>, s=<span class="number">25</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="//s3.mindex.xyz/blog/Courses/147e784e6ecae3fd226abce4f3905550.png" alt=""></p><h3 id="Split-data">Split data</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">TRAIN_SIZE = <span class="number">0.7</span></span><br><span class="line">VAL_SIZE = <span class="number">0.15</span></span><br><span class="line">TEST_SIZE = <span class="number">0.15</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_val_test_split</span>(<span class="params">X, y, train_size</span>):</span><br><span class="line">    X_train, X_, y_train, y_ = train_test_split(X, y, train_size=TRAIN_SIZE, stratify=y)</span><br><span class="line">    X_test, X_val, y_test, y_val = train_test_split(X_, y_, train_size=<span class="number">0.5</span>, stratify=y_)</span><br><span class="line">    <span class="keyword">return</span> X_train, X_val, X_test, y_train, y_val, y_test</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create data splits</span></span><br><span class="line">X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(</span><br><span class="line">    X=X, y=y, train_size=TRAIN_SIZE)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_train: <span class="subst">&#123;X_train.shape&#125;</span>, y_train: <span class="subst">&#123;y_train.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_val: <span class="subst">&#123;X_val.shape&#125;</span>, y_val: <span class="subst">&#123;y_val.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_test: <span class="subst">&#123;X_test.shape&#125;</span>, y_test: <span class="subst">&#123;y_test.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;Sample point: <span class="subst">&#123;X_train[<span class="number">0</span>]&#125;</span> → <span class="subst">&#123;y_train[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># X_train: (1050, 2), y_train: (1050,)</span></span><br><span class="line"><span class="comment"># X_val: (225, 2), y_val: (225,)</span></span><br><span class="line"><span class="comment"># X_test: (225, 2), y_test: (225,)</span></span><br><span class="line"><span class="comment"># Sample point: [0.17003003 0.63079261] → c3</span></span><br></pre></td></tr></table></figure><h3 id="Label-encoding">Label encoding</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output vectorizer</span></span><br><span class="line">label_encoder = LabelEncoder()</span><br><span class="line"></span><br><span class="line"><span class="comment"># FIt on train date</span></span><br><span class="line">label_encoder = label_encoder.fit(y_train)</span><br><span class="line">classes = <span class="built_in">list</span>(label_encoder.classes_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;classes: <span class="subst">&#123;classes&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># classes: [&#x27;c1&#x27;, &#x27;c2&#x27;, &#x27;c3&#x27;]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert labels to tokens</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;y_train[0]: <span class="subst">&#123;y_train[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line">y_train = label_encoder.transform(y_train)</span><br><span class="line">y_val = label_encoder.transform(y_val)</span><br><span class="line">y_test = label_encoder.transform(y_test)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;y_train[0]: <span class="subst">&#123;y_train[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># y_train[0]: c3</span></span><br><span class="line"><span class="comment"># y_train[0]: 2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Class weights</span></span><br><span class="line">counts = np.bincount(y_train)</span><br><span class="line">class_weights = &#123;i: <span class="number">1.0</span>/count <span class="keyword">for</span> i, count <span class="keyword">in</span> <span class="built_in">enumerate</span>(counts)&#125;</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;counts: <span class="subst">&#123;counts&#125;</span>\nweights: <span class="subst">&#123;class_weights&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># counts: [350 350 350]</span></span><br><span class="line"><span class="comment"># weights: &#123;0: 0.002857142857142857, 1: 0.002857142857142857, 2: 0.002857142857142857&#125;</span></span><br></pre></td></tr></table></figure><h3 id="Standardize-data">Standardize data</h3><p>因为 $y$ 是类别值，所以我们只标准化 $X$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># Standardize the data (mean=0, std=1) using training data</span></span><br><span class="line">X_scaler = StandardScaler().fit(X_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Apply scaler on training and test data (don&#x27;t standardize outputs for classification)</span></span><br><span class="line">X_train = X_scaler.transform(X_train)</span><br><span class="line">X_val = X_scaler.transform(X_val)</span><br><span class="line">X_test = X_scaler.transform(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check (means should be ~0 and std should be ~1)</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_test[0]: mean: <span class="subst">&#123;np.mean(X_test[:, <span class="number">0</span>], axis=<span class="number">0</span>):<span class="number">.1</span>f&#125;</span>, std: <span class="subst">&#123;np.std(X_test[:, <span class="number">0</span>], axis=<span class="number">0</span>):<span class="number">.1</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_test[1]: mean: <span class="subst">&#123;np.mean(X_test[:, <span class="number">1</span>], axis=<span class="number">0</span>):<span class="number">.1</span>f&#125;</span>, std: <span class="subst">&#123;np.std(X_test[:, <span class="number">1</span>], axis=<span class="number">0</span>):<span class="number">.1</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># X_test[0]: mean: 0.0, std: 1.0</span></span><br><span class="line"><span class="comment"># X_test[1]: mean: -0.0, std: 1.0</span></span><br></pre></td></tr></table></figure><h2 id="Linear-model">Linear model</h2><p>在尝试使用神经网络之前，为了解释激活函数，我们先用前面学到的逻辑回归模型来学习我们的数据。</p><p>你会发现一个用线性激活函数的线性模型对我们的数据来说并不是合适的。</p><h3 id="Model-Train">Model &amp; Train</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> Adam</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">INPUT_DIM = X_train.shape[<span class="number">1</span>] <span class="comment"># X is 2-dimensional</span></span><br><span class="line">HIDDEN_DIM = <span class="number">100</span></span><br><span class="line">NUM_CLASSES = <span class="built_in">len</span>(classes) <span class="comment"># 3 classes</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim, hidden_dim, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(LinearModel, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(input_dim, hidden_dim)</span><br><span class="line">        self.fc2 = nn.Linear(hidden_dim, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x_in</span>):</span><br><span class="line">        z = self.fc1(x_in) <span class="comment"># linear activation</span></span><br><span class="line">        z = self.fc2(z)</span><br><span class="line">        <span class="keyword">return</span> z</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize model</span></span><br><span class="line">model = LinearModel(input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM, num_classes=NUM_CLASSES)</span><br><span class="line"></span><br><span class="line">LEARNING_RATE = <span class="number">1e-2</span></span><br><span class="line">NUM_EPOCHS = <span class="number">10</span></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line"></span><br><span class="line">class_weights_tensor = torch.Tensor(<span class="built_in">list</span>(class_weights.values()))</span><br><span class="line">loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy_fn</span>(<span class="params">y_pred, y_true</span>):</span><br><span class="line">    n_correct = torch.eq(y_pred, y_true).<span class="built_in">sum</span>().item()</span><br><span class="line">    accuracy = (n_correct / <span class="built_in">len</span>(y_pred)) * <span class="number">100</span></span><br><span class="line">    <span class="keyword">return</span> accuracy</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optimizer</span></span><br><span class="line">optimizer = Adam(model.parameters(), lr=LEARNING_RATE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert data to tensors</span></span><br><span class="line">X_train = torch.Tensor(X_train)</span><br><span class="line">y_train = torch.LongTensor(y_train)</span><br><span class="line">X_val = torch.Tensor(X_val)</span><br><span class="line">y_val = torch.LongTensor(y_val)</span><br><span class="line">X_test = torch.Tensor(X_test)</span><br><span class="line">y_test = torch.LongTensor(y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(NUM_EPOCHS):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    y_pred = model(X_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Loss</span></span><br><span class="line">    loss = loss_fn(y_pred, y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Zero all gradients</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        predictions = y_pred.<span class="built_in">max</span>(dim=<span class="number">1</span>)[<span class="number">1</span>] <span class="comment"># class</span></span><br><span class="line">        accuracy = accuracy_fn(y_pred=predictions, y_true=y_train)</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch&#125;</span> | loss: <span class="subst">&#123;loss:<span class="number">.2</span>f&#125;</span>, accuracy: <span class="subst">&#123;accuracy:<span class="number">.1</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Epoch: 0 | loss: 1.18, accuracy: 43.7</span></span><br><span class="line"><span class="comment"># Epoch: 1 | loss: 0.92, accuracy: 55.6</span></span><br><span class="line"><span class="comment"># Epoch: 2 | loss: 0.79, accuracy: 54.5</span></span><br><span class="line"><span class="comment"># Epoch: 3 | loss: 0.74, accuracy: 54.4</span></span><br><span class="line"><span class="comment"># Epoch: 4 | loss: 0.73, accuracy: 53.9</span></span><br><span class="line"><span class="comment"># Epoch: 5 | loss: 0.73, accuracy: 53.9</span></span><br><span class="line"><span class="comment"># Epoch: 6 | loss: 0.74, accuracy: 55.0</span></span><br><span class="line"><span class="comment"># Epoch: 7 | loss: 0.75, accuracy: 55.8</span></span><br><span class="line"><span class="comment"># Epoch: 8 | loss: 0.76, accuracy: 56.2</span></span><br><span class="line"><span class="comment"># Epoch: 9 | loss: 0.77, accuracy: 56.7</span></span><br></pre></td></tr></table></figure><h3 id="Evaluation">Evaluation</h3><p>我们来看一下这个线性模型在螺旋数据上的表现如何。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_fscore_support</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_metrics</span>(<span class="params">y_true, y_pred, classes</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Per-class performance metrics.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Performance</span></span><br><span class="line">    performance = &#123;<span class="string">&quot;overall&quot;</span>: &#123;&#125;, <span class="string">&quot;class&quot;</span>: &#123;&#125;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Overall performance</span></span><br><span class="line">    metrics = precision_recall_fscore_support(y_true, y_pred, average=<span class="string">&quot;weighted&quot;</span>)</span><br><span class="line">    performance[<span class="string">&quot;overall&quot;</span>][<span class="string">&quot;precision&quot;</span>] = metrics[<span class="number">0</span>]</span><br><span class="line">    performance[<span class="string">&quot;overall&quot;</span>][<span class="string">&quot;recall&quot;</span>] = metrics[<span class="number">1</span>]</span><br><span class="line">    performance[<span class="string">&quot;overall&quot;</span>][<span class="string">&quot;f1&quot;</span>] = metrics[<span class="number">2</span>]</span><br><span class="line">    performance[<span class="string">&quot;overall&quot;</span>][<span class="string">&quot;num_samples&quot;</span>] = np.float64(<span class="built_in">len</span>(y_true))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Per-class performance</span></span><br><span class="line">    metrics = precision_recall_fscore_support(y_true, y_pred, average=<span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(classes)):</span><br><span class="line">        performance[<span class="string">&quot;class&quot;</span>][classes[i]] = &#123;</span><br><span class="line">            <span class="string">&quot;precision&quot;</span>: metrics[<span class="number">0</span>][i],</span><br><span class="line">            <span class="string">&quot;recall&quot;</span>: metrics[<span class="number">1</span>][i],</span><br><span class="line">            <span class="string">&quot;f1&quot;</span>: metrics[<span class="number">2</span>][i],</span><br><span class="line">            <span class="string">&quot;num_samples&quot;</span>: np.float64(metrics[<span class="number">3</span>][i]),</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> performance</span><br><span class="line"></span><br><span class="line"><span class="comment"># Predictions</span></span><br><span class="line">y_prob = F.softmax(model(X_test), dim=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;sample probability: <span class="subst">&#123;y_prob[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line">y_pred = y_prob.<span class="built_in">max</span>(dim=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;sample class: <span class="subst">&#123;y_pred[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># sample probability: tensor([0.3424, 0.0918, 0.5659], grad_fn=&lt;SelectBackward0&gt;)</span></span><br><span class="line"><span class="comment"># sample class: 2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Performance</span></span><br><span class="line">performance = get_metrics(y_true=y_test, y_pred=y_pred, classes=classes)</span><br><span class="line"><span class="built_in">print</span> (json.dumps(performance, indent=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &#123;</span></span><br><span class="line"><span class="comment">#   &quot;overall&quot;: &#123;</span></span><br><span class="line"><span class="comment">#     &quot;precision&quot;: 0.5174825174825175,</span></span><br><span class="line"><span class="comment">#     &quot;recall&quot;: 0.5155555555555555,</span></span><br><span class="line"><span class="comment">#     &quot;f1&quot;: 0.5162093875662788,</span></span><br><span class="line"><span class="comment">#     &quot;num_samples&quot;: 225.0</span></span><br><span class="line"><span class="comment">#   &#125;,</span></span><br><span class="line"><span class="comment">#   &quot;class&quot;: &#123;</span></span><br><span class="line"><span class="comment">#     &quot;c1&quot;: &#123;</span></span><br><span class="line"><span class="comment">#       &quot;precision&quot;: 0.5194805194805194,</span></span><br><span class="line"><span class="comment">#       &quot;recall&quot;: 0.5333333333333333,</span></span><br><span class="line"><span class="comment">#       &quot;f1&quot;: 0.5263157894736841,</span></span><br><span class="line"><span class="comment">#       &quot;num_samples&quot;: 75.0</span></span><br><span class="line"><span class="comment">#     &#125;,</span></span><br><span class="line"><span class="comment">#     &quot;c2&quot;: &#123;</span></span><br><span class="line"><span class="comment">#       &quot;precision&quot;: 0.46153846153846156,</span></span><br><span class="line"><span class="comment">#       &quot;recall&quot;: 0.48,</span></span><br><span class="line"><span class="comment">#       &quot;f1&quot;: 0.47058823529411764,</span></span><br><span class="line"><span class="comment">#       &quot;num_samples&quot;: 75.0</span></span><br><span class="line"><span class="comment">#     &#125;,</span></span><br><span class="line"><span class="comment">#     &quot;c3&quot;: &#123;</span></span><br><span class="line"><span class="comment">#       &quot;precision&quot;: 0.5714285714285714,</span></span><br><span class="line"><span class="comment">#       &quot;recall&quot;: 0.5333333333333333,</span></span><br><span class="line"><span class="comment">#       &quot;f1&quot;: 0.5517241379310344,</span></span><br><span class="line"><span class="comment">#       &quot;num_samples&quot;: 75.0</span></span><br><span class="line"><span class="comment">#     &#125;</span></span><br><span class="line"><span class="comment">#   &#125;</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_multiclass_decision_boundary</span>(<span class="params">model, X, y</span>):</span><br><span class="line">    x_min, x_max = X[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">0.1</span>, X[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">0.1</span></span><br><span class="line">    y_min, y_max = X[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">0.1</span>, X[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">0.1</span></span><br><span class="line">    xx, yy = np.meshgrid(np.linspace(x_min, x_max, <span class="number">101</span>), np.linspace(y_min, y_max, <span class="number">101</span>))</span><br><span class="line">    cmap = plt.cm.Spectral</span><br><span class="line"></span><br><span class="line">    X_test = torch.from_numpy(np.c_[xx.ravel(), yy.ravel()]).<span class="built_in">float</span>()</span><br><span class="line">    y_pred = F.softmax(model(X_test), dim=<span class="number">1</span>)</span><br><span class="line">    _, y_pred = y_pred.<span class="built_in">max</span>(dim=<span class="number">1</span>)</span><br><span class="line">    y_pred = y_pred.reshape(xx.shape)</span><br><span class="line">    plt.contourf(xx, yy, y_pred, cmap=plt.cm.Spectral, alpha=<span class="number">0.8</span>)</span><br><span class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, s=<span class="number">40</span>, cmap=plt.cm.RdYlBu)</span><br><span class="line">    plt.xlim(xx.<span class="built_in">min</span>(), xx.<span class="built_in">max</span>())</span><br><span class="line">    plt.ylim(yy.<span class="built_in">min</span>(), yy.<span class="built_in">max</span>())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Visualize the decision boundary</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">5</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Train&quot;</span>)</span><br><span class="line">plot_multiclass_decision_boundary(model=model, X=X_train, y=y_train)</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Test&quot;</span>)</span><br><span class="line">plot_multiclass_decision_boundary(model=model, X=X_test, y=y_test)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="//s3.mindex.xyz/blog/Courses/e722233774a0fd9b91f4d77a3068287d.png" alt=""></p><h2 id="Activation-functions">Activation functions</h2><p>使用广义的线性方法产生了较差的结果，因为我们试图用线性激活函数去学习非线性数据。</p><p>所以我们需要一个可以能让模型学习到数据中的非线性的激活函数。有几种不同的选择，我们稍微探索一下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Fig size</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data</span></span><br><span class="line">x = torch.arange(-<span class="number">5.</span>, <span class="number">5.</span>, <span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Sigmoid activation (constrain a value between 0 and 1.)</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Sigmoid activation&quot;</span>)</span><br><span class="line">y = torch.sigmoid(x)</span><br><span class="line">plt.plot(x.numpy(), y.numpy())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Tanh activation (constrain a value between -1 and 1.)</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">y = torch.tanh(x)</span><br><span class="line">plt.title(<span class="string">&quot;Tanh activation&quot;</span>)</span><br><span class="line">plt.plot(x.numpy(), y.numpy())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Relu (clip the negative values to 0)</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">y = F.relu(x)</span><br><span class="line">plt.title(<span class="string">&quot;ReLU activation&quot;</span>)</span><br><span class="line">plt.plot(x.numpy(), y.numpy())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show plots</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="//s3.mindex.xyz/blog/Courses/499e55bee0461d4b7471247d91ec78b1.png" alt=""></p><p>ReLU激活函数$(max(0, z))$ 是目前为止用的最广泛的激活函数。但每个激活函数都有自己适用场景。比如：如果我们需要输出在0和1之间，那么sigmoid是合适的选择。</p><p>*（在某些情况下，ReLU函数也是不够的。例如，当神经元的输出大多为负时，激活函数的输出为0，这将导致神经元“死去”。为了减轻这种影响，我们可以降低学习率活着使用<a href="https://medium.com/@danqing/a-practical-guide-to-relu-b83ca804f1f7" title="ReLU">“ReLU变种”</a>。 如 Leaky ReLU 或 PRelu，它们会适当倾斜于神经元的负输出。）</p><h2 id="NumPy">NumPy</h2><p>现在，我们创建一个与逻辑回归模型完全相似的多层感知机，但包含一个学习数据中非线性的激活函数。</p><h3 id="Initialize-weights">Initialize weights</h3><p><strong>第一步</strong>: 随机初始化模型的权重$W$。（后面会介绍更有效的初始化策略）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Initialize first layer&#x27;s weights</span></span><br><span class="line">W1 = <span class="number">0.01</span> * np.random.randn(INPUT_DIM, HIDDEN_DIM)</span><br><span class="line">b1 = np.zeros((<span class="number">1</span>, HIDDEN_DIM))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;W1: <span class="subst">&#123;W1.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;b1: <span class="subst">&#123;b1.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># W1: (2, 100)</span></span><br><span class="line"><span class="comment"># b1: (1, 100)</span></span><br></pre></td></tr></table></figure><h3 id="Model">Model</h3><p><strong>第二步</strong>: 讲输入 $X$ 送到模型中进行前向传播以得到网络的输出。</p><p>首先，我们将输入传给第一层。<br>$$<br>z_1 = XW_1<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># z1 = [NX2] · [2X100] + [1X100] = [NX100]</span></span><br><span class="line">z1 = np.dot(X_train, W1) + b1</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;z1: <span class="subst">&#123;z1.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># z1: (1050, 100)</span></span><br></pre></td></tr></table></figure><p>接下来，我们应用非线性激活函数Relu。<br>$$<br>a_1 = f(z_1)<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Apply activation function</span></span><br><span class="line">a1 = np.maximum(<span class="number">0</span>, z1) <span class="comment"># ReLU</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;a_1: <span class="subst">&#123;a1.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># a_1: (1050, 100)</span></span><br></pre></td></tr></table></figure><p>然着我们将激活函数的输出传给第二层，以获得logit。<br>$$<br>z_2 = a_1W_2<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Initialize second layer&#x27;s weights</span></span><br><span class="line">W2 = <span class="number">0.01</span> * np.random.randn(HIDDEN_DIM, NUM_CLASSES)</span><br><span class="line">b2 = np.zeros((<span class="number">1</span>, NUM_CLASSES))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;W2: <span class="subst">&#123;W2.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;b2: <span class="subst">&#123;b2.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># W2: (100, 3)</span></span><br><span class="line"><span class="comment"># b2: (1, 3)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># z2 = logits = [NX100] · [100X3] + [1X3] = [NX3]</span></span><br><span class="line">logits = np.dot(a1, W2) + b2</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;logits: <span class="subst">&#123;logits.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;sample: <span class="subst">&#123;logits[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># logits: (1050, 3)</span></span><br><span class="line"><span class="comment"># sample: [ 0.00017606 -0.0023457   0.00035913]</span></span><br></pre></td></tr></table></figure><p>之后，我们将应用softmax来获得网络的概率输出。</p><p>$$<br>\hat{y} = softmax(z_2)<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Normalization via softmax to obtain class probabilities</span></span><br><span class="line">exp_logits = np.exp(logits)</span><br><span class="line">y_hat = exp_logits / np.<span class="built_in">sum</span>(exp_logits, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;y_hat: <span class="subst">&#123;y_hat.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;sample: <span class="subst">&#123;y_hat[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># y_hat: (1050, 3)</span></span><br><span class="line"><span class="comment"># sample: [0.33359304 0.33275285 0.33365411]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="Loss">Loss</h3><p><strong>第三步</strong>： 利用交叉熵计算我们分类任务的损失。<br>$$<br>J(\theta) = - \sum_i^K{log(\hat{y}_i)} = - \sum_i^K{log(\frac{e^{W_yX_i}}{\sum_j{e^{WX_i}}})}\\<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Loss</span></span><br><span class="line">correct_class_logprobs = -np.log(y_hat[<span class="built_in">range</span>(<span class="built_in">len</span>(y_hat)), y_train])</span><br><span class="line">loss = np.<span class="built_in">sum</span>(correct_class_logprobs) / <span class="built_in">len</span>(y_train)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;loss: <span class="subst">&#123;loss:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># loss: 1.10</span></span><br></pre></td></tr></table></figure><h3 id="Gradients">Gradients</h3><p><strong>第四步</strong> 计算损失函数 $J(\theta)$ 相对于权重的梯度。</p><p>对于$W_2$的梯度，与前篇逻辑回归的梯度相同，因为 $\hat{y} = softmax(z_2)$</p><p>$$<br>\begin{split}<br>\frac{\partial{J}}{\partial{W_{2j}}} &amp;= \frac{\partial{J}}{\partial{\hat{y}}} \frac{\partial{\hat{y}}}{\partial{W_{2j}}}  \\<br>&amp;= - \frac{1}{\hat{y}} \frac{\partial{\hat{y}}}{\partial{W_{2j}}} \\<br>&amp;= - \frac{1}{\frac{e^{a_1 W_{2y}}}{\sum_j{e^{a_1 W}}}} \frac{\sum_j{e^{a_1 W}e^{a_1 W_{2y}} 0 - e^{a_1 W_{2y}} e^{a_1 W_{2j}} a_1 }}{(\sum_j{e^{a_1 W}})^2} \\<br>&amp;= \frac{a_1 e^{a_1 W_{2j}}}{\sum_j{e^{a_1 W}}} \\<br>&amp;= a_1 \hat{y}<br>\end{split}<br>$$</p><p>$$<br>\begin{split}<br>\frac{\partial{J}}{\partial{W_{2y}}} &amp;= \frac{\partial{J}}{\partial{\hat{y}}} \frac{\partial{\hat{y}}}{\partial{W_{2y}}}  \\<br>&amp;= - \frac{1}{\hat{y}} \frac{\partial{\hat{y}}}{\partial{W_{2y}}} \\<br>&amp;= - \frac{1}{\frac{e^{a_1 W_{2y}}}{\sum_j{e^{a_1 W}}}} \frac{\sum_j{e^{a_1 W}e^{a_1 W_{2y}} a_1 - e^{W_{2y} a_1}e^{a_1 W_{2y}} a_1}}{(\sum_j{e^{a_1 W}})^2} = \frac{1}{\hat{y}} (a_1 \hat{y}^2 - a_1 \hat{y}) \\<br>&amp;= a_1 (\hat{y} - 1)<br>\end{split}<br>$$</p><p>对于 $W_1$ 的梯度计算有点棘手，因为我们必须要通过两组权重进行反向传播。</p><p>$$<br>\begin{split}<br>\frac{\partial{J}}{\partial{W_1}} &amp;= \frac{\partial{J}}{\partial{\hat{y}}} \frac{\partial{\hat{y}}}{\partial{X}} \frac{\partial{X}}{\partial{z_1}}  \frac{\partial{z_1}}{\partial{W_1}} \\<br>&amp;= W_2 (\partial{\hat{y}})(\partial{ReLU})X<br>\end{split}<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dJ/dW2</span></span><br><span class="line">dscores = y_hat</span><br><span class="line">dscores[<span class="built_in">range</span>(<span class="built_in">len</span>(y_hat)), y_train] -= <span class="number">1</span></span><br><span class="line">dscores /= <span class="built_in">len</span>(y_train)</span><br><span class="line">dW2 = np.dot(a1.T, dscores)</span><br><span class="line">db2 = np.<span class="built_in">sum</span>(dscores, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># dJ/dW1</span></span><br><span class="line">dhidden = np.dot(dscores, W2.T)</span><br><span class="line">dhidden[a1 &lt;= <span class="number">0</span>] = <span class="number">0</span> <span class="comment"># ReLu backprop</span></span><br><span class="line">dW1 = np.dot(X_train.T, dhidden)</span><br><span class="line">db1 = np.<span class="built_in">sum</span>(dhidden, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="Update-weights">Update weights</h3><p><strong>第五步</strong> 指定一个学习率来更新权重 $W$，惩罚错误的分类奖励正确的分类。<br>$$<br>W_i = W_i - \alpha \frac{\partial{J}}{\partial{W_i}}<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Update weights</span></span><br><span class="line">W1 += -LEARNING_RATE * dW1</span><br><span class="line">b1 += -LEARNING_RATE * db1</span><br><span class="line">W2 += -LEARNING_RATE * dW2</span><br><span class="line">b2 += -LEARNING_RATE * db2</span><br></pre></td></tr></table></figure><h3 id="Training">Training</h3><p><strong>第六步</strong>: 重复步骤 2 ~ 5，以最小化损失为目的来训练模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Convert tensors to NumPy arrays</span></span><br><span class="line">X_train = X_train.numpy()</span><br><span class="line">y_train = y_train.numpy()</span><br><span class="line">X_val = X_val.numpy()</span><br><span class="line">y_val = y_val.numpy()</span><br><span class="line">X_test = X_test.numpy()</span><br><span class="line">y_test = y_test.numpy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize random weights</span></span><br><span class="line">W1 = <span class="number">0.01</span> * np.random.randn(INPUT_DIM, HIDDEN_DIM)</span><br><span class="line">b1 = np.zeros((<span class="number">1</span>, HIDDEN_DIM))</span><br><span class="line">W2 = <span class="number">0.01</span> * np.random.randn(HIDDEN_DIM, NUM_CLASSES)</span><br><span class="line">b2 = np.zeros((<span class="number">1</span>, NUM_CLASSES))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training loop</span></span><br><span class="line"><span class="keyword">for</span> epoch_num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># First layer forward pass [NX2] · [2X100] = [NX100]</span></span><br><span class="line">    z1 = np.dot(X_train, W1) + b1</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Apply activation function</span></span><br><span class="line">    a1 = np.maximum(<span class="number">0</span>, z1) <span class="comment"># ReLU</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># z2 = logits = [NX100] · [100X3] = [NX3]</span></span><br><span class="line">    logits = np.dot(a1, W2) + b2</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Normalization via softmax to obtain class probabilities</span></span><br><span class="line">    exp_logits = np.exp(logits)</span><br><span class="line">    y_hat = exp_logits / np.<span class="built_in">sum</span>(exp_logits, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Loss</span></span><br><span class="line">    correct_class_logprobs = -np.log(y_hat[<span class="built_in">range</span>(<span class="built_in">len</span>(y_hat)), y_train])</span><br><span class="line">    loss = np.<span class="built_in">sum</span>(correct_class_logprobs) / <span class="built_in">len</span>(y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># show progress</span></span><br><span class="line">    <span class="keyword">if</span> epoch_num%<span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># Accuracy</span></span><br><span class="line">        y_pred = np.argmax(logits, axis=<span class="number">1</span>)</span><br><span class="line">        accuracy =  np.mean(np.equal(y_train, y_pred))</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch_num&#125;</span>, loss: <span class="subst">&#123;loss:<span class="number">.3</span>f&#125;</span>, accuracy: <span class="subst">&#123;accuracy:<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># dJ/dW2</span></span><br><span class="line">    dscores = y_hat</span><br><span class="line">    dscores[<span class="built_in">range</span>(<span class="built_in">len</span>(y_hat)), y_train] -= <span class="number">1</span></span><br><span class="line">    dscores /= <span class="built_in">len</span>(y_train)</span><br><span class="line">    dW2 = np.dot(a1.T, dscores)</span><br><span class="line">    db2 = np.<span class="built_in">sum</span>(dscores, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># dJ/dW1</span></span><br><span class="line">    dhidden = np.dot(dscores, W2.T)</span><br><span class="line">    dhidden[a1 &lt;= <span class="number">0</span>] = <span class="number">0</span> <span class="comment"># ReLu backprop</span></span><br><span class="line">    dW1 = np.dot(X_train.T, dhidden)</span><br><span class="line">    db1 = np.<span class="built_in">sum</span>(dhidden, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights</span></span><br><span class="line">    W1 += -<span class="number">1e0</span> * dW1</span><br><span class="line">    b1 += -<span class="number">1e0</span> * db1</span><br><span class="line">    W2 += -<span class="number">1e0</span> * dW2</span><br><span class="line">    b2 += -<span class="number">1e0</span> * db2</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Epoch: 0, loss: 1.098, accuracy: 0.519</span></span><br><span class="line"><span class="comment"># Epoch: 100, loss: 0.541, accuracy: 0.680</span></span><br><span class="line"><span class="comment"># Epoch: 200, loss: 0.305, accuracy: 0.893</span></span><br><span class="line"><span class="comment"># Epoch: 300, loss: 0.135, accuracy: 0.951</span></span><br><span class="line"><span class="comment"># Epoch: 400, loss: 0.091, accuracy: 0.976</span></span><br><span class="line"><span class="comment"># Epoch: 500, loss: 0.069, accuracy: 0.984</span></span><br><span class="line"><span class="comment"># Epoch: 600, loss: 0.056, accuracy: 0.989</span></span><br><span class="line"><span class="comment"># Epoch: 700, loss: 0.048, accuracy: 0.991</span></span><br><span class="line"><span class="comment"># Epoch: 800, loss: 0.043, accuracy: 0.994</span></span><br><span class="line"><span class="comment"># Epoch: 900, loss: 0.039, accuracy: 0.994</span></span><br></pre></td></tr></table></figure><h3 id="Evaluation-2">Evaluation</h3><p>在测试集上评估这个模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MLPFromScratch</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, x</span>):</span><br><span class="line">        z1 = np.dot(x, W1) + b1</span><br><span class="line">        a1 = np.maximum(<span class="number">0</span>, z1)</span><br><span class="line">        logits = np.dot(a1, W2) + b2</span><br><span class="line">        exp_logits = np.exp(logits)</span><br><span class="line">        y_hat = exp_logits / np.<span class="built_in">sum</span>(exp_logits, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> y_hat</span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluation</span></span><br><span class="line">model = MLPFromScratch()</span><br><span class="line">y_prob = model.predict(X_test)</span><br><span class="line">y_pred = np.argmax(y_prob, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># # Performance</span></span><br><span class="line">performance = get_metrics(y_true=y_test, y_pred=y_pred, classes=classes)</span><br><span class="line"><span class="built_in">print</span> (json.dumps(performance, indent=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &#123;</span></span><br><span class="line"><span class="comment">#   &quot;overall&quot;: &#123;</span></span><br><span class="line"><span class="comment">#     &quot;precision&quot;: 0.9826749826749827,</span></span><br><span class="line"><span class="comment">#     &quot;recall&quot;: 0.9822222222222222,</span></span><br><span class="line"><span class="comment">#     &quot;f1&quot;: 0.9822481383871041,</span></span><br><span class="line"><span class="comment">#     &quot;num_samples&quot;: 225.0</span></span><br><span class="line"><span class="comment">#   &#125;,</span></span><br><span class="line"><span class="comment">#   &quot;class&quot;: &#123;</span></span><br><span class="line"><span class="comment">#     &quot;c1&quot;: &#123;</span></span><br><span class="line"><span class="comment">#       &quot;precision&quot;: 1.0,</span></span><br><span class="line"><span class="comment">#       &quot;recall&quot;: 0.9733333333333334,</span></span><br><span class="line"><span class="comment">#       &quot;f1&quot;: 0.9864864864864865,</span></span><br><span class="line"><span class="comment">#       &quot;num_samples&quot;: 75.0</span></span><br><span class="line"><span class="comment">#     &#125;,</span></span><br><span class="line"><span class="comment">#     &quot;c2&quot;: &#123;</span></span><br><span class="line"><span class="comment">#       &quot;precision&quot;: 0.9615384615384616,</span></span><br><span class="line"><span class="comment">#       &quot;recall&quot;: 1.0,</span></span><br><span class="line"><span class="comment">#       &quot;f1&quot;: 0.9803921568627451,</span></span><br><span class="line"><span class="comment">#       &quot;num_samples&quot;: 75.0</span></span><br><span class="line"><span class="comment">#     &#125;,</span></span><br><span class="line"><span class="comment">#     &quot;c3&quot;: &#123;</span></span><br><span class="line"><span class="comment">#       &quot;precision&quot;: 0.9864864864864865,</span></span><br><span class="line"><span class="comment">#       &quot;recall&quot;: 0.9733333333333334,</span></span><br><span class="line"><span class="comment">#       &quot;f1&quot;: 0.9798657718120806,</span></span><br><span class="line"><span class="comment">#       &quot;num_samples&quot;: 75.0</span></span><br><span class="line"><span class="comment">#     &#125;</span></span><br><span class="line"><span class="comment">#   &#125;</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_multiclass_decision_boundary_numpy</span>(<span class="params">model, X, y, savefig_fp=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Plot the multiclass decision boundary for a model that accepts 2D inputs.</span></span><br><span class="line"><span class="string">    Credit: https://cs231n.github.io/neural-networks-case-study/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">        model &#123;function&#125; -- trained model with function model.predict(x_in).</span></span><br><span class="line"><span class="string">        X &#123;numpy.ndarray&#125; -- 2D inputs with shape (N, 2).</span></span><br><span class="line"><span class="string">        y &#123;numpy.ndarray&#125; -- 1D outputs with shape (N,).</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Axis boundaries</span></span><br><span class="line">    x_min, x_max = X[:, <span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">0.1</span>, X[:, <span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">0.1</span></span><br><span class="line">    y_min, y_max = X[:, <span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">0.1</span>, X[:, <span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">0.1</span></span><br><span class="line">    xx, yy = np.meshgrid(np.linspace(x_min, x_max, <span class="number">101</span>),</span><br><span class="line">                         np.linspace(y_min, y_max, <span class="number">101</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create predictions</span></span><br><span class="line">    x_in = np.c_[xx.ravel(), yy.ravel()]</span><br><span class="line">    y_pred = model.predict(x_in)</span><br><span class="line">    y_pred = np.argmax(y_pred, axis=<span class="number">1</span>).reshape(xx.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Plot decision boundary</span></span><br><span class="line">    plt.contourf(xx, yy, y_pred, cmap=plt.cm.Spectral, alpha=<span class="number">0.8</span>)</span><br><span class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, s=<span class="number">40</span>, cmap=plt.cm.RdYlBu)</span><br><span class="line">    plt.xlim(xx.<span class="built_in">min</span>(), xx.<span class="built_in">max</span>())</span><br><span class="line">    plt.ylim(yy.<span class="built_in">min</span>(), yy.<span class="built_in">max</span>())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Plot</span></span><br><span class="line">    <span class="keyword">if</span> savefig_fp:</span><br><span class="line">        plt.savefig(savefig_fp, <span class="built_in">format</span>=<span class="string">&quot;png&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Visualize the decision boundary</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">5</span>))</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Train&quot;</span>)</span><br><span class="line">plot_multiclass_decision_boundary_numpy(model=model, X=X_train, y=y_train)</span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Test&quot;</span>)</span><br><span class="line">plot_multiclass_decision_boundary_numpy(model=model, X=X_test, y=y_test)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="//s3.mindex.xyz/blog/Courses/0878670f7a00ef84e2037f39161b6fa5.png" alt=""></p><h2 id="Ending">Ending</h2><p>神经网络是机器学习和人工智能领域的基础，我们必须彻底掌握。</p><h2 id="Citation">Citation</h2><figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="language-xml">@article</span><span class="template-variable">&#123;madewithml,</span></span><br><span class="line"><span class="template-variable">    author       = &#123;Goku Mohandas&#125;</span><span class="language-xml">,</span></span><br><span class="line"><span class="language-xml">    title        = </span><span class="template-variable">&#123; Neural networks - Made With ML &#125;</span><span class="language-xml">,</span></span><br><span class="line"><span class="language-xml">    howpublished = </span><span class="template-variable">&#123;\url&#123;https://madewithml.com/&#125;</span><span class="language-xml">&#125;,</span></span><br><span class="line"><span class="language-xml">    year         = </span><span class="template-variable">&#123;2022&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">&#125;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      Numpy实现一个神经网络。
    
    </summary>
    
    
      <category term="Way2AI" scheme="https://neo1989.net/categories/Way2AI/"/>
    
    
      <category term="Coder" scheme="https://neo1989.net/tags/Coder/"/>
    
      <category term="AI" scheme="https://neo1989.net/tags/AI/"/>
    
      <category term="PyTorch" scheme="https://neo1989.net/tags/PyTorch/"/>
    
  </entry>
  
</feed>
