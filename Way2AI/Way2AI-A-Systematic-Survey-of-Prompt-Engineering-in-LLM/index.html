<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="我读书少，你莫骗我。"><title>Way2AI · Prompt Engineering 概述 | 愚苏记</title><link rel="stylesheet" type="text/css" href="https://cdn.staticfile.org/lxgw-wenkai-webfont/1.6.0/style.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="/lib/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="/lib/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="/lib/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="/lib/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="/lib/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + '96c862f2728296588ae9849f3bcb95db';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();</script><link rel="alternate" type="application/atom+xml" href="/atom.xml"><meta name="generator" content="Hexo 7.1.1"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Way2AI · Prompt Engineering 概述</h1><a id="logo" href="/.">愚苏记</a><p class="description">To no avail but try.</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-4-4"><div class="content_container no-padding-right"><div class="post"><h1 class="post-title">Way2AI · Prompt Engineering 概述</h1><div class="post-meta">Mar 14, 2024<span> | </span><span class="category"><a href="/categories/Way2AI/">Way2AI</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 4.9k</span><span class="post-meta-item-text"> Words</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 17</span><span class="post-meta-item-text"> Minutes</span></span></span></div><a class="disqus-comment-count" data-disqus-identifier="Way2AI/Way2AI-A-Systematic-Survey-of-Prompt-Engineering-in-LLM/" href="/Way2AI/Way2AI-A-Systematic-Survey-of-Prompt-Engineering-in-LLM/#disqus_thread"></a><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">Contents</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Prompt-Engineering"><span class="toc-number">1.</span> <span class="toc-text">Prompt Engineering</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#New-Tasks-Without-Extensive-Training"><span class="toc-number">1.1.</span> <span class="toc-text">New Tasks Without Extensive Training</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Zero-Shot-Prompting"><span class="toc-number">1.1.1.</span> <span class="toc-text">Zero-Shot Prompting</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Few-Shot-Prompting"><span class="toc-number">1.1.2.</span> <span class="toc-text">Few-Shot Prompting</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reasoning-and-Logic"><span class="toc-number">1.2.</span> <span class="toc-text">Reasoning and Logic</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Chain-of-Thought-CoT-Prompting"><span class="toc-number">1.2.1.</span> <span class="toc-text">Chain-of-Thought (CoT) Prompting</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Automatic-Chain-of-Thought-Auto-CoT-Prompting"><span class="toc-number">1.2.2.</span> <span class="toc-text">Automatic Chain-of-Thought (Auto-CoT) Prompting</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Self-Consistency"><span class="toc-number">1.2.3.</span> <span class="toc-text">Self-Consistency</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Logical-Chain-of-Thought-LogiCoT-Prompting"><span class="toc-number">1.2.4.</span> <span class="toc-text">Logical Chain-of-Thought (LogiCoT) Prompting</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Chain-of-Symbol-CoS-Prompting"><span class="toc-number">1.2.5.</span> <span class="toc-text">Chain-of-Symbol (CoS) Prompting</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Tree-of-Thoughts-ToT-Prompting"><span class="toc-number">1.2.6.</span> <span class="toc-text">Tree-of-Thoughts (ToT) Prompting</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Graph-of-Thoughts-GoT-Prompting"><span class="toc-number">1.2.7.</span> <span class="toc-text">Graph-of-Thoughts (GoT) Prompting</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#System-2-Attention-S2A-Prompting"><span class="toc-number">1.2.8.</span> <span class="toc-text">System 2 Attention (S2A) Prompting</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Thread-of-Thought-ThoT-Prompting"><span class="toc-number">1.2.9.</span> <span class="toc-text">Thread of Thought (ThoT) Prompting</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Chain-of-Table-Prompting"><span class="toc-number">1.2.10.</span> <span class="toc-text">Chain-of-Table Prompting</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reduce-Hallucination"><span class="toc-number">1.3.</span> <span class="toc-text">Reduce Hallucination</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Retrieval-Augmented-Generation-RAG"><span class="toc-number">1.3.1.</span> <span class="toc-text">Retrieval Augmented Generation (RAG)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ReAct-Prompting"><span class="toc-number">1.3.2.</span> <span class="toc-text">ReAct Prompting</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Chain-of-Verification-CoVe-Prompting"><span class="toc-number">1.3.3.</span> <span class="toc-text">Chain-of-Verification (CoVe) Prompting</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Chain-of-Note-CoN-Prompting"><span class="toc-number">1.3.4.</span> <span class="toc-text">Chain-of-Note (CoN) Prompting</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Chain-of-Knowledge-CoK-Prompting"><span class="toc-number">1.3.5.</span> <span class="toc-text">Chain-of-Knowledge (CoK) Prompting</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#User-Interface"><span class="toc-number">1.4.</span> <span class="toc-text">User Interface</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Active-Prompting"><span class="toc-number">1.4.1.</span> <span class="toc-text">Active Prompting</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Fine-Tuning-and-Optimization"><span class="toc-number">1.5.</span> <span class="toc-text">Fine-Tuning and Optimization</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Automatic-Prompt-Engineer-APE"><span class="toc-number">1.5.1.</span> <span class="toc-text">Automatic Prompt Engineer (APE)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Knowledge-Based-Reasoning-and-Generation"><span class="toc-number">1.6.</span> <span class="toc-text">Knowledge-Based Reasoning and Generation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Automatic-Reasoning-and-Tool-use-ART"><span class="toc-number">1.6.1.</span> <span class="toc-text">Automatic Reasoning and Tool-use (ART)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Improving-Consistency-and-Coherence"><span class="toc-number">1.7.</span> <span class="toc-text">Improving Consistency and Coherence</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Contrastive-Chain-of-Thought-CCoT-Prompting"><span class="toc-number">1.7.1.</span> <span class="toc-text">Contrastive Chain-of-Thought (CCoT) Prompting</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Managing-Emotions-and-Tone"><span class="toc-number">1.8.</span> <span class="toc-text">Managing Emotions and Tone</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Emotion-Prompting"><span class="toc-number">1.8.1.</span> <span class="toc-text">Emotion Prompting</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Code-Generation-and-Execution"><span class="toc-number">1.9.</span> <span class="toc-text">Code Generation and Execution</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Scratchpad-Prompting"><span class="toc-number">1.9.1.</span> <span class="toc-text">Scratchpad Prompting</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Program-of-Thoughts-PoT-Prompting"><span class="toc-number">1.9.2.</span> <span class="toc-text">Program of Thoughts (PoT) Prompting</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Structured-Chain-of-Thought-SCoT-Prompting"><span class="toc-number">1.9.3.</span> <span class="toc-text">Structured Chain-of-Thought (SCoT) Prompting</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Chain-of-Code-CoC-Prompting"><span class="toc-number">1.9.4.</span> <span class="toc-text">Chain-of-Code (CoC) Prompting</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Optimization-and-Efficiency"><span class="toc-number">1.10.</span> <span class="toc-text">Optimization and Efficiency</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Optimization-by-Prompting-OPRO"><span class="toc-number">1.10.1.</span> <span class="toc-text">Optimization by Prompting (OPRO)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Understanding-User-Intent"><span class="toc-number">1.11.</span> <span class="toc-text">Understanding User Intent</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Rephrase-and-Respond-RaR-Prompting"><span class="toc-number">1.11.1.</span> <span class="toc-text">Rephrase and Respond (RaR) Prompting</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Metacognition-and-Self-Reflection"><span class="toc-number">1.12.</span> <span class="toc-text">Metacognition and Self-Reflection</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Take-a-Step-Back-Prompting"><span class="toc-number">1.12.1.</span> <span class="toc-text">Take a Step Back Prompting</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conclusion"><span class="toc-number">2.</span> <span class="toc-text">Conclusion</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Source"><span class="toc-number">3.</span> <span class="toc-text">Source</span></a></li></ol></div></div><div class="post-content"><h2 id="Prompt-Engineering">Prompt Engineering</h2>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><p>按应用领域进行分类，简要概述提示技术的发展历程，从最初的零样本提示技术，一直到现在的最新进展。</p>
<h3 id="New-Tasks-Without-Extensive-Training">New Tasks Without Extensive Training</h3>
<h4 id="Zero-Shot-Prompting">Zero-Shot Prompting</h4>
<p>零样本提示为我们如何利用大语言模型（LLM）提供了全新的视角。这种技术无需依赖大量的训练数据，而是通过精心设计的提示，引导模型去完成前所未有的任务。具体的说，模型在提示中接收到了任务的描述，但并没有标注数据来训练特定的输入-输出映射。然后，模型就会利用自身已有的知识，根据给定的提示为新任务生成预测。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/bd6a40576eb18f2c0337d0ec2145ee19.png" alt=""></p>
<h4 id="Few-Shot-Prompting">Few-Shot Prompting</h4>
<p>少样本引导是通过提供一些输入-输出示例，帮助模型理解特定任务的一种方法，这与零样本引导（不提供任何示例）有所不同。即便只提供少数几个高质量的示例，也已经能够在一定程度上提升模型在复杂任务上的表现。</p>
<p>然而，少样本引导需要额外的 Token 来包含这些示例，对于更长的文本输入来说，可能会带来一些处理上的困难。<br>
此外，提示示例的选取和组织方式对模型的行为有着显著影响，例如模型可能会倾向于选择使用频率较高的词汇，这种偏见可能会影响少样本引导的结果。</p>
<p>尽管少样本引导能够增强处理复杂任务的能力，特别是在像 GPT-3 这样的大型预训练模型中，但是，精心设计的引导策略对于实现最佳性能和减少模型的无意识偏见至关重要。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/144b4f22e7e1afc18d1e55de3e7bd4f1.png" alt=""></p>
<h3 id="Reasoning-and-Logic">Reasoning and Logic</h3>
<h4 id="Chain-of-Thought-CoT-Prompting">Chain-of-Thought (CoT) Prompting</h4>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2201.11903" title="CoT">CoT</a> 提示能够更有效地引导大语言模型产生结构化且深思熟虑的回应。我们通过一系列的实验，展示了CoT提示的独特优势，强调了它能够引导大语言模型按照逻辑链条进行推理的能力。这种方式使得模型的回应展现出对给定提示更深入的理解。例如，对于一个需要多步推理的数学文字题目，CoT提示能够呈现出整个推理过程和最终答案，这仿佛就像人类如何将问题分解为逻辑中间步骤一样。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/cc23793ec5adae2dc2c1a38b23fff338.png" alt=""></p>
<h4 id="Automatic-Chain-of-Thought-Auto-CoT-Prompting">Automatic Chain-of-Thought (Auto-CoT) Prompting</h4>
<p>“Let’s think step by step”， 自动引导大语言模型（LLMs）形成推理链。<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2210.03493" title="Auto-CoT">Auto-CoT</a> 注意到在单独生成的推理链中可能会出现错误，因此采取了多样化采样的策略以提高模型的鲁棒性。它会提出各种各样的问题，并为每个问题生成多个不同的推理链，从而形成一个最终的示例集。这种自动化的多样化采样策略可以最大限度地减少错误，同时提高了少样本（few-shot）学习的效果，免去了手动制作推理链的繁重工作。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/697f3251c2e47a8c25d89b959fa931eb.png" alt=""></p>
<h4 id="Self-Consistency">Self-Consistency</h4>
<p>与常用的“贪心解码”（每一步都选择最可能的选项）相比，“自我一致性”的解码策略能在使用CoT（Chain-of-Thought，逐步推理）技术指导大语言模型时，更好地提升推理性能。对于那些存在多个可能解决路径的复杂推理任务，&quot;自我一致性&quot;策略能从语言模型的解码器中采样出多样化的推理链条。接着，它通过对这些采样链条进行统计处理（即“边缘化”），来确定最具一致性的最终答案。这种方法的优势在于，对于需要深入分析的问题，通常存在更多的推理路径，这种多样性正是我们找到解决方案的关键。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/6e31e14eab13341dd9f693aedb1ef816.png" alt=""></p>
<h4 id="Logical-Chain-of-Thought-LogiCoT-Prompting">Logical Chain-of-Thought (LogiCoT) Prompting</h4>
<p>大语言模型 (LLMs) 要解决各种领域的复杂多步问题，具备逻辑推理能力是至关重要的。现有的方法，比如 CoT 提示，虽然倡导逐步推理，但在验证机制上却不够有效。</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.12147" title="LogiCoT">LogiCoT</a> 采用了&quot;反证法&quot;的思想，对模型生成的每一步推理进行验证，并在发现错误时提供有针对性的反馈进行修正。通过这样一种&quot;思考-验证-修正&quot;的循环过程，LogiCoT 能有效地减少模型在推理过程中的逻辑错误和误导性信息。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/9ba28acd4ee5b6197afe5c5d428e5bca.png" alt=""></p>
<h4 id="Chain-of-Symbol-CoS-Prompting">Chain-of-Symbol (CoS) Prompting</h4>
<p>大语言模型常常在处理涉及复杂空间关系的任务时遇到困难，因为它们主要依赖于自然语言，这可能导致歧义和偏见。</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.10276" title="CoS">CoS</a> 使用简洁的符号来替代自然语言。CoS 的优势在于：它可以提供清晰、简洁的提示，增强大语言模型的空间推理能力，并提高人类对模型的理解。然而，CoS 也面临着一些挑战，比如如何扩展和泛化，如何与其他技术集成，以及如何解释基于符号的大语言模型的推理过程等。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/fa8d491e924cb02ff8449d58d3a1a483.png" alt=""></p>
<h4 id="Tree-of-Thoughts-ToT-Prompting">Tree-of-Thoughts (ToT) Prompting</h4>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.10601" title="ToT">ToT</a> 通过构建一个包含中间推理步骤的树形结构，来拓展链式思维（CoT）提示的方法，这些步骤被称为 “思维”。每一个&quot;思维&quot;都代表一段有条理的语言序列，指向最终的解决方案。这样的结构让大语言模型能够通过评估每个&quot;思维&quot;在解决问题上的进展，进行更深入的推理。思维树结合了模型生成和评估&quot;思维&quot;的能力，以及广度优先或深度优先等搜索算法。这使得模型能在推理链中进行系统性的探索，预先扩展可能有希望的解决方向，同时在找到错误的解决方案时能够回溯。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/408297ef014c50ff725acd01558eb70c.png" alt=""></p>
<h4 id="Graph-of-Thoughts-GoT-Prompting">Graph-of-Thoughts (GoT) Prompting</h4>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2308.09687" title="GoT">GoT</a>  对传统的顺序方法进行了改进，使其更好地对应人类思维的非线性特性。这个框架支持动态的交互，回溯和评估各种想法，允许从不同的分支中整合和组合思维，打破了思维树的线性结构。它的主要贡献在于，将推理过程模拟成一个有向图，并提供了一个带有多种转换操作的模块化架构。这个框架被视为一种灵活且动态的语言模型提示方式，能够捕捉人类思维过程的复杂性，并提升模型的能力。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/1dd475a4bcf9855715799415add7466a.png" alt=""></p>
<h4 id="System-2-Attention-S2A-Prompting">System 2 Attention (S2A) Prompting</h4>
<p>在基于 Transformer 的大语言模型 (LLM) 中，柔性的关注机制可能会过度考虑无关的信息，这对于生成有效的 token 不利。</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.11829" title="S2A">S2A</a> 利用大语言模型的推理能力，通过重新整理输入的上下文，只关注与任务相关的信息。S2A 采用了两步过程，通过重塑上下文和生成更精确的回应，来提高其关注能力和回应质量。S2A 的效果在各种任务中得到了验证，包括回答基于事实的问题，生成长篇文章，以及解决数学文字题目。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/bbed833d5b6ad0cb192d38cfc5176047.png" alt=""></p>
<h4 id="Thread-of-Thought-ThoT-Prompting">Thread of Thought (ThoT) Prompting</h4>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.08734" title="ThoT">ThoT</a> 的设计灵感来自人类的认知过程，它能有条不紊地分析大量的信息，将这些信息划分为易于处理的小部分。这个过程分为两个阶段，首先，LLM 会概括和审查每一段信息，然后再精炼这些信息，以便给出最后的回应。ThoT 的灵活性体现在它可以作为一个多功能的插件，用于增强不同模型和提示方法的推理能力。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/685c878ed68c513cb9025a8428563eb7.png" alt=""></p>
<h4 id="Chain-of-Table-Prompting">Chain-of-Table Prompting</h4>
<p>像 CoT、PoT 和 ToT 这样的方法主要是通过自由形式的文本或代码来进行推理，但在处理包含大量数据和复杂结构的表格时，却遭遇了一些困难。</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2401.04398" title="Chain-of-Table">Chain-of-Table</a> 的核心思想是通过动态地在表格上生成并执行常见的 SQL 或 DataFrame 操作，实现步骤之间的逐步推理。这一过程的反复迭代可以改进中间的推理结果，从而提升大语言模型的预测能力，使其能够通过形象的逻辑推理链条进行预测。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/a10c977d23baa955352761769ce584f2.png" alt=""><br>
<img src="//s3.mindex.xyz/blog/Courses/708189f5f2c23f49cf287e871674f3da.png" alt=""></p>
<h3 id="Reduce-Hallucination">Reduce Hallucination</h3>
<h4 id="Retrieval-Augmented-Generation-RAG">Retrieval Augmented Generation (RAG)</h4>
<p>大语言模型 (LLMs) 已经带来了文本生成的革命性变化，但其依赖有限、静态的训练数据，使得在需要外部知识的任务中，准确的响应成为了难题。传统的提示方法并不能解决这个问题，因为它需要耗费大量的重新训练。</p>
<p><a href="/tags/RAG/" title="RAG">RAG</a> 为我们提供了新的解决方案，它将信息检索巧妙地融入到提示过程中。RAG 能够分析用户的输入，制定出精准的查询，并在预先构建的知识库中查找相关的资源。检索到的信息片段被纳入到原始的提示中，为其提供了丰富的上下文背景。这样增强后的提示，使大语言模型能够生成具有创新性和准确性的响应。RAG 的敏捷性突破了静态限制，对于需要实时知识的任务，它无疑是一种改变游戏规则的技术。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/2b7824dc44fda311ea348ff4af2ecca2.png" alt=""></p>
<h4 id="ReAct-Prompting">ReAct Prompting</h4>
<p>与以往将推理和行动分别处理的研究不同，<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2210.03629" title="ReAct">ReAct</a> 让大语言模型（LLMs）有能力同时进行推理过程和特定任务的行动生成。这种交织的过程增强了推理和行动之间的协同效应，使模型在处理异常情况时能够更好地引导、追踪和更新行动计划。ReAct 被广泛应用于各种语言处理和决策制定任务中，并在与当前SOTA相比较的基线测试中展现出了显著的优势。尤其值得一提的是，在问题回答（HotpotQA）和事实验证（Fever）任务中，ReAct 通过与简单的维基百科API的交互，有效地解决了错误传播和产生不真实信息的问题，从而产生了更易于理解的任务解决路径。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/d398a9d0ea408794f3bb35f78d76a2c3.png" alt=""></p>
<h4 id="Chain-of-Verification-CoVe-Prompting">Chain-of-Verification (CoVe) Prompting</h4>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2309.11495" title="CoVe">CoVe</a> 包含四个步骤：模型首先生成初步的回答，然后提出一些验证问题以检查自己的回答，接着独立地解答这些问题，最后根据验证结果修正并产生最终的回答。这种经过深思熟虑的多步骤验证方式，提升了大语言模型的逻辑推理能力，使其即使在面对矛盾信息时也能减少错误。CoVe 的设计理念是模拟人类的验证过程，以此提高大语言模型输出的连贯性和精确性。在列表问题、问答和长篇生成等实验中，CoVe 成功地在保证事实准确性的同时，减少了虚构现象。通过提出具有针对性的验证问题，模型能更好地发现并纠正自身的不准确之处。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/f77ebfaff72cd60616c655ed8356dd12.png" alt=""></p>
<h4 id="Chain-of-Note-CoN-Prompting">Chain-of-Note (CoN) Prompting</h4>
<p>检索增强型语言模型（Retrieval-augmented language models，RALMs）的设计初衷是为了提升大型语言模型（Large Language Models）的能力，通过融合外部知识，以减少模型在生成过程中产生的不真实信息。然而，这些检索到的信息并非总是可靠的，有可能会引导模型产生错误的回应。常规的 RALMs 在评估自身知识是否充足时，往往会遇到困难，尤其是在缺乏足够信息时，这些模型通常无法给出“我不知道”的答案。</p>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># For standard RALM</span></span><br><span class="line">Task Description:</span><br><span class="line">The primary objective is <span class="built_in">to</span> briefly answer <span class="keyword">a</span> specific question.</span><br><span class="line"></span><br><span class="line"><span class="comment"># For RALM with CON</span></span><br><span class="line">Task Description:</span><br><span class="line"><span class="number">1.</span> Read <span class="keyword">the</span> given question <span class="keyword">and</span> Wikipedia passages <span class="built_in">to</span> gather relevant information.</span><br><span class="line"><span class="number">2.</span> Write reading notes summarizing <span class="keyword">the</span> key points <span class="built_in">from</span> these passages.</span><br><span class="line"><span class="number">3.</span> Discuss <span class="keyword">the</span> relevance <span class="keyword">of</span> <span class="keyword">the</span> given question <span class="keyword">and</span> Wikipedia passages.</span><br><span class="line"><span class="number">4.</span> If some passages are relevant <span class="built_in">to</span> <span class="keyword">the</span> given question, provide <span class="keyword">a</span> brief  answer based <span class="keyword">on</span> <span class="title">the</span> <span class="title">passages</span>.</span><br><span class="line"><span class="number">5.</span> If no passage is relevant, directly provide answer <span class="keyword">without</span> considering <span class="keyword">the</span> passages.</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.09210" title="CoN">CoN</a> 能够系统地评估文档的相关性，强调关键且可靠的信息，过滤掉无关的内容，从而使得模型的回应更加精确，更具上下文相关性。<br>
CoN 不仅是一个提示模板，而且还包含了一个经过微调的可以记笔记模型。因此CoN可以看作是RAG和Fine-Tuning的结合。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/4512f010ca40405423106942c10baa58.png" alt=""><br>
<img src="//s3.mindex.xyz/blog/Courses/8b5f22339915adbdfc67dde8e70ca6a6.png" alt=""></p>
<h4 id="Chain-of-Knowledge-CoK-Prompting">Chain-of-Knowledge (CoK) Prompting</h4>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.13269" title="CoK">CoK</a>  从人类解决问题的方式中获得灵感，将复杂的任务系统地分解成一系列有序的步骤。这个过程首先是全面的推理准备阶段，建立问题的上下文，并对问题进行框架化。然后，它进入动态知识适应阶段，从各种来源如内部知识库、外部数据库以及给定的提示中，精心收集相关的证据。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/c7f7c5ea582e777b188323ff20acba7e.png" alt=""><br>
<img src="//s3.mindex.xyz/blog/Courses/df831c882f4df1aabade839c782c0716.png" alt=""></p>
<h3 id="User-Interface">User Interface</h3>
<h4 id="Active-Prompting">Active Prompting</h4>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2302.12246">Active-Prompting</a> 引入了一种新的机制，可以确定哪些问题对于注释最具影响力。这种方法借鉴了基于不确定性的主动学习的思想，通过使用各种度量标准来描述不确定性，并选择最具不确定性的问题进行注释。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/c689e6ee19708f997f565ad61fa60f73.png" alt=""></p>
<h3 id="Fine-Tuning-and-Optimization">Fine-Tuning and Optimization</h3>
<h4 id="Automatic-Prompt-Engineer-APE">Automatic Prompt Engineer (APE)</h4>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2211.01910" title="APE">APE</a> 通过动态地生成和选择对特定任务最有影响力的提示，从而克服了传统手工设计的、固定不变的提示的缺点。这种巧妙的方法会分析用户的输入，制定一系列可能的指令，然后利用强化学习来挑选出最佳的提示。这种提示能够根据不同的上下文环境进行实时调整，提高了模型的适应性。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/fec997cd64d3cad3f8161207bf98bb7a.png" alt=""></p>
<h3 id="Knowledge-Based-Reasoning-and-Generation">Knowledge-Based Reasoning and Generation</h3>
<h4 id="Automatic-Reasoning-and-Tool-use-ART">Automatic Reasoning and Tool-use (ART)</h4>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.09014" title="ART">ART</a> 赋予了大语言模型通过多步骤过程进行推理，以及无缝地利用外部专业知识的能力，从而使其能够应对复杂问题，超越了简单的文本生成。</p>
<p>ART通过整合专业知识和计算工具，打开了大语言模型的多功能性，使其的输出能与现实世界紧密联系。这使得大语言模型能够在科学研究、数据分析，甚至决策支持等多元领域发挥作用。</p>
<p>ART不仅超越了传统的提示技术，还通过结构化程序自动化了推理步骤，从而消除了手工制作的需要。其动态的工具整合能力确保了与外部工具的顺畅协作，可以暂停生成过程以融入外部工具的输出结果，然后无缝地恢复生成流程。在一些具有挑战性的基准测试（例如Big-Bench和MMLU）上，实验证明了ART的有效性，其表现甚至超过了传统的提示技术，有时甚至能够达到手工制作示例的效果。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/736ea666e264e7bb729505c7454b60d6.png" alt=""><br>
<img src="//s3.mindex.xyz/blog/Courses/e286a415d47aba340dd72ee42f93bc7a.png" alt=""><br>
<img src="//s3.mindex.xyz/blog/Courses/65deeb80598eff36a0d403e7c745a0bc.png" alt=""></p>
<h3 id="Improving-Consistency-and-Coherence">Improving Consistency and Coherence</h3>
<h4 id="Contrastive-Chain-of-Thought-CCoT-Prompting">Contrastive Chain-of-Thought (CCoT) Prompting</h4>
<p>传统用于大语言模型的CoT提示方法往往忽视了一个关键环节：从错误中吸取教训。</p>
<p>而 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.09277" title="CCoT">CCoT</a> 不仅提供了正确的推理示例，还展示了错误的推理过程。试想你在探索一张地图，既有明确的正确路径，也标出了需要避开的误区，这就是CCoT带来的优势！</p>
<p><img src="//s3.mindex.xyz/blog/Courses/2342eec6fbabec308efa898da263f8b2.png" alt=""><br>
<img src="//s3.mindex.xyz/blog/Courses/614cb77a1ae49769c1ce1a48fc895bfd.png" alt=""><br>
<img src="//s3.mindex.xyz/blog/Courses/9d0aa48a1d217f14449a7cc30fb93a21.png" alt=""></p>
<h3 id="Managing-Emotions-and-Tone">Managing Emotions and Tone</h3>
<h4 id="Emotion-Prompting">Emotion Prompting</h4>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2307.11760">EmotionPrompt</a> 解决了大语言模型理解情绪线索能力的不确定性。他们从心理学研究中汲取灵感，探索语言对人类表现的影响，将11个情绪刺激语句融入到提示中，旨在提升大语言模型的情绪智能。实验结果显示，这些情绪刺激语句的加入，能够有效地融入到模型的运作中，从而在各种任务中显著提升大语言模型的表现。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/ac0b8274fbc10014e730d3bb9f460c08.png" alt=""><br>
<img src="//s3.mindex.xyz/blog/Courses/ba723c819c6506283f3ba9720a3d91aa.png" alt=""></p>
<h3 id="Code-Generation-and-Execution">Code Generation and Execution</h3>
<h4 id="Scratchpad-Prompting">Scratchpad Prompting</h4>
<p>尽管基于 Transformer 的语言模型在生成基础编程任务的代码上表现卓越，但在涉及到需要精确逻辑推理的复杂、多步骤算法计算中，它们却面临挑战。</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2112.00114" title="Scratchpad Prompting">Scratchpad</a> 更注重任务设计，而非模型的修改，使得模型能在给出最终答案之前，生成一系列的中间计算步骤。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/badc6033f1cde07372bd7a5d51b50149.png" alt=""></p>
<h4 id="Program-of-Thoughts-PoT-Prompting">Program of Thoughts (PoT) Prompting</h4>
<p>语言模型在解决数学表达式时的表现并不理想，主要原因在于它们容易出现算术错误，无法处理复杂的方程，且在表达大量迭代过程时效率低下。</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2211.12588" title="PoT">PoT</a> 倡导在计算步骤中使用外部的编程语言解释器，以提高语言模型的数值推理能力。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/c7a6067d672639aad0ece1593402d05e.png" alt=""></p>
<h4 id="Structured-Chain-of-Thought-SCoT-Prompting">Structured Chain-of-Thought (SCoT) Prompting</h4>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.06599" title="SCoT">SCoT</a> 通过将程序结构（如序列、分支和循环结构）融入推理步骤，从而提升了大语言模型在生成结构化源代码方面的表现。这种方法明确地引导大语言模型从源代码的角度思考需求，相比于 CoT 提示，其在代码生成方面的效果得到了显著提升。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/336065b71cdb63da883607248c7fe400.png" alt=""></p>
<h4 id="Chain-of-Code-CoC-Prompting">Chain-of-Code (CoC) Prompting</h4>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2312.04474" title="CoC">CoC</a> 通过利用编写代码的方式来改善LM的推理能力，适用于逻辑和语义任务。CoC 鼓励LMs把语义子任务格式化为灵活的伪代码，这样就可以让解释器捕捉到未定义的行为，并通过一个被称为&quot;LM模拟器&quot;（LMulator）的工具来模拟这些行为。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/920be294f8d31bcb2dfc99c9b48f718a.png" alt=""></p>
<h3 id="Optimization-and-Efficiency">Optimization and Efficiency</h3>
<h4 id="Optimization-by-Prompting-OPRO">Optimization by Prompting (OPRO)</h4>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2309.03409" title="OPRO">OPRO</a> 使用自然语言的提示，根据问题的描述，逐步生成解决方案，从而使得快速适应不同任务和个性化优化过程成为可能。通过在诸如线性回归和旅行商问题这样的经典问题上的案例研究，展示了LLMs在优化问题上的巨大潜力。此外，OPRO还探索了如何优化提示，以在自然语言处理任务中最大化准确性，这也突显出LLMs的敏感性。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/fc2a4795b407fb610709971983ea9db8.png" alt=""><br>
<img src="//s3.mindex.xyz/blog/Courses/fece14e6124c739fb7768d5ef7379ca6.png" alt=""></p>
<h3 id="Understanding-User-Intent">Understanding User Intent</h3>
<h4 id="Rephrase-and-Respond-RaR-Prompting">Rephrase and Respond (RaR) Prompting</h4>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2311.04205" title="RaR">RaR</a> 让大语言模型有能力在一次提示中对问题进行重新表述和扩展，从而提高了模型理解问题和回答问题的准确性。他们还开发了一种两步骤的 RaR 变种，这种变种结合了重新表述和回应的大语言模型，显著提高了各种任务的性能。研究强调，相比于人类随意提出的问题，重新表述的问题能够增强语义的清晰度，解决问题本身的模糊性。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/11b29a315244c8ee5370bfe49edf1078.png" alt=""><br>
<img src="//s3.mindex.xyz/blog/Courses/e586e329ea1017532ef7dc13886d48e6.png" alt=""></p>
<h3 id="Metacognition-and-Self-Reflection">Metacognition and Self-Reflection</h3>
<h4 id="Take-a-Step-Back-Prompting">Take a Step Back Prompting</h4>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2310.06117" title="Step Back Prompting">Step Back</a> 方法包含两个步骤，即“抽象”和“推理”的整合。通过广泛的实验，将“Step Back”应用于PaLM-2L在STEM（科学、技术、工程和数学）、知识问答和多跳推理等各种推理密集型任务中，实验结果表明，这种方法能显著提升模型的推理能力。</p>
<p><img src="//s3.mindex.xyz/blog/Courses/0117ebc52d00cbb97b43e4cbfc1d4b1b.png" alt=""></p>
<h2 id="Conclusion">Conclusion</h2>
<p>提示工程未来的发展潜力巨大，元学习和混合提示架构等新兴趋势预示着它的能力将得到进一步提升。然而，我们在发展的同时，必须高度重视道德问题，强调负责任的开发和部署，确保其能够积极地融入我们的生活中。</p>
<h2 id="Source">Source</h2>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2402.07927" title="A Systematic Survey of Prompt Engineering">A Systematic Survey of Prompt Engineering</a></p>
</div><iframe src="/donate/?AliPayQR=null&amp;WeChatQR=http://s3.mindex.xyz/mp/qrcode-s.jpg&amp;GitHub=http://github.com/neo1989&amp;BTCQR=null&amp;BTCKEY=null&amp;PayPal=null" style="overflow-x:hidden; overflow-y:hidden; border:0xp none #fff; min-height:240px; width:100%;" frameborder="0" scrolling="no"></iframe><div><ul class="post-copyright"><li class="post-copyright-author"><strong>Author: </strong>尼欧</li><li class="post-copyright-link"><strong>Blog Link: </strong><a href="/Way2AI/Way2AI-A-Systematic-Survey-of-Prompt-Engineering-in-LLM/">https://neo1989.net/Way2AI/Way2AI-A-Systematic-Survey-of-Prompt-Engineering-in-LLM/</a></li><li class="post-copyright-license"><strong>Copyright Declaration: </strong>转载请声明出处。</li></ul></div><br><div class="tags"><a href="/tags/Coder/">Coder</a><a href="/tags/AI/">AI</a><a href="/tags/LLM/">LLM</a></div><div class="post-nav"><a class="next" href="/Way2AI/Way2AI-How-to-Build-an-Enterprise-RAG-System/">Way2AI · 如何构建企业级 RAG 系统</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论（请确保 Disqus 可以正常加载）</button></div><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'https://neo1989.net/Way2AI/Way2AI-A-Systematic-Survey-of-Prompt-Engineering-in-LLM/';
    this.page.identifier = 'Way2AI/Way2AI-A-Systematic-Survey-of-Prompt-Engineering-in-LLM/';
    this.page.title = 'Way2AI · Prompt Engineering 概述';
  };</script><!-- script(type='text/javascript' id='disqus-lazy-load-script').--><!--   $.ajax({--><!--   url: 'https://disqus.com/next/config.json',--><!--   timeout: 2500,--><!--   type: 'GET',--><!--   success: function(){--><!--     var d = document;--><!--     var s = d.createElement('script');--><!--     s.src = '//#{theme.disqus}.disqus.com/embed.js';--><!--     s.setAttribute('data-timestamp', + new Date());--><!--     (d.head || d.body).appendChild(s);--><!--     $('.disqus_click_btn').css('display', 'none');--><!--   },--><!--   error: function() {--><!--     $('.disqus_click_btn').css('display', 'block');--><!--   }--><!--   });--><script type="text/javascript" id="disqus-click-load">$('.btn_click_load').click(() => {  //click to load comments
    (() => { // DON'T EDIT BELOW THIS LINE
        var d = document;
        var s = d.createElement('script');
        s.src = '//neo1989.disqus.com/embed.js';
        s.setAttribute('data-timestamp', + new Date());
        (d.head || d.body).appendChild(s);
    })();
    $('.disqus_click_btn').css('display','none');
});</script><script type="text/javascript" id="disqus-count-script">$(function() {
     var xhr = new XMLHttpRequest();
     xhr.open('GET', '//disqus.com/next/config.json', true);
     xhr.timeout = 2500;
     xhr.onreadystatechange = function () {
       if (xhr.readyState === 4 && xhr.status === 200) {
         $('.post-meta .post-comments-count').show();
         var s = document.createElement('script');
         s.id = 'dsq-count-scr';
         s.src = 'https://neo1989.disqus.com/count.js';
         s.async = true;
         (document.head || document.body).appendChild(s);
       }
     };
     xhr.ontimeout = function () { xhr.abort(); };
     xhr.send(null);
   });
</script></div></div></div></div></div><div class="pure-u-1 pure-u-md-4-6"><div id="footer">Copyright © 2024 <a href="/." rel="nofollow">愚苏记.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/i-yard/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho/maupassant"> Cho.</a></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="/lib/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="/lib/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script><script type="text/javascript" id="maid-script" mermaidoptioins="{&quot;startOnload&quot;:true,&quot;theme&quot;:&quot;forest&quot;}" src="/js/mermaid.min.js?v=1.0.0"></script><script>if (window.mermaid) {
  var options = JSON.parse(document.getElementById('maid-script').getAttribute('mermaidoptioins'));
  mermaid.initialize(options);
}</script></div><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>