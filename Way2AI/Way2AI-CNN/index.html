<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="我读书少，你莫骗我。"><title>Way2AI · 卷积神经网络 | 愚苏记</title><link rel="stylesheet" type="text/css" href="https://cdn.staticfile.org/lxgw-wenkai-webfont/1.6.0/style.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="/lib/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="/lib/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="/lib/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="/lib/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="/lib/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + '96c862f2728296588ae9849f3bcb95db';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();</script><link rel="alternate" type="application/atom+xml" href="/atom.xml"><meta name="generator" content="Hexo 7.1.1"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Way2AI · 卷积神经网络</h1><a id="logo" href="/.">愚苏记</a><p class="description">To no avail but try.</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-5-5"><div class="content_container no-padding-right"><div class="post"><h1 class="post-title">Way2AI · 卷积神经网络</h1><div class="post-meta">Jun 27, 2023<span> | </span><span class="category"><a href="/categories/Way2AI/">Way2AI</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 5.2k</span><span class="post-meta-item-text"> Words</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 27</span><span class="post-meta-item-text"> Minutes</span></span></span></div><a class="disqus-comment-count" data-disqus-identifier="Way2AI/Way2AI-CNN/" href="/Way2AI/Way2AI-CNN/#disqus_thread"></a><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">Contents</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#TL-DR"><span class="toc-number">1.</span> <span class="toc-text">TL;DR</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Set-up"><span class="toc-number">2.</span> <span class="toc-text">Set up</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Load-data"><span class="toc-number">2.1.</span> <span class="toc-text">Load data</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Preprocessing"><span class="toc-number">2.2.</span> <span class="toc-text">Preprocessing</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Split-data"><span class="toc-number">2.3.</span> <span class="toc-text">Split data</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Label-encoding"><span class="toc-number">3.</span> <span class="toc-text">Label encoding</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tokenizer"><span class="toc-number">4.</span> <span class="toc-text">Tokenizer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#One-hot-encoding"><span class="toc-number">5.</span> <span class="toc-text">One-hot encoding</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Padding"><span class="toc-number">6.</span> <span class="toc-text">Padding</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Dataset"><span class="toc-number">7.</span> <span class="toc-text">Dataset</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CNN"><span class="toc-number">8.</span> <span class="toc-text">CNN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Inputs"><span class="toc-number">8.1.</span> <span class="toc-text">Inputs</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Filters"><span class="toc-number">8.2.</span> <span class="toc-text">Filters</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Pooling"><span class="toc-number">8.3.</span> <span class="toc-text">Pooling</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Batch-normalization"><span class="toc-number">8.4.</span> <span class="toc-text">Batch normalization</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Modling"><span class="toc-number">9.</span> <span class="toc-text">Modling</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Model"><span class="toc-number">9.1.</span> <span class="toc-text">Model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Training"><span class="toc-number">9.2.</span> <span class="toc-text">Training</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Evaluaton"><span class="toc-number">9.3.</span> <span class="toc-text">Evaluaton</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Inference"><span class="toc-number">9.4.</span> <span class="toc-text">Inference</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ending"><span class="toc-number">10.</span> <span class="toc-text">Ending</span></a></li></ol></div></div><div class="post-content"><h2 id="TL-DR">TL;DR</h2>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><p>本文简单示范了如何利用CNN处理NLP任务。</p>
<p>CNNs的核心就是利用卷积（滑动）操作来提取数据特征的卷积核（aka kernels, filters,weights, etc.)。它们随机初始化但通过参数共享来提取特征。</p>
<p><img src="//s3.mindex.xyz/tmp/1a58a0c1e58cd3f543995ecee0eb71d4.gif" alt=""></p>
<h2 id="Set-up">Set up</h2>
<p>复用<a href="http://neo1989.net/Way2AI/Way2AI-utilities/" title="PyTorch实现神经网络的基本套路">《PyTorch实现神经网络的基本套路》</a> 里介绍的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_seeds</span>(<span class="params">seed=<span class="number">1024</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Set seeds for reproducibility.&quot;&quot;&quot;</span></span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    random.seed(seed)</span><br><span class="line">    touch.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed_all(seed)  <span class="comment"># multi-GPU</span></span><br><span class="line"></span><br><span class="line">set_seeds(seed=<span class="number">1024</span>)</span><br><span class="line"></span><br><span class="line">cuda = <span class="literal">True</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span>(torch.cuda.is_available() <span class="keyword">and</span> cuda) <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">torch.set_default_tensor_type(&#123;<span class="string">&quot;cuda&quot;</span>: <span class="string">&quot;torch.cuda.FloatTensor&quot;</span>, <span class="string">&quot;cpu&quot;</span>: <span class="string">&quot;torch.FloatTensor&quot;</span>&#125;.get(<span class="built_in">str</span>(device)))</span><br></pre></td></tr></table></figure>
<h3 id="Load-data">Load data</h3>
<p>我们将在<a target="_blank" rel="noopener" href="https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset" title="AG News Classification Dataset">AGNews dataset</a> 这个数据集上完成本次学习任务。这是一份来自4个不同新闻分类120k条新闻标题样本。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load data</span></span><br><span class="line">url = <span class="string">&quot;https://s3.mindex.xyz/datasets/news.csv&quot;</span></span><br><span class="line">df = pd.read_csv(url, header=<span class="number">0</span>)</span><br><span class="line">df = df.sample(frac=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure>
<p><img src="//s3.mindex.xyz/tmp/5820e01cf3a5f9f93ce85ba8d488647e.png" alt=""></p>
<h3 id="Preprocessing">Preprocessing</h3>
<p>首先要做的，是对这些数据进行预处理，手段包括删除停用词、字母小写（英文）、词形还原词干提取、中文分词、正则处理等。</p>
<p>由于我们的任务是纯英文数据，这里使用英文的通用处理方法。中文任务以后再表。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> PorterStemmer</span><br><span class="line"></span><br><span class="line">nltk.download(<span class="string">&quot;stopwords&quot;</span>)</span><br><span class="line">STOPWORDS = stopwords.words(<span class="string">&quot;english&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (STOPWORDS[:<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># [&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;]</span></span><br><span class="line"></span><br><span class="line">porter = PorterStemmer()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">text, stopwords=STOPWORDS</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Conditional preprocessing on our text unique to our task.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Lower</span></span><br><span class="line">    text = text.lower()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Remove stopwords</span></span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">r&quot;\b(&quot;</span> + <span class="string">r&quot;|&quot;</span>.join(stopwords) + <span class="string">r&quot;)\b\s*&quot;</span>)</span><br><span class="line">    text = pattern.sub(<span class="string">&quot;&quot;</span>, text)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Remove words in parenthesis</span></span><br><span class="line">    text = re.sub(<span class="string">r&quot;\([^)]*\)&quot;</span>, <span class="string">&quot;&quot;</span>, text)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Spacing and filters</span></span><br><span class="line">    text = re.sub(<span class="string">r&quot;([-;;.,!?&lt;=&gt;])&quot;</span>, <span class="string">r&quot; \1 &quot;</span>, text)  <span class="comment"># separate punctuation tied to words</span></span><br><span class="line">    text = re.sub(<span class="string">&quot;[^A-Za-z0-9]+&quot;</span>, <span class="string">&quot; &quot;</span>, text)  <span class="comment"># remove non alphanumeric chars</span></span><br><span class="line">    text = re.sub(<span class="string">&quot; +&quot;</span>, <span class="string">&quot; &quot;</span>, text)  <span class="comment"># remove multiple spaces</span></span><br><span class="line">    text = text.strip()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Apply to dataframe</span></span><br><span class="line">preprocessed_df = df.copy()</span><br><span class="line">preprocessed_df.title = preprocessed_df.title.apply(preprocess)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;<span class="subst">&#123;df.title.values[-<span class="number">1</span>]&#125;</span>\n\n<span class="subst">&#123;preprocessed_df.title.values[-<span class="number">1</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Oil Slips Under \$55 a Barrel</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># oil slips 55 barrel</span></span><br></pre></td></tr></table></figure>
<h3 id="Split-data">Split data</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">TRAIN_SIZE = <span class="number">0.7</span></span><br><span class="line">VAL_SIZE = <span class="number">0.15</span></span><br><span class="line">TEST_SIZE = <span class="number">0.15</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_val_test_split</span>(<span class="params">X, y, train_size</span>):</span><br><span class="line">    X_train, X_, y_train,y_ = train_test_split(X, y, train_size=train_size, stratify=y)</span><br><span class="line">    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=<span class="number">0.5</span>, stratify=y_)</span><br><span class="line">    <span class="keyword">return</span> X_train, X_val, X_test, y_train, y_val, y_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Data</span></span><br><span class="line">X = preprocessed_df[<span class="string">&quot;title&quot;</span>].values</span><br><span class="line">y = preprocessed_df[<span class="string">&quot;category&quot;</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create data splits</span></span><br><span class="line">X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X=X, y=y, train_size=TRAIN_SIZE)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_train: <span class="subst">&#123;X_train.shape&#125;</span>, y_train: <span class="subst">&#123;y_train.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_val: <span class="subst">&#123;X_val.shape&#125;</span>, y_val: <span class="subst">&#123;y_val.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;X_test: <span class="subst">&#123;X_test.shape&#125;</span>, y_test: <span class="subst">&#123;y_test.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;Sample point: <span class="subst">&#123;X_train[<span class="number">0</span>]&#125;</span> → <span class="subst">&#123;y_train[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># X_train: (84000,), y_train: (84000,)</span></span><br><span class="line"><span class="comment"># X_val: (18000,), y_val: (18000,)</span></span><br><span class="line"><span class="comment"># X_test: (18000,), y_test: (18000,)</span></span><br><span class="line"><span class="comment"># Sample point: wenger plans buy new keeper → Sports</span></span><br></pre></td></tr></table></figure>
<h2 id="Label-encoding">Label encoding</h2>
<p>复用<a href="http://neo1989.net/Way2AI/Way2AI-utilities/" title="PyTorch实现神经网络的基本套路">《PyTorch实现神经网络的基本套路》</a> 里介绍的 LabelEncoder</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># Encode</span></span><br><span class="line">label_encoder = LabelEncoder()</span><br><span class="line">label_encoder.fit(y_train)</span><br><span class="line">NUM_CLASSES = <span class="built_in">len</span>(label_encoder)</span><br><span class="line"><span class="built_in">print</span> (label_encoder.class_to_index)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &#123;&#x27;Business&#x27;: 0, &#x27;Sci/Tech&#x27;: 1, &#x27;Sports&#x27;: 2, &#x27;World&#x27;: 3&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert labels to tokens</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;y_train[0]: <span class="subst">&#123;y_train[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line">y_train = label_encoder.encode(y_train)</span><br><span class="line">y_val = label_encoder.encode(y_val)</span><br><span class="line">y_test = label_encoder.encode(y_test)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;y_train[0]: <span class="subst">&#123;y_train[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># y_train[0]: Sports</span></span><br><span class="line"><span class="comment"># y_train[0]: 2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Class weights</span></span><br><span class="line">counts = np.bincount(y_train)</span><br><span class="line">class_weights = &#123;i: <span class="number">1.0</span>/count <span class="keyword">for</span> i, count <span class="keyword">in</span> <span class="built_in">enumerate</span>(counts)&#125;</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;counts: <span class="subst">&#123;counts&#125;</span>\nweights: <span class="subst">&#123;class_weights&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># counts: [21000 21000 21000 21000]</span></span><br><span class="line"><span class="comment"># weights: &#123;0: 4.761904761904762e-05, 1: 4.761904761904762e-05, 2: 4.761904761904762e-05, 3: 4.761904761904762e-05&#125;</span></span><br></pre></td></tr></table></figure>
<h2 id="Tokenizer">Tokenizer</h2>
<p>由于任务要处理的是文本，无法直接送给模型。因此我们定义一个Tokenizer来处理文本数据，目的是将文本序列转化成离散的标记（tokens)，以便后续的处理和分析。这意味着每个token可以映射到一个唯一的索引，这样我们就可以用一个索引数组（向量）来表示文本序列。而一个token可以是一个字符、一个单词、一个词组等等。</p>
<p>下面是一个示例实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">from</span> more_itertools <span class="keyword">import</span> take</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Tokenizer</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, char_level, num_tokens=<span class="literal">None</span>, pad_token=<span class="string">&quot;&lt;PAD&gt;&quot;</span>, oov_token=<span class="string">&quot;&lt;UNK&gt;&quot;</span>, token_to_index=<span class="literal">None</span></span>):</span><br><span class="line">        self.char_level = char_level</span><br><span class="line">        self.separator = <span class="string">&quot;&quot;</span> <span class="keyword">if</span> self.char_level <span class="keyword">else</span> <span class="string">&quot; &quot;</span></span><br><span class="line">        <span class="keyword">if</span> num_tokens:</span><br><span class="line">            num_tokens -= <span class="number">2</span> <span class="comment"># pad + unk tokens</span></span><br><span class="line">        self.num_tokens = num_tokens</span><br><span class="line">        self.pad_token = pad_token</span><br><span class="line">        self.oov_token = oov_token</span><br><span class="line">        self.token_to_index = token_to_index <span class="keyword">if</span> token_to_index <span class="keyword">else</span> &#123;pad_token: <span class="number">0</span>, oov_token: <span class="number">1</span>&#125;</span><br><span class="line">        self.index_to_token = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> self.token_to_index.items()&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.token_to_index)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;&lt;Tokenizer(num_tokens=<span class="subst">&#123;<span class="built_in">len</span>(self)&#125;</span>)&gt;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit_on_texts</span>(<span class="params">self, texts</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.char_level:</span><br><span class="line">            texts = [text.split(<span class="string">&quot; &quot;</span>) <span class="keyword">for</span> text <span class="keyword">in</span> texts]</span><br><span class="line">        all_tokens = [token <span class="keyword">for</span> text <span class="keyword">in</span> texts <span class="keyword">for</span> token <span class="keyword">in</span> text]</span><br><span class="line">        counts = Counter(all_tokens).most_common(self.num_tokens)</span><br><span class="line">        self.min_token_freq = counts[-<span class="number">1</span>][<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> token, count <span class="keyword">in</span> counts:</span><br><span class="line">            index = <span class="built_in">len</span>(self)</span><br><span class="line">            self.token_to_index[token] = index</span><br><span class="line">            self.index_to_token[index] = token</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">texts_to_sequences</span>(<span class="params">self, texts</span>):</span><br><span class="line">        sequences = []</span><br><span class="line">        <span class="keyword">for</span> text <span class="keyword">in</span> texts:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> self.char_level:</span><br><span class="line">                text = text.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">            sequence = []</span><br><span class="line">            <span class="keyword">for</span> token <span class="keyword">in</span> text:</span><br><span class="line">                sequence.append(self.token_to_index.get(</span><br><span class="line">                    token, self.token_to_index[self.oov_token]))</span><br><span class="line">            sequences.append(np.asarray(sequence))</span><br><span class="line">        <span class="keyword">return</span> sequences</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sequences_to_texts</span>(<span class="params">self, sequences</span>):</span><br><span class="line">        texts = []</span><br><span class="line">        <span class="keyword">for</span> sequence <span class="keyword">in</span> sequences:</span><br><span class="line">            text = []</span><br><span class="line">            <span class="keyword">for</span> index <span class="keyword">in</span> sequence:</span><br><span class="line">                text.append(self.index_to_token.get(index, self.oov_token))</span><br><span class="line">            texts.append(self.separator.join([token <span class="keyword">for</span> token <span class="keyword">in</span> text]))</span><br><span class="line">        <span class="keyword">return</span> texts</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save</span>(<span class="params">self, fp</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(fp, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            contents = &#123;</span><br><span class="line">                <span class="string">&quot;char_level&quot;</span>: self.char_level,</span><br><span class="line">                <span class="string">&quot;oov_token&quot;</span>: self.oov_token,</span><br><span class="line">                <span class="string">&quot;token_to_index&quot;</span>: self.token_to_index</span><br><span class="line">            &#125;</span><br><span class="line">            json.dump(contents, fp, indent=<span class="number">4</span>, sort_keys=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load</span>(<span class="params">cls, fp</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(fp, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            kwargs = json.load(fp=fp)</span><br><span class="line">        <span class="keyword">return</span> cls(**kwargs)</span><br></pre></td></tr></table></figure>
<p>本次实验我们限制tokens的数量为500个(停用词已删除)，其中包括两个占位的。如果您的计算资源足够，可以使用更大的tokens数量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Tokenize</span></span><br><span class="line">tokenizer = Tokenizer(char_level=<span class="literal">False</span>, num_tokens=<span class="number">500</span>)</span><br><span class="line">tokenizer.fit_on_texts(texts=X_train)</span><br><span class="line">VOCAB_SIZE = <span class="built_in">len</span>(tokenizer)</span><br><span class="line"><span class="built_in">print</span> (tokenizer)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &lt;Tokenizer(num_tokens=500)&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Sample of tokens</span></span><br><span class="line"><span class="built_in">print</span> (take(<span class="number">10</span>, tokenizer.token_to_index.items()))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;least freq token&#x27;s freq: <span class="subst">&#123;tokenizer.min_token_freq&#125;</span>&quot;</span>) <span class="comment"># use this to adjust num_tokens</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># [(&#x27;&lt;PAD&gt;&#x27;, 0), (&#x27;&lt;UNK&gt;&#x27;, 1), (&#x27;39&#x27;, 2), (&#x27;b&#x27;, 3), (&#x27;gt&#x27;, 4), (&#x27;lt&#x27;, 5), (&#x27;us&#x27;, 6), (&#x27;new&#x27;, 7), (&#x27;oil&#x27;, 8), (&#x27;microsoft&#x27;, 9)]</span></span><br><span class="line"><span class="comment"># least freq token&#x27;s freq: 166</span></span><br></pre></td></tr></table></figure>
<p>Ok，接下来将我们文本数据全部token化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Convert texts to sequences of indices</span></span><br><span class="line">X_train = tokenizer.texts_to_sequences(X_train)</span><br><span class="line">X_val = tokenizer.texts_to_sequences(X_val)</span><br><span class="line">X_test = tokenizer.texts_to_sequences(X_test)</span><br><span class="line">preprocessed_text = tokenizer.sequences_to_texts([X_train[<span class="number">0</span>]])[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;Text to indices:\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  (preprocessed) → <span class="subst">&#123;preprocessed_text&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  (tokenized) → <span class="subst">&#123;X_train[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Text to indices:</span></span><br><span class="line"><span class="comment">#   (preprocessed) → ibm wins time talks &lt;UNK&gt; case</span></span><br><span class="line"><span class="comment">#   (tokenized) → [ 31  32  69  26   1 100]</span></span><br></pre></td></tr></table></figure>
<h2 id="One-hot-encoding">One-hot encoding</h2>
<p>One-hot编码是一种将离散变量表示为二进制向量的技术。它允许我们以一种模型可以理解的方式来表示数据，并且不受token的实际值的影响。</p>
<p>举个例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设我们有个只含5个字符的词表：</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;a&quot;</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="string">&quot;e&quot;</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">&quot;i&quot;</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="string">&quot;o&quot;</span>: <span class="number">3</span>,</span><br><span class="line">    <span class="string">&quot;u&quot;</span>: <span class="number">4</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 那么文本 aou 就会表示成一个二维矩阵：</span></span><br><span class="line"><span class="comment"># 列对应着词表，而每一行表示单个token的二进制向量（只在词表对应位置置为1，其他位置为0）</span></span><br><span class="line">[[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]]</span><br></pre></td></tr></table></figure>
<p>我们手动实现一下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">to_categorical</span>(<span class="params">seq, num_classes</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;One-hot encode a sequence of tokens.&quot;&quot;&quot;</span></span><br><span class="line">    one_hot = np.zeros((<span class="built_in">len</span>(seq), num_classes))</span><br><span class="line">    <span class="keyword">for</span> i, item <span class="keyword">in</span> <span class="built_in">enumerate</span>(seq):</span><br><span class="line">        one_hot[i, item] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> one_hot</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># One-hot encoding</span></span><br><span class="line"><span class="built_in">print</span> (X_train[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span> (<span class="built_in">len</span>(X_train[<span class="number">0</span>]))</span><br><span class="line">cat = to_categorical(seq=X_train[<span class="number">0</span>], num_classes=<span class="built_in">len</span>(tokenizer))</span><br><span class="line"><span class="built_in">print</span> (cat)</span><br><span class="line"><span class="built_in">print</span> (cat.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># [ 31  32  69  26   1 100]</span></span><br><span class="line"><span class="comment"># 6</span></span><br><span class="line"><span class="comment"># [[0. 0. 0. ... 0. 0. 0.]</span></span><br><span class="line"><span class="comment">#  [0. 0. 0. ... 0. 0. 0.]</span></span><br><span class="line"><span class="comment">#  [0. 0. 0. ... 0. 0. 0.]</span></span><br><span class="line"><span class="comment">#  [0. 0. 0. ... 0. 0. 0.]</span></span><br><span class="line"><span class="comment">#  [0. 1. 0. ... 0. 0. 0.]</span></span><br><span class="line"><span class="comment">#  [0. 0. 0. ... 0. 0. 0.]]</span></span><br><span class="line"><span class="comment"># (6, 500)</span></span><br></pre></td></tr></table></figure>
<p>接下来需要将我们的数据进行one-hot编码处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Convert tokens to one-hot</span></span><br><span class="line">vocab_size = <span class="built_in">len</span>(tokenizer)</span><br><span class="line">X_train = [to_categorical(seq, num_classes=vocab_size) <span class="keyword">for</span> seq <span class="keyword">in</span> X_train]</span><br><span class="line">X_val = [to_categorical(seq, num_classes=vocab_size) <span class="keyword">for</span> seq <span class="keyword">in</span> X_val]</span><br><span class="line">X_test = [to_categorical(seq, num_classes=vocab_size) <span class="keyword">for</span> seq <span class="keyword">in</span> X_test]</span><br></pre></td></tr></table></figure>
<h2 id="Padding">Padding</h2>
<p>由于我们的数据是不定长的新闻标题，而模型能够处理的是相同形状的数据，所以引入padding来预处理数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pad_sequences</span>(<span class="params">sequences, max_seq_len=<span class="number">0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Pad sequences to max length in sequence.&quot;&quot;&quot;</span></span><br><span class="line">    max_seq_len = <span class="built_in">max</span>(max_seq_len, <span class="built_in">max</span>(<span class="built_in">len</span>(sequence) <span class="keyword">for</span> sequence <span class="keyword">in</span> sequences))</span><br><span class="line">    num_classes = sequences[<span class="number">0</span>].shape[-<span class="number">1</span>]</span><br><span class="line">    padded_sequences = np.zeros((<span class="built_in">len</span>(sequences), max_seq_len, num_classes))</span><br><span class="line">    <span class="keyword">for</span> i, sequence <span class="keyword">in</span> <span class="built_in">enumerate</span>(sequences):</span><br><span class="line">        padded_sequences[i][:<span class="built_in">len</span>(sequence)] = sequence</span><br><span class="line">    <span class="keyword">return</span> padded_sequences</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3D sequences</span></span><br><span class="line"><span class="built_in">print</span> (X_train[<span class="number">0</span>].shape, X_train[<span class="number">1</span>].shape, X_train[<span class="number">2</span>].shape)</span><br><span class="line">padded = pad_sequences(X_train[<span class="number">0</span>:<span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span> (padded.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># (6, 500) (8, 500) (6, 500)</span></span><br><span class="line"><span class="comment"># (3, 8, 500)</span></span><br></pre></td></tr></table></figure>
<h2 id="Dataset">Dataset</h2>
<p>一如上篇文章里介绍的，我们需要把数据放在 Dataset 中，并使用 DataLoader 来有效地创建用于训练和验证的批次。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line">FILTER_SIZE = <span class="number">1</span> <span class="comment"># unigram</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Dataset</span>(torch.utils.data.Dataset):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, X, y, max_filter_size</span>):</span><br><span class="line">        self.X = X</span><br><span class="line">        self.y = y</span><br><span class="line">        self.max_filter_size = max_filter_size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__str__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;&lt;Dataset(N=<span class="subst">&#123;<span class="built_in">len</span>(self)&#125;</span>)&gt;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        X = self.X[index]</span><br><span class="line">        y = self.y[index]</span><br><span class="line">        <span class="keyword">return</span> [X, y]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">self, batch</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Processing on a batch.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Get inputs</span></span><br><span class="line">        batch = np.array(batch)</span><br><span class="line">        X = batch[:, <span class="number">0</span>]</span><br><span class="line">        y = batch[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Pad sequences</span></span><br><span class="line">        X = pad_sequences(X, max_seq_len=self.max_filter_size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Cast</span></span><br><span class="line">        X = torch.FloatTensor(X.astype(np.int32))</span><br><span class="line">        y = torch.LongTensor(y.astype(np.int32))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> X, y</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_dataloader</span>(<span class="params">self, batch_size, shuffle=<span class="literal">False</span>, drop_last=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="keyword">return</span> torch.utils.data.DataLoader(</span><br><span class="line">            dataset=self, batch_size=batch_size, collate_fn=self.collate_fn,</span><br><span class="line">            shuffle=shuffle, drop_last=drop_last, pin_memory=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create datasets for embedding</span></span><br><span class="line">train_dataset = Dataset(X=X_train, y=y_train, max_filter_size=FILTER_SIZE)</span><br><span class="line">val_dataset = Dataset(X=X_val, y=y_val, max_filter_size=FILTER_SIZE)</span><br><span class="line">test_dataset = Dataset(X=X_test, y=y_test, max_filter_size=FILTER_SIZE)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;Datasets:\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  Train dataset:<span class="subst">&#123;train_dataset.__str__()&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  Val dataset: <span class="subst">&#123;val_dataset.__str__()&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  Test dataset: <span class="subst">&#123;test_dataset.__str__()&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">&quot;Sample point:\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  X: <span class="subst">&#123;test_dataset[<span class="number">0</span>][<span class="number">0</span>]&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  y: <span class="subst">&#123;test_dataset[<span class="number">0</span>][<span class="number">1</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Datasets:</span></span><br><span class="line"><span class="comment">#   Train dataset:&lt;Dataset(N=84000)&gt;</span></span><br><span class="line"><span class="comment">#   Val dataset: &lt;Dataset(N=18000)&gt;</span></span><br><span class="line"><span class="comment">#   Test dataset: &lt;Dataset(N=18000)&gt;</span></span><br><span class="line"><span class="comment"># Sample point:</span></span><br><span class="line"><span class="comment">#   X: [[0. 1. 0. ... 0. 0. 0.]</span></span><br><span class="line"><span class="comment">#  [0. 1. 0. ... 0. 0. 0.]</span></span><br><span class="line"><span class="comment">#  [0. 0. 0. ... 0. 0. 0.]]</span></span><br><span class="line"><span class="comment">#   y: 1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create dataloaders</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">train_dataloader = train_dataset.create_dataloader(batch_size=batch_size)</span><br><span class="line">val_dataloader = val_dataset.create_dataloader(batch_size=batch_size)</span><br><span class="line">test_dataloader = test_dataset.create_dataloader(batch_size=batch_size)</span><br><span class="line">batch_X, batch_y = <span class="built_in">next</span>(<span class="built_in">iter</span>(test_dataloader))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;Sample batch:\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  X: <span class="subst">&#123;<span class="built_in">list</span>(batch_X.size())&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  y: <span class="subst">&#123;<span class="built_in">list</span>(batch_y.size())&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">&quot;Sample point:\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  X: <span class="subst">&#123;batch_X[<span class="number">0</span>]&#125;</span>\n&quot;</span></span><br><span class="line">    <span class="string">f&quot;  y: <span class="subst">&#123;batch_y[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Sample batch:</span></span><br><span class="line"><span class="comment">#   X: [64, 15, 500]</span></span><br><span class="line"><span class="comment">#   y: [64]</span></span><br><span class="line"><span class="comment"># Sample point:</span></span><br><span class="line"><span class="comment">#   X: tensor([[0., 1., 0.,  ..., 0., 0., 0.],</span></span><br><span class="line"><span class="comment">#         [0., 1., 0.,  ..., 0., 0., 0.],</span></span><br><span class="line"><span class="comment">#         [0., 0., 0.,  ..., 0., 0., 0.],</span></span><br><span class="line"><span class="comment">#         ...,</span></span><br><span class="line"><span class="comment">#         [0., 0., 0.,  ..., 0., 0., 0.],</span></span><br><span class="line"><span class="comment">#         [0., 0., 0.,  ..., 0., 0., 0.],</span></span><br><span class="line"><span class="comment">#         [0., 0., 0.,  ..., 0., 0., 0.]])</span></span><br><span class="line"><span class="comment">#   y: 1</span></span><br><span class="line"><span class="comment"># </span></span><br></pre></td></tr></table></figure>
<h2 id="CNN">CNN</h2>
<p>接下来呢要进入本篇的重点，CNN了。</p>
<h3 id="Inputs">Inputs</h3>
<p>下面这个简单的示例里，我们随机给出了N个样本，每个样本有8个token，而我们的词表大小是10个。</p>
<p>也就意味着，我们inputs的形状是 (N, 8, 10)</p>
<p>但需要注意的是，当我使用PyTorch处理CNN时，通道数需要在第二个维度，也就意味着，在这个例子里，我们的inputs的形状得是 (N, 10, 8)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Assume all our inputs are padded to have the same num of tokens.</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">max_seq_len = <span class="number">8</span>  <span class="comment"># tokens per input</span></span><br><span class="line">vocab_size = <span class="number">10</span>  <span class="comment"># one-hot size</span></span><br><span class="line">x = torch.randn(batch_size, max_seq_len, vocab_size)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;X: <span class="subst">&#123;x.shape&#125;</span>&quot;</span>)</span><br><span class="line">x = x.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;X: <span class="subst">&#123;x.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># X: torch.Size([64, 8, 10])</span></span><br><span class="line"><span class="comment"># X: torch.Size([64, 10, 8])</span></span><br></pre></td></tr></table></figure>
<p><img src="//s3.mindex.xyz/tmp/fea49de2fb514aafde1b3545c5163058.png" alt=""></p>
<h3 id="Filters">Filters</h3>
<p>在下面的动画中，我们将卷积核和输入简化成2D，以便于可视化，而且实际上值并不总是是0或1，而是任意的浮点数。</p>
<p><img src="//s3.mindex.xyz/tmp/1a58a0c1e58cd3f543995ecee0eb71d4.gif" alt=""></p>
<p>现在回到我们的示例数据，单个样本的形状是(8, 10) [max_seq_len, vocab_size]，然后我们考虑用50个形状是(1, 3)的一维卷积来提取数据的特征，由于我们的数据的通道数是10 （num_channels = vocab_size = one_hot_size = 10）, 这边意味着这个卷积核的形状便是 (3, 10, 50) [kernel_size, vocab_size, num_filters]</p>
<p><img src="//s3.mindex.xyz/tmp/18c83d441855deaf7671fea9f9f26bdc.png" alt=""></p>
<p>这里有两个关键的概念，步长(stride) 和 填充(padding). 详见下图</p>
<p><img src="//s3.mindex.xyz/tmp/49dc51e7b89f5215577c01e74a17ce73.png" alt=""></p>
<p>这里采用一维卷积<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d" title="Conv1d">Conv1D</a>来处理示例数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Convolutional filters (VALID padding)</span></span><br><span class="line">num_filters = <span class="number">50</span> <span class="comment"># num filters</span></span><br><span class="line">filter_size = <span class="number">3</span></span><br><span class="line">stride = <span class="number">1</span></span><br><span class="line">padding = <span class="number">0</span>  <span class="comment"># valid padding (no padding)</span></span><br><span class="line">conv1 = nn.Conv1d(in_channels=vocab_size, out_channels=num_filters,</span><br><span class="line">                  kernel_size=filter_size, stride=stride,</span><br><span class="line">                  padding=padding, padding_mode=<span class="string">&quot;zeros&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;conv: <span class="subst">&#123;conv1.weight.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># conv: torch.Size([50, 10, 3])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Forward pass</span></span><br><span class="line">z = conv1(x)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;z: <span class="subst">&#123;z.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># z: torch.Size([64, 50, 6])</span></span><br></pre></td></tr></table></figure>
<p><img src="//s3.mindex.xyz/tmp/0fcb44386fcdfdd5c7e56e79be18515a.png" alt=""></p>
<p>如你所见，我们输入数据max_seq_len=8，而经过卷积后的output的长度却是6。如果需要保证长度一致，那么就需要引入padding了。<br>
$$<br>
\begin{split}<br>
W = \frac{W - F + 2P}{S} + 1 \\<br>
P = \frac{S(W - 1) - W + F}{2}<br>
\end{split}<br>
$$</p>
<p>如果P不是一个整数，考虑向上取整(math.ceil)在右侧填充。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Convolutional filters (SAME padding)</span></span><br><span class="line">num_filters = <span class="number">50</span> <span class="comment"># num filters</span></span><br><span class="line">filter_size = <span class="number">3</span></span><br><span class="line">stride = <span class="number">1</span></span><br><span class="line">padding = <span class="number">0</span>  <span class="comment"># valid padding (no padding)</span></span><br><span class="line">conv = nn.Conv1d(in_channels=vocab_size, out_channels=num_filters,</span><br><span class="line">                 kernel_size=filter_size, stride=stride,</span><br><span class="line">                 padding=padding, padding_mode=<span class="string">&quot;zeros&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;conv: <span class="subst">&#123;conv.weight.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># conv: torch.Size([50, 10, 3])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># `SAME` padding</span></span><br><span class="line">padding_left = <span class="built_in">int</span>((conv.stride[<span class="number">0</span>]*(max_seq_len-<span class="number">1</span>) - max_seq_len + filter_size) / <span class="number">2</span>)</span><br><span class="line">padding_right =<span class="built_in">int</span>(math.ceil((conv.stride[<span class="number">0</span>]*(max_seq_len-<span class="number">1</span>) - max_seq_len + filter_size) / <span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;padding: <span class="subst">&#123;(padding_left, padding_right)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># padding: (1, 1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Forward pass</span></span><br><span class="line">z = conv(F.pad(x, (padding_left, padding_right)))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;z: <span class="subst">&#123;z.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># z: torch.Size([64, 50, 8])</span></span><br></pre></td></tr></table></figure>
<p>未来我们会探索更高维度的卷积层。包括使用Conv2D来处理3D数据（图像、字符级别文本等），使用Conv3D来处理4D数据（视频、时间序列数据等）</p>
<h3 id="Pooling">Pooling</h3>
<p>池化是一种用于简化下游计算的方法，通过将高维特征图总结为较低维特征图来减少冗余信息。在卷积滤波器对输入进行处理后产生的特征映射中，由于卷积和重叠的性质，会存在大量的冗余信息。池化操作可以采用最大值或平均值等方式。下面是一个池化的示例：假设来自卷积层的输出是4x4的特征图，我们使用2x2的最大池化过滤器进行处理。</p>
<p><img src="//s3.mindex.xyz/tmp/16910ad2e084e2b567c1cfadffcabab4.png" alt=""></p>
<p>在这个例子里，我们使用<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.MaxPool1d.html#torch.nn.MaxPool1d" title="MaxPool1d">MaxPool1D</a>取一个max值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Max pooling</span></span><br><span class="line">pool_output = F.max_pool1d(z, z.size(<span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;Size: <span class="subst">&#123;pool_output.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Size: torch.Size([64, 50, 1])</span></span><br></pre></td></tr></table></figure>
<h3 id="Batch-normalization">Batch normalization</h3>
<p>在构建模型前，需要讨论的最后一个主题便是<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1502.03167" title="batch normalization">batch normalization</a>.  它是一种对来自前一层激活的标准化操作，使其均值为0，标准差为1。</p>
<p>在以前的笔记本中，我们对输入进行标准化，以便模型能够更快地进行优化，并提高学习率。这里采用相同的概念，但我们在重复的前向传递过程中保持标准化的值，以进一步帮助优化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Batch normalization</span></span><br><span class="line">batch_norm = nn.BatchNorm1d(num_features=num_filters)</span><br><span class="line">z = batch_norm(conv(x)) <span class="comment"># applied to activations (after conv layer &amp; before pooling)</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;z: <span class="subst">&#123;z.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># z: torch.Size([64, 50, 6])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Mean and std before batchnorm</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;mean: <span class="subst">&#123;torch.mean(conv(x)):<span class="number">.2</span>f&#125;</span>, std: <span class="subst">&#123;torch.std(conv(x)):<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># mean: -0.00, std: 0.59</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Mean and std after batchnorm</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;mean: <span class="subst">&#123;torch.mean(z):<span class="number">.2</span>f&#125;</span>, std: <span class="subst">&#123;torch.std(z):<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># mean: -0.00, std: 1.00</span></span><br></pre></td></tr></table></figure>
<h2 id="Modling">Modling</h2>
<h3 id="Model">Model</h3>
<p>可视化一下模型的前向传播.</p>
<ul>
<li>首先对输入tokenizer化 (batch_size, max_seq_len)</li>
<li>然后，one-hot编码 (batch_size, max_seq_len, vocab_size)</li>
<li>接下来，使用filters（filter_size, vocab_size, num_filter)进行卷积，然后批归一化。这里我们的filters相当于一个n-gram检测器。</li>
<li>紧跟着，应用max polling，从特征图中提取最相关信息</li>
<li>再接一个含dropout的全连接层</li>
<li>最后再一个softmax全连接层以输出最终的类别概率</li>
</ul>
<p><img src="//s3.mindex.xyz/tmp/3984d8e8ac31581c8b9525fd221e275c.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">NUM_FILTERS = <span class="number">50</span></span><br><span class="line">HIDDEN_DIM = <span class="number">100</span></span><br><span class="line">DROPOUT_P = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, num_filters, filter_size,</span></span><br><span class="line"><span class="params">                 hidden_dim, dropout_p, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(CNN, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># COnvolutional filters</span></span><br><span class="line">        self.filter_size = filter_size</span><br><span class="line">        self.conv = nn.Conv1d(</span><br><span class="line">            in_channels=vocab_size, out_channels=num_filters,</span><br><span class="line">            kernel_size=filter_size, stride=<span class="number">1</span>, padding=<span class="number">0</span>, padding_mode=<span class="string">&#x27;zeros&#x27;</span>)</span><br><span class="line">        self.batch_norm = nn.BatchNorm1d(num_features=num_filters)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># FC layers</span></span><br><span class="line">        self.fc1 = nn.Linear(num_filters, hidden_dim)</span><br><span class="line">        self.dropout = nn.Dropout(dropout_p)</span><br><span class="line">        self.fc2 = nn.Linear(hidden_dim, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs, channel_first=<span class="literal">False</span>,</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Rearrange input so num_channels is in dim 1 (N, C, L)</span></span><br><span class="line">        x_in, = inputs</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> channel_first:</span><br><span class="line">            x_in = x_in.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Padding for `SAME` padding</span></span><br><span class="line">        max_seq_len = x_in.shape[<span class="number">2</span>]</span><br><span class="line">        padding_left = <span class="built_in">int</span>((self.conv.stride[<span class="number">0</span>]*(max_seq_len-<span class="number">1</span>) - max_seq_len + self.filter_size)/<span class="number">2</span>)</span><br><span class="line">        padding_right = <span class="built_in">int</span>(math.ceil((self.conv.stride[<span class="number">0</span>]*(max_seq_len-<span class="number">1</span>) - max_seq_len + self.filter_size)/<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Conv outputs</span></span><br><span class="line">        z = self.conv(F.pad(x_in, (padding_left, padding_right)))</span><br><span class="line">        z = F.max_pool1d(z, z.size(<span class="number">2</span>)).squeeze(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># FC layer</span></span><br><span class="line">        z = self.fc1(z)</span><br><span class="line">        z = self.dropout(z)</span><br><span class="line">        z = self.fc2(z)</span><br><span class="line">        <span class="keyword">return</span> z</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize model</span></span><br><span class="line">model = CNN(vocab_size=VOCAB_SIZE, num_filters=NUM_FILTERS, filter_size=FILTER_SIZE,</span><br><span class="line">            hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)</span><br><span class="line">model = model.to(device)</span><br><span class="line"><span class="built_in">print</span> (model.named_parameters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &lt;bound method Module.named_parameters of CNN(</span></span><br><span class="line"><span class="comment">#   (conv): Conv1d(500, 50, kernel_size=(1,), stride=(1,))</span></span><br><span class="line"><span class="comment">#   (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span></span><br><span class="line"><span class="comment">#   (fc1): Linear(in_features=50, out_features=100, bias=True)</span></span><br><span class="line"><span class="comment">#   (dropout): Dropout(p=0.1, inplace=False)</span></span><br><span class="line"><span class="comment">#   (fc2): Linear(in_features=100, out_features=4, bias=True)</span></span><br><span class="line"><span class="comment"># )&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="Training">Training</h3>
<p>接下来，利用到<a href="http://neo1989.net/Way2AI/Way2AI-utilities/" title="PyTorch实现神经网络的基本套路">《PyTorch实现神经网络的基本套路》</a> 里介绍到Trainer类。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> Adam</span><br><span class="line"></span><br><span class="line">LEARNING_RATE = <span class="number">1e-3</span></span><br><span class="line">PATIENCE = <span class="number">5</span></span><br><span class="line">NUM_EPOCHS = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Trainer</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model, device, loss_fn=<span class="literal">None</span>, optimizer=<span class="literal">None</span>, scheduler=<span class="literal">None</span></span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Set params</span></span><br><span class="line">        self.model = model</span><br><span class="line">        self.device = device</span><br><span class="line">        self.loss_fn = loss_fn</span><br><span class="line">        self.optimizer = optimizer</span><br><span class="line">        self.scheduler = scheduler</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">self, dataloader</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Train step.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Set model to train mode</span></span><br><span class="line">        self.model.train()</span><br><span class="line">        loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Iterate over train batches</span></span><br><span class="line">        <span class="keyword">for</span> i, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Step</span></span><br><span class="line">            batch = [item.to(self.device) <span class="keyword">for</span> item <span class="keyword">in</span> batch]  <span class="comment"># Set device</span></span><br><span class="line">            inputs, targets = batch[:-<span class="number">1</span>], batch[-<span class="number">1</span>]</span><br><span class="line">            self.optimizer.zero_grad()  <span class="comment"># Reset gradients</span></span><br><span class="line">            z = self.model(inputs)  <span class="comment"># Forward pass</span></span><br><span class="line">            J = self.loss_fn(z, targets)  <span class="comment"># Define loss</span></span><br><span class="line">            J.backward()  <span class="comment"># Backward pass</span></span><br><span class="line">            self.optimizer.step()  <span class="comment"># Update weights</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Cumulative Metrics</span></span><br><span class="line">            loss += (J.detach().item() - loss) / (i + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">eval_step</span>(<span class="params">self, dataloader</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Validation or test step.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Set model to eval mode</span></span><br><span class="line">        self.model.<span class="built_in">eval</span>()</span><br><span class="line">        loss = <span class="number">0.0</span></span><br><span class="line">        y_trues, y_probs = [], []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Iterate over val batches</span></span><br><span class="line">        <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">            <span class="keyword">for</span> i, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Step</span></span><br><span class="line">                batch = [item.to(self.device) <span class="keyword">for</span> item <span class="keyword">in</span> batch]  <span class="comment"># Set device</span></span><br><span class="line">                inputs, y_true = batch[:-<span class="number">1</span>], batch[-<span class="number">1</span>]</span><br><span class="line">                z = self.model(inputs)  <span class="comment"># Forward pass</span></span><br><span class="line">                J = self.loss_fn(z, y_true).item()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Cumulative Metrics</span></span><br><span class="line">                loss += (J - loss) / (i + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Store outputs</span></span><br><span class="line">                y_prob = F.softmax(z).cpu().numpy()</span><br><span class="line">                y_probs.extend(y_prob)</span><br><span class="line">                y_trues.extend(y_true.cpu().numpy())</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> loss, np.vstack(y_trues), np.vstack(y_probs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict_step</span>(<span class="params">self, dataloader</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Prediction step.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Set model to eval mode</span></span><br><span class="line">        self.model.<span class="built_in">eval</span>()</span><br><span class="line">        y_probs = []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Iterate over val batches</span></span><br><span class="line">        <span class="keyword">with</span> torch.inference_mode():</span><br><span class="line">            <span class="keyword">for</span> i, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Forward pass w/ inputs</span></span><br><span class="line">                inputs, targets = batch[:-<span class="number">1</span>], batch[-<span class="number">1</span>]</span><br><span class="line">                z = self.model(inputs)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Store outputs</span></span><br><span class="line">                y_prob = F.softmax(z).cpu().numpy()</span><br><span class="line">                y_probs.extend(y_prob)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> np.vstack(y_probs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, num_epochs, patience, train_dataloader, val_dataloader</span>):</span><br><span class="line">        best_val_loss = np.inf</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">            <span class="comment"># Steps</span></span><br><span class="line">            train_loss = self.train_step(dataloader=train_dataloader)</span><br><span class="line">            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)</span><br><span class="line">            self.scheduler.step(val_loss)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Early stopping</span></span><br><span class="line">            <span class="keyword">if</span> val_loss &lt; best_val_loss:</span><br><span class="line">                best_val_loss = val_loss</span><br><span class="line">                best_model = self.model</span><br><span class="line">                _patience = patience  <span class="comment"># reset _patience</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                _patience -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> _patience:  <span class="comment"># 0</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Stopping early!&quot;</span>)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Logging</span></span><br><span class="line">            <span class="built_in">print</span>(</span><br><span class="line">                <span class="string">f&quot;Epoch: <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span> | &quot;</span></span><br><span class="line">                <span class="string">f&quot;train_loss: <span class="subst">&#123;train_loss:<span class="number">.5</span>f&#125;</span>, &quot;</span></span><br><span class="line">                <span class="string">f&quot;val_loss: <span class="subst">&#123;val_loss:<span class="number">.5</span>f&#125;</span>, &quot;</span></span><br><span class="line">                <span class="string">f&quot;lr: <span class="subst">&#123;self.optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>]:<span class="number">.2</span>E&#125;</span>, &quot;</span></span><br><span class="line">                <span class="string">f&quot;_patience: <span class="subst">&#123;_patience&#125;</span>&quot;</span></span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">return</span> best_model</span><br></pre></td></tr></table></figure>
<p>定义必要的组件，然后开始训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Defince Loss</span></span><br><span class="line">class_weights_tensor = torch.Tensor(<span class="built_in">list</span>(class_weights.values())).to(device)</span><br><span class="line">loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define optimizer &amp; scheduler</span></span><br><span class="line">optimizer = Adam(model.parameters(), lr=LEARNING_RATE)</span><br><span class="line">scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(</span><br><span class="line">    optimizer, mode=<span class="string">&quot;min&quot;</span>, factor=<span class="number">0.1</span>, patience=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train module</span></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model, device=device, loss_fn=loss_fn,</span><br><span class="line">    optimizer=optimizer, scheduler=scheduler)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train</span></span><br><span class="line">best_model = trainer.train(</span><br><span class="line">    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Epoch: 1 | train_loss: 0.86713, val_loss: 0.79795, lr: 1.00E-03, _patience: 5</span></span><br><span class="line"><span class="comment"># Epoch: 2 | train_loss: 0.77799, val_loss: 0.79238, lr: 1.00E-03, _patience: 5</span></span><br><span class="line"><span class="comment"># Epoch: 3 | train_loss: 0.77053, val_loss: 0.78976, lr: 1.00E-03, _patience: 5</span></span><br><span class="line"><span class="comment"># Epoch: 4 | train_loss: 0.76625, val_loss: 0.78882, lr: 1.00E-03, _patience: 5</span></span><br><span class="line"><span class="comment"># Epoch: 5 | train_loss: 0.76305, val_loss: 0.78799, lr: 1.00E-03, _patience: 5</span></span><br><span class="line"><span class="comment"># Epoch: 6 | train_loss: 0.76027, val_loss: 0.78786, lr: 1.00E-03, _patience: 5</span></span><br><span class="line"><span class="comment"># Epoch: 7 | train_loss: 0.75813, val_loss: 0.78810, lr: 1.00E-03, _patience: 4</span></span><br><span class="line"><span class="comment"># Epoch: 8 | train_loss: 0.75588, val_loss: 0.78725, lr: 1.00E-03, _patience: 5</span></span><br><span class="line"><span class="comment"># Epoch: 9 | train_loss: 0.75429, val_loss: 0.78740, lr: 1.00E-03, _patience: 4</span></span><br><span class="line"><span class="comment"># Epoch: 10 | train_loss: 0.75270, val_loss: 0.78747, lr: 1.00E-03, _patience: 3</span></span><br></pre></td></tr></table></figure>
<h3 id="Evaluaton">Evaluaton</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_fscore_support</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_metrics</span>(<span class="params">y_true, y_pred, classes</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Per-class performance metrics.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Performance</span></span><br><span class="line">    performance = &#123;<span class="string">&quot;overall&quot;</span>: &#123;&#125;, <span class="string">&quot;class&quot;</span>: &#123;&#125;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Overall performance</span></span><br><span class="line">    metrics = precision_recall_fscore_support(y_true, y_pred, average=<span class="string">&quot;weighted&quot;</span>)</span><br><span class="line">    performance[<span class="string">&quot;overall&quot;</span>][<span class="string">&quot;precision&quot;</span>] = metrics[<span class="number">0</span>]</span><br><span class="line">    performance[<span class="string">&quot;overall&quot;</span>][<span class="string">&quot;recall&quot;</span>] = metrics[<span class="number">1</span>]</span><br><span class="line">    performance[<span class="string">&quot;overall&quot;</span>][<span class="string">&quot;f1&quot;</span>] = metrics[<span class="number">2</span>]</span><br><span class="line">    performance[<span class="string">&quot;overall&quot;</span>][<span class="string">&quot;num_samples&quot;</span>] = np.float64(<span class="built_in">len</span>(y_true))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Per-class performance</span></span><br><span class="line">    metrics = precision_recall_fscore_support(y_true, y_pred, average=<span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(classes)):</span><br><span class="line">        performance[<span class="string">&quot;class&quot;</span>][classes[i]] = &#123;</span><br><span class="line">            <span class="string">&quot;precision&quot;</span>: metrics[<span class="number">0</span>][i],</span><br><span class="line">            <span class="string">&quot;recall&quot;</span>: metrics[<span class="number">1</span>][i],</span><br><span class="line">            <span class="string">&quot;f1&quot;</span>: metrics[<span class="number">2</span>][i],</span><br><span class="line">            <span class="string">&quot;num_samples&quot;</span>: np.float64(metrics[<span class="number">3</span>][i]),</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> performance</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get predictions</span></span><br><span class="line">test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)</span><br><span class="line">y_pred = np.argmax(y_prob, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Determine performance</span></span><br><span class="line">performance = get_metrics(</span><br><span class="line">    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)</span><br><span class="line"><span class="built_in">print</span> (json.dumps(performance[<span class="string">&quot;overall&quot;</span>], indent=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &#123;</span></span><br><span class="line"><span class="comment">#   &quot;precision&quot;: 0.7074944756886696,</span></span><br><span class="line"><span class="comment">#   &quot;recall&quot;: 0.6868333333333333,</span></span><br><span class="line"><span class="comment">#   &quot;f1&quot;: 0.6866617275444412,</span></span><br><span class="line"><span class="comment">#   &quot;num_samples&quot;: 18000.0</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br></pre></td></tr></table></figure>
<p>保存一些必要的模型数据，以供后续能够完整的加载和使用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Save artifacts</span></span><br><span class="line"><span class="built_in">dir</span> = Path(<span class="string">&quot;cnn&quot;</span>)</span><br><span class="line"><span class="built_in">dir</span>.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">label_encoder.save(fp=Path(<span class="built_in">dir</span>, <span class="string">&quot;label_encoder.json&quot;</span>))</span><br><span class="line">tokenizer.save(fp=Path(<span class="built_in">dir</span>, <span class="string">&#x27;tokenizer.json&#x27;</span>))</span><br><span class="line">torch.save(best_model.state_dict(), Path(<span class="built_in">dir</span>, <span class="string">&quot;model.pt&quot;</span>))</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(Path(<span class="built_in">dir</span>, <span class="string">&#x27;performance.json&#x27;</span>), <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    json.dump(performance, indent=<span class="number">2</span>, sort_keys=<span class="literal">False</span>, fp=fp)</span><br></pre></td></tr></table></figure>
<h3 id="Inference">Inference</h3>
<p>接下来看看如何利用模型进行新的推理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load artifacts</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">label_encoder = LabelEncoder.load(fp=Path(<span class="built_in">dir</span>, <span class="string">&quot;label_encoder.json&quot;</span>))</span><br><span class="line">tokenizer = Tokenizer.load(fp=Path(<span class="built_in">dir</span>, <span class="string">&#x27;tokenizer.json&#x27;</span>))</span><br><span class="line">model = CNN(</span><br><span class="line">    vocab_size=VOCAB_SIZE, num_filters=NUM_FILTERS, filter_size=FILTER_SIZE,</span><br><span class="line">    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)</span><br><span class="line">model.load_state_dict(torch.load(Path(<span class="built_in">dir</span>, <span class="string">&quot;model.pt&quot;</span>), map_location=device))</span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># CNN(</span></span><br><span class="line"><span class="comment">#   (conv): Conv1d(500, 50, kernel_size=(1,), stride=(1,))</span></span><br><span class="line"><span class="comment">#   (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span></span><br><span class="line"><span class="comment">#   (fc1): Linear(in_features=50, out_features=100, bias=True)</span></span><br><span class="line"><span class="comment">#   (dropout): Dropout(p=0.1, inplace=False)</span></span><br><span class="line"><span class="comment">#   (fc2): Linear(in_features=100, out_features=4, bias=True)</span></span><br><span class="line"><span class="comment"># )</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize trainer</span></span><br><span class="line">trainer = Trainer(model=model, device=device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Dataloader</span></span><br><span class="line">text = <span class="string">&quot;China’s economic recovery fades as services, factory activity show weakness&quot;</span></span><br><span class="line">sequences = tokenizer.texts_to_sequences([preprocess(text)])</span><br><span class="line"><span class="built_in">print</span> (tokenizer.sequences_to_texts(sequences))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># [&#x27;china economic &lt;UNK&gt; &lt;UNK&gt; services &lt;UNK&gt; &lt;UNK&gt; show &lt;UNK&gt;&#x27;]</span></span><br><span class="line"></span><br><span class="line">X = [to_categorical(seq, num_classes=<span class="built_in">len</span>(tokenizer)) <span class="keyword">for</span> seq <span class="keyword">in</span> sequences]</span><br><span class="line">y_filler = label_encoder.encode([label_encoder.classes[<span class="number">0</span>]]*<span class="built_in">len</span>(X))</span><br><span class="line">dataset = Dataset(X=X, y=y_filler, max_filter_size=FILTER_SIZE)</span><br><span class="line">dataloader = dataset.create_dataloader(batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Inference</span></span><br><span class="line">y_prob = trainer.predict_step(dataloader)</span><br><span class="line">y_pred = np.argmax(y_prob, axis=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span> (label_encoder.decode(y_pred))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># [&#x27;Business&#x27;]</span></span><br></pre></td></tr></table></figure>
<p>推理结果是 “China’s economic recovery fades as services, factory activity show weakness” 这篇文章属于 “Business” 这个分类，符合预期。</p>
<p>我们来看一下这个case的具体概率分布</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_probability_distribution</span>(<span class="params">y_prob, classes</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Create a dict of class probabilities from an array.&quot;&quot;&quot;</span></span><br><span class="line">    results = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i, class_ <span class="keyword">in</span> <span class="built_in">enumerate</span>(classes):</span><br><span class="line">        results[class_] = np.float64(y_prob[i])</span><br><span class="line">    sorted_results = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">sorted</span>(</span><br><span class="line">        results.items(), key=<span class="keyword">lambda</span> item: item[<span class="number">1</span>], reverse=<span class="literal">True</span>)&#125;</span><br><span class="line">    <span class="keyword">return</span> sorted_results</span><br><span class="line"></span><br><span class="line"><span class="comment"># Class distributions</span></span><br><span class="line">prob_dist = get_probability_distribution(y_prob=y_prob[<span class="number">0</span>], classes=label_encoder.classes)</span><br><span class="line"><span class="built_in">print</span> (json.dumps(prob_dist, indent=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># &#123;</span></span><br><span class="line"><span class="comment">#   &quot;Business&quot;: 0.7551461458206177,</span></span><br><span class="line"><span class="comment">#   &quot;World&quot;: 0.23087970912456512,</span></span><br><span class="line"><span class="comment">#   &quot;Sci/Tech&quot;: 0.01362547930330038,</span></span><br><span class="line"><span class="comment">#   &quot;Sports&quot;: 0.0003486045461613685</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br></pre></td></tr></table></figure>
<h2 id="Ending">Ending</h2>
<p>本篇给出了一个使用CNN对文本进行分类的完整示例，有很多细节需要深入学习。</p>
<p>但无论如何，先跑起来再说，在战斗中学习战斗。</p>
</div><iframe src="/donate/?AliPayQR=null&amp;WeChatQR=http://s3.mindex.xyz/mp/qrcode-s.jpg&amp;GitHub=http://github.com/neo1989&amp;BTCQR=null&amp;BTCKEY=null&amp;PayPal=null" style="overflow-x:hidden; overflow-y:hidden; border:0xp none #fff; min-height:240px; width:100%;" frameborder="0" scrolling="no"></iframe><div><ul class="post-copyright"><li class="post-copyright-author"><strong>Author: </strong>尼欧</li><li class="post-copyright-link"><strong>Blog Link: </strong><a href="/Way2AI/Way2AI-CNN/">https://neo1989.net/Way2AI/Way2AI-CNN/</a></li><li class="post-copyright-license"><strong>Copyright Declaration: </strong>转载请声明出处。</li></ul></div><br><div class="tags"><a href="/tags/Coder/">Coder</a><a href="/tags/AI/">AI</a><a href="/tags/PyTorch/">PyTorch</a></div><div class="post-nav"><a class="pre" href="/Way2AI/Way2AI-Embeddings-1/">Way2AI · Embeddings （上）</a><a class="next" href="/Notes/NOTE-openai-function-calling/">ChatGPT开放函数调用能力 · 好用到震惊！</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论（请确保 Disqus 可以正常加载）</button></div><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'https://neo1989.net/Way2AI/Way2AI-CNN/';
    this.page.identifier = 'Way2AI/Way2AI-CNN/';
    this.page.title = 'Way2AI · 卷积神经网络';
  };</script><!-- script(type='text/javascript' id='disqus-lazy-load-script').--><!--   $.ajax({--><!--   url: 'https://disqus.com/next/config.json',--><!--   timeout: 2500,--><!--   type: 'GET',--><!--   success: function(){--><!--     var d = document;--><!--     var s = d.createElement('script');--><!--     s.src = '//#{theme.disqus}.disqus.com/embed.js';--><!--     s.setAttribute('data-timestamp', + new Date());--><!--     (d.head || d.body).appendChild(s);--><!--     $('.disqus_click_btn').css('display', 'none');--><!--   },--><!--   error: function() {--><!--     $('.disqus_click_btn').css('display', 'block');--><!--   }--><!--   });--><script type="text/javascript" id="disqus-click-load">$('.btn_click_load').click(() => {  //click to load comments
    (() => { // DON'T EDIT BELOW THIS LINE
        var d = document;
        var s = d.createElement('script');
        s.src = '//neo1989.disqus.com/embed.js';
        s.setAttribute('data-timestamp', + new Date());
        (d.head || d.body).appendChild(s);
    })();
    $('.disqus_click_btn').css('display','none');
});</script><script type="text/javascript" id="disqus-count-script">$(function() {
     var xhr = new XMLHttpRequest();
     xhr.open('GET', '//disqus.com/next/config.json', true);
     xhr.timeout = 2500;
     xhr.onreadystatechange = function () {
       if (xhr.readyState === 4 && xhr.status === 200) {
         $('.post-meta .post-comments-count').show();
         var s = document.createElement('script');
         s.id = 'dsq-count-scr';
         s.src = 'https://neo1989.disqus.com/count.js';
         s.async = true;
         (document.head || document.body).appendChild(s);
       }
     };
     xhr.ontimeout = function () { xhr.abort(); };
     xhr.send(null);
   });
</script></div></div></div></div></div><div class="pure-u-1 pure-u-md-4-6"><div id="footer">Copyright © 2024 <a href="/." rel="nofollow">愚苏记.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/i-yard/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho/maupassant"> Cho.</a></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="/lib/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="/lib/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
  displayAlign: "left"
  });
</script><script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.6/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script><script type="text/javascript" id="maid-script" mermaidoptioins="{&quot;startOnload&quot;:true,&quot;theme&quot;:&quot;forest&quot;}" src="/js/mermaid.min.js?v=1.0.0"></script><script>if (window.mermaid) {
  var options = JSON.parse(document.getElementById('maid-script').getAttribute('mermaidoptioins'));
  mermaid.initialize(options);
}</script></div><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>