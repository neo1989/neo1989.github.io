<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="我读书少，你莫骗我。"><title>Way2AI · PyTorch | 愚苏记</title><link rel="stylesheet" type="text/css" href="https://cdn.staticfile.org/lxgw-wenkai-webfont/1.6.0/style.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="/lib/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="/lib/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="/lib/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="/lib/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="/lib/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + '96c862f2728296588ae9849f3bcb95db';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();</script><link rel="alternate" type="application/atom+xml" href="/atom.xml"><meta name="generator" content="Hexo 7.1.1"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Way2AI · PyTorch</h1><a id="logo" href="/.">愚苏记</a><p class="description">To no avail but try.</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-4-4"><div class="content_container no-padding-right"><div class="post"><h1 class="post-title">Way2AI · PyTorch</h1><div class="post-meta">May 17, 2023<span> | </span><span class="category"><a href="/categories/Way2AI/">Way2AI</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 1.9k</span><span class="post-meta-item-text"> Words</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 10</span><span class="post-meta-item-text"> Minutes</span></span></span></div><a class="disqus-comment-count" data-disqus-identifier="Way2AI/Way2AI-PyTorch/" href="/Way2AI/Way2AI-PyTorch/#disqus_thread"></a><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">Contents</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#TL-DR"><span class="toc-number">1.</span> <span class="toc-text">TL;DR</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Set-up"><span class="toc-number">2.</span> <span class="toc-text">Set up</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Basic"><span class="toc-number">3.</span> <span class="toc-text">Basic</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Operations"><span class="toc-number">4.</span> <span class="toc-text">Operations</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Indexing"><span class="toc-number">5.</span> <span class="toc-text">Indexing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Slicing"><span class="toc-number">6.</span> <span class="toc-text">Slicing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Joining"><span class="toc-number">7.</span> <span class="toc-text">Joining</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Gradients-%E6%A2%AF%E5%BA%A6"><span class="toc-number">8.</span> <span class="toc-text">Gradients 梯度</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CUDA"><span class="toc-number">9.</span> <span class="toc-text">CUDA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Citation"><span class="toc-number">10.</span> <span class="toc-text">Citation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ending"><span class="toc-number">11.</span> <span class="toc-text">Ending</span></a></li></ol></div></div><div class="post-content"><h2 id="TL-DR">TL;DR</h2>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><p>Way2AI系列，确保出发去&quot;改变世界&quot;之前，我们已经打下了一个坚实的基础。</p>
<p>本文简单介绍了PyTorch这个机器学习框架的必备知识。</p>
<h2 id="Set-up">Set up</h2>
<p>首先，我们将导入NumPy和PyTorch库，并设置随机种子以实现可重复性。<br>
请注意，PyTorch 也需要一个种子，因为我们将生成随机张量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">SEED = <span class="number">1024</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set seed for reproducibility</span></span><br><span class="line">np.random.seed(seed=SEED)</span><br><span class="line">torch.manual_seed(SEED)</span><br></pre></td></tr></table></figure>
<h2 id="Basic">Basic</h2>
<p>下面一些 PyTorch 的基础知识，例如如何创建张量以及将常见的数据结构（列表、数组等）转换为张量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Creating a random tensor</span></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>) <span class="comment"># normal distribution (rand(2,3) -&gt; uniform distribution)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Type: <span class="subst">&#123;x.<span class="built_in">type</span>()&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size: <span class="subst">&#123;x.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Values: \n<span class="subst">&#123;x&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Type: torch.FloatTensor</span></span><br><span class="line"><span class="comment"># Size: torch.Size([2, 3])</span></span><br><span class="line"><span class="comment"># Values:</span></span><br><span class="line"><span class="comment"># tensor([[-1.4837,  0.2671, -1.8337],</span></span><br><span class="line"><span class="comment">#         [-0.1047,  0.6002, -0.5496]])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Zero and Ones tensor</span></span><br><span class="line">x = torch.zeros(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span> (x)</span><br><span class="line">x = torch.ones(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span> (x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># tensor([[0., 0., 0.],</span></span><br><span class="line"><span class="comment">#         [0., 0., 0.]])</span></span><br><span class="line"><span class="comment"># tensor([[1., 1., 1.],</span></span><br><span class="line"><span class="comment">#         [1., 1., 1.]])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># List → Tensor</span></span><br><span class="line">x = torch.Tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],[<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size: <span class="subst">&#123;x.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Values: \n<span class="subst">&#123;x&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Size: torch.Size([2, 3])</span></span><br><span class="line"><span class="comment"># Values:</span></span><br><span class="line"><span class="comment"># tensor([[1., 2., 3.],</span></span><br><span class="line"><span class="comment">#         [4., 5., 6.]])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># NumPy array → Tensor</span></span><br><span class="line">x = torch.Tensor(np.random.rand(<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size: <span class="subst">&#123;x.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Values: \n<span class="subst">&#123;x&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Size: torch.Size([2, 3])</span></span><br><span class="line"><span class="comment"># Values:</span></span><br><span class="line"><span class="comment"># tensor([[0.4445, 0.3168, 0.9231],</span></span><br><span class="line"><span class="comment">#         [0.4659, 0.7984, 0.1992]])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Changing tensor type</span></span><br><span class="line">x = torch.Tensor(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Type: <span class="subst">&#123;x.<span class="built_in">type</span>()&#125;</span>&quot;</span>)</span><br><span class="line">x = x.long()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Type: <span class="subst">&#123;x.<span class="built_in">type</span>()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Type: torch.FloatTensor</span></span><br><span class="line"><span class="comment"># Type: torch.LongTensor</span></span><br></pre></td></tr></table></figure>
<h2 id="Operations">Operations</h2>
<p>下面探索一些张量的基本操作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Addition</span></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">y = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">z = x + y</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size: <span class="subst">&#123;z.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Values: \n<span class="subst">&#123;z&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Size: torch.Size([2, 3])</span></span><br><span class="line"><span class="comment"># Values:</span></span><br><span class="line"><span class="comment"># tensor([[-0.4446,  0.4933, -1.4847],</span></span><br><span class="line"><span class="comment">#         [ 0.8493,  0.6911, -0.3357]])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Dot product</span></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">y = torch.randn(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">z = torch.mm(x, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size: <span class="subst">&#123;z.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Values: \n<span class="subst">&#123;z&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Size: torch.Size([2, 2])</span></span><br><span class="line"><span class="comment"># Values:</span></span><br><span class="line"><span class="comment"># tensor([[ 0.2733, -4.0392],</span></span><br><span class="line"><span class="comment">#         [ 1.6385, -4.7220]])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Transpose</span></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size: <span class="subst">&#123;x.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Values: \n<span class="subst">&#123;x&#125;</span>&quot;</span>)</span><br><span class="line">y = torch.t(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size: <span class="subst">&#123;y.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Values: \n<span class="subst">&#123;y&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Size: torch.Size([2, 3])</span></span><br><span class="line"><span class="comment"># Values:</span></span><br><span class="line"><span class="comment"># tensor([[ 0.5920, -0.6301, -0.8856],</span></span><br><span class="line"><span class="comment">#         [ 1.2261, -0.4671, -1.0279]])</span></span><br><span class="line"><span class="comment"># Size: torch.Size([3, 2])</span></span><br><span class="line"><span class="comment"># Values:</span></span><br><span class="line"><span class="comment"># tensor([[ 0.5920,  1.2261],</span></span><br><span class="line"><span class="comment">#         [-0.6301, -0.4671],</span></span><br><span class="line"><span class="comment">#         [-0.8856, -1.0279]])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Reshape</span></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">z = x.view(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size: <span class="subst">&#123;z.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Values: \n<span class="subst">&#123;z&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Size: torch.Size([3, 2])</span></span><br><span class="line"><span class="comment"># Values:</span></span><br><span class="line"><span class="comment"># tensor([[-1.0387,  0.1039],</span></span><br><span class="line"><span class="comment">#         [ 0.5989, -1.4801],</span></span><br><span class="line"><span class="comment">#         [-0.8618, -0.9181]])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Dangers of reshaping (unintended consequences)</span></span><br><span class="line">x = torch.tensor([</span><br><span class="line">    [[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>]],</span><br><span class="line">    [[<span class="number">10</span>, <span class="number">10</span>, <span class="number">10</span>, <span class="number">10</span>], [<span class="number">20</span>, <span class="number">20</span>, <span class="number">20</span>, <span class="number">20</span>], [<span class="number">30</span>, <span class="number">30</span>, <span class="number">30</span>, <span class="number">30</span>]]</span><br><span class="line">])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size: <span class="subst">&#123;x.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;x: \n<span class="subst">&#123;x&#125;</span>\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">a = x.view(x.size(<span class="number">1</span>), -<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nSize: <span class="subst">&#123;a.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;a: \n<span class="subst">&#123;a&#125;</span>\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">b = x.transpose(<span class="number">0</span>, <span class="number">1</span>).contiguous()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nSize: <span class="subst">&#123;b.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;b: \n<span class="subst">&#123;b&#125;</span>\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">c = b.view(b.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nSize: <span class="subst">&#123;c.shape&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;c: \n<span class="subst">&#123;c&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Size: torch.Size([2, 3, 4])</span></span><br><span class="line"><span class="comment"># x:</span></span><br><span class="line"><span class="comment"># tensor([[[ 1,  1,  1,  1],</span></span><br><span class="line"><span class="comment">#          [ 2,  2,  2,  2],</span></span><br><span class="line"><span class="comment">#          [ 3,  3,  3,  3]],</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#         [[10, 10, 10, 10],</span></span><br><span class="line"><span class="comment">#          [20, 20, 20, 20],</span></span><br><span class="line"><span class="comment">#          [30, 30, 30, 30]]])</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># Size: torch.Size([3, 8])</span></span><br><span class="line"><span class="comment"># a:</span></span><br><span class="line"><span class="comment"># tensor([[ 1,  1,  1,  1,  2,  2,  2,  2],</span></span><br><span class="line"><span class="comment">#         [ 3,  3,  3,  3, 10, 10, 10, 10],</span></span><br><span class="line"><span class="comment">#         [20, 20, 20, 20, 30, 30, 30, 30]])</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># Size: torch.Size([3, 2, 4])</span></span><br><span class="line"><span class="comment"># b:</span></span><br><span class="line"><span class="comment"># tensor([[[ 1,  1,  1,  1],</span></span><br><span class="line"><span class="comment">#          [10, 10, 10, 10]],</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#         [[ 2,  2,  2,  2],</span></span><br><span class="line"><span class="comment">#          [20, 20, 20, 20]],</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#         [[ 3,  3,  3,  3],</span></span><br><span class="line"><span class="comment">#          [30, 30, 30, 30]]])</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># Size: torch.Size([3, 8])</span></span><br><span class="line"><span class="comment"># c:</span></span><br><span class="line"><span class="comment"># tensor([[ 1,  1,  1,  1, 10, 10, 10, 10],</span></span><br><span class="line"><span class="comment">#         [ 2,  2,  2,  2, 20, 20, 20, 20],</span></span><br><span class="line"><span class="comment">#         [ 3,  3,  3,  3, 30, 30, 30, 30]])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Dimensional operations</span></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Values: \n<span class="subst">&#123;x&#125;</span>&quot;</span>)</span><br><span class="line">y = torch.<span class="built_in">sum</span>(x, dim=<span class="number">0</span>) <span class="comment"># add each row&#x27;s value for every column</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Values: \n<span class="subst">&#123;y&#125;</span>&quot;</span>)</span><br><span class="line">z = torch.<span class="built_in">sum</span>(x, dim=<span class="number">1</span>) <span class="comment"># add each columns&#x27;s value for every row</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Values: \n<span class="subst">&#123;z&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Values:</span></span><br><span class="line"><span class="comment"># tensor([[-0.0355,  0.4145,  0.6798],</span></span><br><span class="line"><span class="comment">#         [-0.2936,  0.1872, -0.2724]])</span></span><br><span class="line"><span class="comment"># Values:</span></span><br><span class="line"><span class="comment"># tensor([-0.3292,  0.6017,  0.4074])</span></span><br><span class="line"><span class="comment"># Values:</span></span><br><span class="line"><span class="comment"># tensor([ 1.0588, -0.3788])</span></span><br></pre></td></tr></table></figure>
<h2 id="Indexing">Indexing</h2>
<p>可以使用索引从张量中提取指定的值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;x: \n<span class="subst">&#123;x&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;x[:1]: \n<span class="subst">&#123;x[:<span class="number">1</span>]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;x[:1, 1:3]: \n<span class="subst">&#123;x[:<span class="number">1</span>, <span class="number">1</span>:<span class="number">3</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line">x:</span><br><span class="line"><span class="comment"># tensor([[-0.5524, -0.8358, -2.8240,  0.2564],</span></span><br><span class="line"><span class="comment">#         [ 0.5045, -1.1290,  0.7631,  1.0155],</span></span><br><span class="line"><span class="comment">#         [-1.2475, -0.0335,  0.5442,  0.4280]])</span></span><br><span class="line"><span class="comment"># x[:1]:</span></span><br><span class="line"><span class="comment"># tensor([[-0.5524, -0.8358, -2.8240,  0.2564]])</span></span><br><span class="line"><span class="comment"># x[:1, 1:3]:</span></span><br><span class="line"><span class="comment"># tensor([[-0.8358, -2.8240]])</span></span><br></pre></td></tr></table></figure>
<h2 id="Slicing">Slicing</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Select with dimensional indices</span></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Values: \n<span class="subst">&#123;x&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">col_indices = torch.LongTensor([<span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line">chosen = torch.index_select(x, dim=<span class="number">1</span>, index=col_indices) <span class="comment"># values from column 0 &amp; 2</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Values: \n<span class="subst">&#123;chosen&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">row_indices = torch.LongTensor([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">col_indices = torch.LongTensor([<span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line">chosen = x[row_indices, col_indices] <span class="comment"># values from (0, 0) &amp; (1, 2)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Values: \n<span class="subst">&#123;chosen&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># Values:</span></span><br><span class="line"><span class="comment"># tensor([[-1.6357,  0.7964,  0.9450],</span></span><br><span class="line"><span class="comment">#         [-1.6535,  1.8129,  0.9162]])</span></span><br><span class="line"><span class="comment"># Values:</span></span><br><span class="line"><span class="comment"># tensor([[-1.6357,  0.9450],</span></span><br><span class="line"><span class="comment">#         [-1.6535,  0.9162]])</span></span><br><span class="line"><span class="comment"># Values:</span></span><br><span class="line"><span class="comment"># tensor([-1.6357,  0.9162])</span></span><br></pre></td></tr></table></figure>
<h2 id="Joining">Joining</h2>
<p>我们还可以使用concatenate和stack来合并张量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span> (x)</span><br><span class="line"><span class="built_in">print</span> (x.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># tensor([[-0.7004,  0.8429,  0.8971],</span></span><br><span class="line"><span class="comment">#         [-0.0272,  0.4722,  1.1621]])</span></span><br><span class="line"><span class="comment"># torch.Size([2, 3])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Concatenation</span></span><br><span class="line">y = torch.cat([x, x], dim=<span class="number">0</span>) <span class="comment"># concat on a specified dimension</span></span><br><span class="line"><span class="built_in">print</span> (y)</span><br><span class="line"><span class="built_in">print</span> (y.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># tensor([[-0.7004,  0.8429,  0.8971],</span></span><br><span class="line"><span class="comment">#         [-0.0272,  0.4722,  1.1621],</span></span><br><span class="line"><span class="comment">#         [-0.7004,  0.8429,  0.8971],</span></span><br><span class="line"><span class="comment">#         [-0.0272,  0.4722,  1.1621]])</span></span><br><span class="line"><span class="comment"># torch.Size([4, 3])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Stacking</span></span><br><span class="line">z = torch.stack([x, x], dim=<span class="number">0</span>) <span class="comment"># stack on new dimension</span></span><br><span class="line"><span class="built_in">print</span> (z)</span><br><span class="line"><span class="built_in">print</span> (z.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># tensor([[[-0.7004,  0.8429,  0.8971],</span></span><br><span class="line"><span class="comment">#          [-0.0272,  0.4722,  1.1621]],</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#         [[-0.7004,  0.8429,  0.8971],</span></span><br><span class="line"><span class="comment">#          [-0.0272,  0.4722,  1.1621]]])</span></span><br><span class="line"><span class="comment"># torch.Size([2, 2, 3])</span></span><br></pre></td></tr></table></figure>
<h2 id="Gradients-梯度">Gradients 梯度</h2>
<p>我们可以使用梯度追踪(gradient bookkeeping) 来计算张量相对于其组成部分的梯度（变化率）。</p>
<p>梯度是机器学习和深度学习中最重要的概念，没有之一。后续会进一步介绍，这里先简单示例PyTorch如何计算某个函数在某点处的梯度:</p>
<p>$$<br>
y = 3x + 2<br>
$$</p>
<p>$$<br>
z = \sum(y/N)<br>
$$</p>
<p>$$<br>
\frac{\partial(z)}{\partial(x)} = \frac{\partial(z)}{\partial(y)} \cdot \frac{\partial(y)}{\partial(x)} = \frac{1}{N} \cdot 3 = \frac{1}{3 \cdot 4} \cdot 3 = 0.25<br>
$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Tensors with gradient bookkeeping</span></span><br><span class="line">x = torch.rand(<span class="number">3</span>, <span class="number">4</span>, requires_grad=<span class="literal">True</span>)  <span class="comment"># requires_grad=True 表示此处需要计算梯度</span></span><br><span class="line">y = <span class="number">3</span>*x + <span class="number">2</span></span><br><span class="line">z = y.mean()</span><br><span class="line">z.backward()  <span class="comment"># 此时开始计算梯度</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;x: \n<span class="subst">&#123;x&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">f&quot;x.grad: \n<span class="subst">&#123;x.grad&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># x:</span></span><br><span class="line"><span class="comment"># tensor([[0.1154, 0.1101, 0.4831, 0.1580],</span></span><br><span class="line"><span class="comment">#         [0.4459, 0.2242, 0.9525, 0.8113],</span></span><br><span class="line"><span class="comment">#         [0.0387, 0.1512, 0.9678, 0.7512]], requires_grad=True)</span></span><br><span class="line"><span class="comment"># x.grad:</span></span><br><span class="line"><span class="comment"># tensor([[0.2500, 0.2500, 0.2500, 0.2500],</span></span><br><span class="line"><span class="comment">#         [0.2500, 0.2500, 0.2500, 0.2500],</span></span><br><span class="line"><span class="comment">#         [0.2500, 0.2500, 0.2500, 0.2500]])</span></span><br></pre></td></tr></table></figure>
<h2 id="CUDA">CUDA</h2>
<p>我们可以使用CUDA（Nvidia的并行计算平台和API）将张量加载到GPU上进行并行计算。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set device</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">x = torch.rand(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span> (x.is_cuda)</span><br><span class="line">x = torch.rand(<span class="number">2</span>,<span class="number">3</span>).to(device)</span><br><span class="line"><span class="built_in">print</span> (x.is_cuda)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># False</span></span><br><span class="line"><span class="comment"># True</span></span><br></pre></td></tr></table></figure>
<h2 id="Citation">Citation</h2>
<figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="language-xml">@article</span><span class="template-variable">&#123;madewithml,</span></span><br><span class="line"><span class="template-variable">    author       = &#123;Goku Mohandas&#125;</span><span class="language-xml">,</span></span><br><span class="line"><span class="language-xml">    title        = </span><span class="template-variable">&#123; PyTorch - Made With ML &#125;</span><span class="language-xml">,</span></span><br><span class="line"><span class="language-xml">    howpublished = </span><span class="template-variable">&#123;\url&#123;https://madewithml.com/&#125;</span><span class="language-xml">&#125;,</span></span><br><span class="line"><span class="language-xml">    year         = </span><span class="template-variable">&#123;2022&#125;</span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">&#125;</span></span><br></pre></td></tr></table></figure>
<h2 id="Ending">Ending</h2>
<p>到这里，便拥有了Way2AI路上需要的PyTorch的必备知识。我们可以发现，PyTorch的基础操作，与NumPy其实没什么太大的差别。</p>
<p>事实上NumPy和PyTorch可以相互转换，PyTorch提供了与NumPy兼容的接口，可以方便地将数据从NumPy数组转换为PyTorch张量，并在它们之间进行转换。这使得在使用PyTorch进行深度学习时，可以利用NumPy的强大功能进行数据预处理和后处理。</p>
<p>一般地，当我们需要进行常规的数值计算、数组操作和数学函数应用时，可以使用NumPy。当我们需要构建、训练和部署神经网络模型时，可以使用PyTorch。</p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/" title="PyTorch">PyTorch官网</a> 上有关于PyTorch的全部知识。</p>
</div><iframe src="/donate/?AliPayQR=null&amp;WeChatQR=http://s3.mindex.xyz/mp/qrcode-s.jpg&amp;GitHub=http://github.com/neo1989&amp;BTCQR=null&amp;BTCKEY=null&amp;PayPal=null" style="overflow-x:hidden; overflow-y:hidden; border:0xp none #fff; min-height:240px; width:100%;" frameborder="0" scrolling="no"></iframe><div><ul class="post-copyright"><li class="post-copyright-author"><strong>Author: </strong>尼欧</li><li class="post-copyright-link"><strong>Blog Link: </strong><a href="/Way2AI/Way2AI-PyTorch/">https://neo1989.net/Way2AI/Way2AI-PyTorch/</a></li><li class="post-copyright-license"><strong>Copyright Declaration: </strong>转载请声明出处。</li></ul></div><br><div class="tags"><a href="/tags/Coder/">Coder</a><a href="/tags/AI/">AI</a><a href="/tags/PyTorch/">PyTorch</a></div><div class="post-nav"><a class="pre" href="/Way2AI/Way2AI-LinearRegression-1/">Way2AI · 机器学习之Linear Regression (一)</a><a class="next" href="/Way2AI/Way2AI-Pandas/">Way2AI · Pandas</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论（请确保 Disqus 可以正常加载）</button></div><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'https://neo1989.net/Way2AI/Way2AI-PyTorch/';
    this.page.identifier = 'Way2AI/Way2AI-PyTorch/';
    this.page.title = 'Way2AI · PyTorch';
  };</script><!-- script(type='text/javascript' id='disqus-lazy-load-script').--><!--   $.ajax({--><!--   url: 'https://disqus.com/next/config.json',--><!--   timeout: 2500,--><!--   type: 'GET',--><!--   success: function(){--><!--     var d = document;--><!--     var s = d.createElement('script');--><!--     s.src = '//#{theme.disqus}.disqus.com/embed.js';--><!--     s.setAttribute('data-timestamp', + new Date());--><!--     (d.head || d.body).appendChild(s);--><!--     $('.disqus_click_btn').css('display', 'none');--><!--   },--><!--   error: function() {--><!--     $('.disqus_click_btn').css('display', 'block');--><!--   }--><!--   });--><script type="text/javascript" id="disqus-click-load">$('.btn_click_load').click(() => {  //click to load comments
    (() => { // DON'T EDIT BELOW THIS LINE
        var d = document;
        var s = d.createElement('script');
        s.src = '//neo1989.disqus.com/embed.js';
        s.setAttribute('data-timestamp', + new Date());
        (d.head || d.body).appendChild(s);
    })();
    $('.disqus_click_btn').css('display','none');
});</script><script type="text/javascript" id="disqus-count-script">$(function() {
     var xhr = new XMLHttpRequest();
     xhr.open('GET', '//disqus.com/next/config.json', true);
     xhr.timeout = 2500;
     xhr.onreadystatechange = function () {
       if (xhr.readyState === 4 && xhr.status === 200) {
         $('.post-meta .post-comments-count').show();
         var s = document.createElement('script');
         s.id = 'dsq-count-scr';
         s.src = 'https://neo1989.disqus.com/count.js';
         s.async = true;
         (document.head || document.body).appendChild(s);
       }
     };
     xhr.ontimeout = function () { xhr.abort(); };
     xhr.send(null);
   });
</script></div></div></div></div></div><div class="pure-u-1 pure-u-md-4-6"><div id="footer">Copyright © 2024 <a href="/." rel="nofollow">愚苏记.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/i-yard/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho/maupassant"> Cho.</a></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="/lib/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="/lib/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
  displayAlign: "left"
  });
</script><script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.6/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script><script type="text/javascript" id="maid-script" mermaidoptioins="{&quot;startOnload&quot;:true,&quot;theme&quot;:&quot;forest&quot;}" src="/js/mermaid.min.js?v=1.0.0"></script><script>if (window.mermaid) {
  var options = JSON.parse(document.getElementById('maid-script').getAttribute('mermaidoptioins'));
  mermaid.initialize(options);
}</script></div><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>